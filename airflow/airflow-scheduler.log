2024-05-21 23:28:10,346 INFO - Task context logging is enabled
2024-05-21 23:28:10,348 INFO - Loaded executor: SequentialExecutor
2024-05-21 23:28:15,421 INFO - Starting the scheduler
2024-05-21 23:28:15,421 INFO - Processing each file at most -1 times
2024-05-21 23:28:15,429 INFO - Launched DagFileProcessorManager with pid: 73600
2024-05-21 23:28:15,431 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-21 23:28:15,435 INFO - Configured default timezone UTC
2024-05-21 23:28:15,461 INFO - Marked 1 SchedulerJob instances as failed
2024-05-21 23:28:15,491 INFO - Reset the following 2 orphaned TaskInstances:
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-10T00:00:00+00:00 [queued]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-09T00:00:00+00:00 [queued]>
2024-05-21 23:28:15,623 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-13 00:00:00+00:00, run_after=2023-06-14 00:00:00+00:00
2024-05-21 23:28:15,850 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-05 00:00:00+00:00: scheduled__2023-06-05T00:00:00+00:00, state:running, queued_at: 2024-05-21 22:25:44.984822+00:00. externally triggered: False> failed
2024-05-21 23:28:15,852 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-05 00:00:00+00:00, run_id=scheduled__2023-06-05T00:00:00+00:00, run_start_date=2024-05-21 22:25:45.015970+00:00, run_end_date=2024-05-21 23:28:15.852520+00:00, run_duration=3750.83655, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-05 00:00:00+00:00, data_interval_end=2023-06-06 00:00:00+00:00, dag_hash=f18f41c57766075893c036d9a60ba4a1
2024-05-21 23:28:15,859 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-06 00:00:00+00:00, run_after=2023-06-07 00:00:00+00:00
2024-05-21 23:28:15,893 INFO - 5 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.extract_311_data manual__2024-05-21T23:22:14.737669+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-09T00:00:00+00:00 [scheduled]>
2024-05-21 23:28:15,895 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-21 23:28:15,895 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-21 23:28:15,896 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-21 23:28:15,896 INFO - DAG extract_311_data_dag has 3/16 running and queued tasks
2024-05-21 23:28:15,896 INFO - DAG extract_311_data_dag has 4/16 running and queued tasks
2024-05-21 23:28:15,900 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.extract_311_data manual__2024-05-21T23:22:14.737669+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-09T00:00:00+00:00 [scheduled]>
2024-05-21 23:28:15,910 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-21 23:28:15,912 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:28:15,915 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='manual__2024-05-21T23:22:14.737669+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-21 23:28:15,915 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'manual__2024-05-21T23:22:14.737669+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:28:15,916 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:28:15,916 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:28:15,919 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:28:15,919 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:28:15,919 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-21 23:28:15,919 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:28:15,922 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:31:00,288 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'manual__2024-05-21T23:22:14.737669+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:31:24,559 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:34:07,189 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:34:12,008 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:39:16,940 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:39:16,941 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='manual__2024-05-21T23:22:14.737669+00:00', try_number=1, map_index=-1)
2024-05-21 23:39:16,941 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:39:16,941 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:39:16,941 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:39:16,954 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:34:04.609777+00:00, run_end_date=2024-05-21 23:34:06.518335+00:00, run_duration=1.908558, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=282, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:31:17.868468+00:00, queued_by_job_id=279, pid=74373
2024-05-21 23:39:16,954 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:34:10.078764+00:00, run_end_date=2024-05-21 23:34:11.260836+00:00, run_duration=1.182072, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=283, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:31:17.868468+00:00, queued_by_job_id=279, pid=74395
2024-05-21 23:39:16,955 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:28:17.837527+00:00, run_end_date=2024-05-21 23:30:59.377974+00:00, run_duration=161.540447, state=success, executor_state=success, try_number=1, max_tries=2, job_id=277, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-21 23:28:15.903157+00:00, queued_by_job_id=276, pid=73610
2024-05-21 23:39:16,955 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=manual__2024-05-21T23:22:14.737669+00:00, map_index=-1, run_start_date=2024-05-21 23:31:02.423615+00:00, run_end_date=2024-05-21 23:31:23.441845+00:00, run_duration=21.01823, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=278, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-21 23:31:17.868468+00:00, queued_by_job_id=279, pid=74240
2024-05-21 23:39:16,955 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:34:13.997244+00:00, run_end_date=2024-05-21 23:39:16.185043+00:00, run_duration=302.187799, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=284, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-21 23:31:17.868468+00:00, queued_by_job_id=279, pid=74415
2024-05-21 23:39:17,009 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-21 23:39:17,012 INFO - Marked 1 SchedulerJob instances as failed
2024-05-21 23:39:17,016 INFO - Reset the following 1 orphaned TaskInstances:
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-12T00:00:00+00:00 [queued]>
2024-05-21 23:39:17,035 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-15 00:00:00+00:00, run_after=2023-06-16 00:00:00+00:00
2024-05-21 23:39:17,156 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-07 00:00:00+00:00: scheduled__2023-06-07T00:00:00+00:00, state:running, queued_at: 2024-05-21 22:33:16.090531+00:00. externally triggered: False> failed
2024-05-21 23:39:17,157 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-07 00:00:00+00:00, run_id=scheduled__2023-06-07T00:00:00+00:00, run_start_date=2024-05-21 22:33:16.103374+00:00, run_end_date=2024-05-21 23:39:17.157206+00:00, run_duration=3961.053832, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-07 00:00:00+00:00, data_interval_end=2023-06-08 00:00:00+00:00, dag_hash=1501b912344ab72d8f171e57f79ba68c
2024-05-21 23:39:17,160 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-08 00:00:00+00:00, run_after=2023-06-09 00:00:00+00:00
2024-05-21 23:39:17,173 INFO - 6 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.extract_311_data manual__2024-05-21T23:22:14.737669+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-13T00:00:00+00:00 [scheduled]>
2024-05-21 23:39:17,173 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-21 23:39:17,173 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-21 23:39:17,174 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-21 23:39:17,174 INFO - DAG extract_311_data_dag has 3/16 running and queued tasks
2024-05-21 23:39:17,174 INFO - DAG extract_311_data_dag has 4/16 running and queued tasks
2024-05-21 23:39:17,174 INFO - DAG extract_311_data_dag has 5/16 running and queued tasks
2024-05-21 23:39:17,175 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.extract_311_data manual__2024-05-21T23:22:14.737669+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-13T00:00:00+00:00 [scheduled]>
2024-05-21 23:39:17,179 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-21 23:39:17,179 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:39:17,179 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='manual__2024-05-21T23:22:14.737669+00:00', try_number=3, map_index=-1) to executor with priority 8 and queue default
2024-05-21 23:39:17,179 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'manual__2024-05-21T23:22:14.737669+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:39:17,180 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:39:17,180 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:39:17,180 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:39:17,180 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:39:17,181 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:39:17,181 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:39:17,181 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:39:17,181 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:39:17,185 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:43:06,468 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'manual__2024-05-21T23:22:14.737669+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:04,295 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:07,974 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:11,465 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:15,606 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:19,760 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:44:19,760 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='manual__2024-05-21T23:22:14.737669+00:00', try_number=3, map_index=-1)
2024-05-21 23:44:19,760 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=2, map_index=-1)
2024-05-21 23:44:19,761 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=2, map_index=-1)
2024-05-21 23:44:19,761 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:44:19,761 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:44:19,774 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:39:19.220636+00:00, run_end_date=2024-05-21 23:43:05.800551+00:00, run_duration=226.579915, state=success, executor_state=success, try_number=1, max_tries=2, job_id=285, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-21 23:39:17.176043+00:00, queued_by_job_id=276, pid=74629
2024-05-21 23:44:19,774 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=manual__2024-05-21T23:22:14.737669+00:00, map_index=-1, run_start_date=2024-05-21 23:43:08.342465+00:00, run_end_date=2024-05-21 23:44:03.639621+00:00, run_duration=55.297156, state=success, executor_state=success, try_number=3, max_tries=2, job_id=286, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-21 23:39:17.176043+00:00, queued_by_job_id=276, pid=74783
2024-05-21 23:44:19,774 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:44:06.457661+00:00, run_end_date=2024-05-21 23:44:07.378592+00:00, run_duration=0.920931, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=287, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:39:17.176043+00:00, queued_by_job_id=276, pid=74834
2024-05-21 23:44:19,775 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:44:09.763949+00:00, run_end_date=2024-05-21 23:44:10.763374+00:00, run_duration=0.999425, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=288, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:39:17.176043+00:00, queued_by_job_id=276, pid=74854
2024-05-21 23:44:19,775 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:44:13.778020+00:00, run_end_date=2024-05-21 23:44:14.953670+00:00, run_duration=1.17565, state=success, executor_state=success, try_number=1, max_tries=2, job_id=289, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:39:17.176043+00:00, queued_by_job_id=276, pid=74878
2024-05-21 23:44:19,776 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:44:17.692944+00:00, run_end_date=2024-05-21 23:44:18.945948+00:00, run_duration=1.253004, state=success, executor_state=success, try_number=1, max_tries=2, job_id=290, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:39:17.176043+00:00, queued_by_job_id=276, pid=74902
2024-05-21 23:44:19,811 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-21 23:44:19,831 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-16 00:00:00+00:00, run_after=2023-06-17 00:00:00+00:00
2024-05-21 23:44:19,942 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-08 00:00:00+00:00: scheduled__2023-06-08T00:00:00+00:00, state:running, queued_at: 2024-05-21 22:35:29.040967+00:00. externally triggered: False> failed
2024-05-21 23:44:19,942 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-08 00:00:00+00:00, run_id=scheduled__2023-06-08T00:00:00+00:00, run_start_date=2024-05-21 22:35:29.053539+00:00, run_end_date=2024-05-21 23:44:19.942632+00:00, run_duration=4130.889093, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-08 00:00:00+00:00, data_interval_end=2023-06-09 00:00:00+00:00, dag_hash=e0b7d46acb1a01adc0682b065d896f5c
2024-05-21 23:44:19,946 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-09 00:00:00+00:00, run_after=2023-06-10 00:00:00+00:00
2024-05-21 23:44:19,961 INFO - 5 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 manual__2024-05-21T23:22:14.737669+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-13T00:00:00+00:00 [scheduled]>
2024-05-21 23:44:19,962 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-21 23:44:19,962 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-21 23:44:19,962 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-21 23:44:19,962 INFO - DAG extract_311_data_dag has 3/16 running and queued tasks
2024-05-21 23:44:19,963 INFO - DAG extract_311_data_dag has 4/16 running and queued tasks
2024-05-21 23:44:19,963 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 manual__2024-05-21T23:22:14.737669+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-13T00:00:00+00:00 [scheduled]>
2024-05-21 23:44:19,968 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-21 23:44:19,968 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:19,968 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:44:19,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:19,969 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='manual__2024-05-21T23:22:14.737669+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:44:19,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'manual__2024-05-21T23:22:14.737669+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:19,971 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-21 23:44:19,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:19,971 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-21 23:44:19,972 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:44:19,973 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:45:46,178 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:45:49,853 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'manual__2024-05-21T23:22:14.737669+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:45:53,806 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:50:58,294 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:56:03,023 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:56:03,024 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:56:03,024 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='manual__2024-05-21T23:22:14.737669+00:00', try_number=1, map_index=-1)
2024-05-21 23:56:03,024 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:56:03,024 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-21 23:56:03,031 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:45:47.848547+00:00, run_end_date=2024-05-21 23:45:48.959073+00:00, run_duration=1.110526, state=success, executor_state=success, try_number=1, max_tries=2, job_id=292, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:44:19.966187+00:00, queued_by_job_id=276, pid=74998
2024-05-21 23:56:03,031 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=manual__2024-05-21T23:22:14.737669+00:00, map_index=-1, run_start_date=2024-05-21 23:45:51.942692+00:00, run_end_date=2024-05-21 23:45:53.152685+00:00, run_duration=1.209993, state=success, executor_state=success, try_number=1, max_tries=2, job_id=293, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:44:19.966187+00:00, queued_by_job_id=276, pid=75022
2024-05-21 23:56:03,032 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:45:55.708383+00:00, run_end_date=2024-05-21 23:50:57.578301+00:00, run_duration=301.869918, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=294, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-21 23:44:19.966187+00:00, queued_by_job_id=276, pid=75046
2024-05-21 23:56:03,032 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:44:22.111562+00:00, run_end_date=2024-05-21 23:45:45.597851+00:00, run_duration=83.486289, state=success, executor_state=success, try_number=1, max_tries=2, job_id=291, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-21 23:44:19.966187+00:00, queued_by_job_id=276, pid=74927
2024-05-21 23:56:03,033 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:51:00.443926+00:00, run_end_date=2024-05-21 23:56:02.420099+00:00, run_duration=301.976173, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=295, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-21 23:44:19.966187+00:00, queued_by_job_id=276, pid=75245
2024-05-21 23:56:03,065 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-21 23:56:03,084 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-17 00:00:00+00:00, run_after=2023-06-18 00:00:00+00:00
2024-05-21 23:56:03,210 INFO - 6 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available manual__2024-05-21T23:22:14.737669+00:00 [scheduled]>
2024-05-21 23:56:03,211 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-21 23:56:03,211 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-21 23:56:03,212 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-21 23:56:03,212 INFO - DAG extract_311_data_dag has 3/16 running and queued tasks
2024-05-21 23:56:03,212 INFO - DAG extract_311_data_dag has 4/16 running and queued tasks
2024-05-21 23:56:03,213 INFO - DAG extract_311_data_dag has 5/16 running and queued tasks
2024-05-21 23:56:03,214 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available manual__2024-05-21T23:22:14.737669+00:00 [scheduled]>
2024-05-21 23:56:03,217 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-21 23:56:03,218 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:56:03,218 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=3, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:56:03,218 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:56:03,219 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=3, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:56:03,219 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:56:03,219 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-21 23:56:03,220 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:56:03,221 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-21 23:56:03,221 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:56:03,222 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='manual__2024-05-21T23:22:14.737669+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-21 23:56:03,222 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'manual__2024-05-21T23:22:14.737669+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:56:03,224 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:57:11,407 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:57:15,085 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:57:18,364 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-21 23:57:22,040 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:02:27,063 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'manual__2024-05-21T23:22:14.737669+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:07:32,002 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:07:32,002 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=3, map_index=-1)
2024-05-22 00:07:32,003 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=3, map_index=-1)
2024-05-22 00:07:32,003 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:07:32,003 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:07:32,003 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='manual__2024-05-21T23:22:14.737669+00:00', try_number=1, map_index=-1)
2024-05-22 00:07:32,034 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:57:24.363176+00:00, run_end_date=2024-05-22 00:02:26.362266+00:00, run_duration=301.99909, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=300, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-21 23:56:03.215473+00:00, queued_by_job_id=276, pid=75562
2024-05-22 00:07:32,036 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=manual__2024-05-21T23:22:14.737669+00:00, map_index=-1, run_start_date=2024-05-22 00:02:29.067502+00:00, run_end_date=2024-05-22 00:07:31.373493+00:00, run_duration=302.305991, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=301, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-21 23:56:03.215473+00:00, queued_by_job_id=276, pid=75775
2024-05-22 00:07:32,038 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:57:20.266046+00:00, run_end_date=2024-05-21 23:57:21.375026+00:00, run_duration=1.10898, state=success, executor_state=success, try_number=1, max_tries=2, job_id=299, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:56:03.215473+00:00, queued_by_job_id=276, pid=75538
2024-05-22 00:07:32,041 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:56:05.309506+00:00, run_end_date=2024-05-21 23:57:10.709387+00:00, run_duration=65.399881, state=success, executor_state=success, try_number=1, max_tries=2, job_id=296, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-21 23:56:03.215473+00:00, queued_by_job_id=276, pid=75443
2024-05-22 00:07:32,041 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:57:13.338378+00:00, run_end_date=2024-05-21 23:57:14.351290+00:00, run_duration=1.012912, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=297, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:56:03.215473+00:00, queued_by_job_id=276, pid=75497
2024-05-22 00:07:32,041 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-21 23:57:16.881194+00:00, run_end_date=2024-05-21 23:57:17.721589+00:00, run_duration=0.840395, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=298, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-21 23:56:03.215473+00:00, queued_by_job_id=276, pid=75517
2024-05-22 00:07:32,100 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 00:07:32,127 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-18 00:00:00+00:00, run_after=2023-06-19 00:00:00+00:00
2024-05-22 00:07:32,270 ERROR - Marking run <DagRun extract_311_data_dag @ 2024-05-21 22:47:29.496885+00:00: manual__2024-05-21T22:47:29.496885+00:00, state:running, queued_at: 2024-05-21 22:47:29.514385+00:00. externally triggered: True> failed
2024-05-22 00:07:32,271 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2024-05-21 22:47:29.496885+00:00, run_id=manual__2024-05-21T22:47:29.496885+00:00, run_start_date=2024-05-21 22:48:57.270712+00:00, run_end_date=2024-05-22 00:07:32.271279+00:00, run_duration=4715.000567, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-05-20 00:00:00+00:00, data_interval_end=2024-05-21 00:00:00+00:00, dag_hash=9491e3250c99b7b3055325e1daca38c1
2024-05-22 00:07:32,295 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
2024-05-22 00:07:32,295 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 00:07:32,296 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 00:07:32,296 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 00:07:32,297 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
2024-05-22 00:07:32,301 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 00:07:32,301 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:07:32,301 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 00:07:32,302 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:07:32,302 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 00:07:32,302 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:07:32,304 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:09:27,949 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:09:31,730 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:14:36,273 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:14:36,273 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:14:36,274 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:14:36,285 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:07:34.267396+00:00, run_end_date=2024-05-22 00:09:27.308223+00:00, run_duration=113.040827, state=success, executor_state=success, try_number=1, max_tries=2, job_id=302, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 00:07:32.298360+00:00, queued_by_job_id=276, pid=75975
2024-05-22 00:14:36,285 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:09:29.961608+00:00, run_end_date=2024-05-22 00:09:31.137847+00:00, run_duration=1.176239, state=success, executor_state=success, try_number=1, max_tries=2, job_id=303, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 00:07:32.298360+00:00, queued_by_job_id=276, pid=76072
2024-05-22 00:14:36,286 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:09:33.699689+00:00, run_end_date=2024-05-22 00:14:35.617397+00:00, run_duration=301.917708, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=304, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 00:07:32.298360+00:00, queued_by_job_id=276, pid=76096
2024-05-22 00:14:36,321 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 00:14:36,341 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-19 00:00:00+00:00, run_after=2023-06-20 00:00:00+00:00
2024-05-22 00:14:36,503 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-09 00:00:00+00:00: scheduled__2023-06-09T00:00:00+00:00, state:running, queued_at: 2024-05-21 22:42:41.925774+00:00. externally triggered: False> failed
2024-05-22 00:14:36,504 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-09 00:00:00+00:00, run_id=scheduled__2023-06-09T00:00:00+00:00, run_start_date=2024-05-21 22:42:41.940115+00:00, run_end_date=2024-05-22 00:14:36.504545+00:00, run_duration=5514.56443, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-09 00:00:00+00:00, data_interval_end=2023-06-10 00:00:00+00:00, dag_hash=d167f7133b2f36660b69fc11ba91e8fc
2024-05-22 00:14:36,508 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-10 00:00:00+00:00, run_after=2023-06-11 00:00:00+00:00
2024-05-22 00:14:36,518 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
2024-05-22 00:14:36,519 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 00:14:36,519 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 00:14:36,520 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 00:14:36,520 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
2024-05-22 00:14:36,523 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 00:14:36,523 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:14:36,524 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 00:14:36,524 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:14:36,525 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 00:14:36,525 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:14:36,526 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:17:33,811 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:17:37,358 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:22:42,192 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:22:42,193 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:22:42,193 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:22:42,199 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:14:38.698160+00:00, run_end_date=2024-05-22 00:17:33.169698+00:00, run_duration=174.471538, state=success, executor_state=success, try_number=1, max_tries=2, job_id=305, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 00:14:36.521850+00:00, queued_by_job_id=276, pid=76294
2024-05-22 00:22:42,200 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:17:35.512396+00:00, run_end_date=2024-05-22 00:17:36.678380+00:00, run_duration=1.165984, state=success, executor_state=success, try_number=1, max_tries=2, job_id=306, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 00:14:36.521850+00:00, queued_by_job_id=276, pid=76421
2024-05-22 00:22:42,200 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:17:39.254185+00:00, run_end_date=2024-05-22 00:22:41.438108+00:00, run_duration=302.183923, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=307, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 00:14:36.521850+00:00, queued_by_job_id=276, pid=76445
2024-05-22 00:22:42,260 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 00:22:42,293 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-20 00:00:00+00:00, run_after=2023-06-21 00:00:00+00:00
2024-05-22 00:22:42,465 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
2024-05-22 00:22:42,466 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 00:22:42,466 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 00:22:42,466 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 00:22:42,466 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
2024-05-22 00:22:42,469 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 00:22:42,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:22:42,470 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 00:22:42,471 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:22:42,471 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 00:22:42,471 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:22:42,475 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:26:09,739 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:26:13,666 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:31:18,240 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:31:18,240 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:31:18,241 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:31:18,247 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:26:11.504370+00:00, run_end_date=2024-05-22 00:26:12.848341+00:00, run_duration=1.343971, state=success, executor_state=success, try_number=1, max_tries=2, job_id=309, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 00:22:42.467976+00:00, queued_by_job_id=276, pid=76784
2024-05-22 00:31:18,247 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:22:44.221471+00:00, run_end_date=2024-05-22 00:26:09.094012+00:00, run_duration=204.872541, state=success, executor_state=success, try_number=1, max_tries=2, job_id=308, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 00:22:42.467976+00:00, queued_by_job_id=276, pid=76643
2024-05-22 00:31:18,248 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:26:15.534323+00:00, run_end_date=2024-05-22 00:31:17.541645+00:00, run_duration=302.007322, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=310, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 00:22:42.467976+00:00, queued_by_job_id=276, pid=76808
2024-05-22 00:31:18,282 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 00:31:18,301 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-21 00:00:00+00:00, run_after=2023-06-22 00:00:00+00:00
2024-05-22 00:31:18,399 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-13 00:00:00+00:00: scheduled__2023-06-13T00:00:00+00:00, state:running, queued_at: 2024-05-21 23:31:17.033242+00:00. externally triggered: False> failed
2024-05-22 00:31:18,400 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-13 00:00:00+00:00, run_id=scheduled__2023-06-13T00:00:00+00:00, run_start_date=2024-05-21 23:31:17.163533+00:00, run_end_date=2024-05-22 00:31:18.399845+00:00, run_duration=3601.236312, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-13 00:00:00+00:00, data_interval_end=2023-06-14 00:00:00+00:00, dag_hash=65ed8ffc156b3c5adc542f2401032a62
2024-05-22 00:31:18,403 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-14 00:00:00+00:00, run_after=2023-06-15 00:00:00+00:00
2024-05-22 00:31:18,410 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-12 00:00:00+00:00: scheduled__2023-06-12T00:00:00+00:00, state:running, queued_at: 2024-05-21 23:28:15.566617+00:00. externally triggered: False> failed
2024-05-22 00:31:18,411 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-12 00:00:00+00:00, run_id=scheduled__2023-06-12T00:00:00+00:00, run_start_date=2024-05-21 23:28:15.648173+00:00, run_end_date=2024-05-22 00:31:18.411406+00:00, run_duration=3782.763233, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-12 00:00:00+00:00, data_interval_end=2023-06-13 00:00:00+00:00, dag_hash=65ed8ffc156b3c5adc542f2401032a62
2024-05-22 00:31:18,415 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-13 00:00:00+00:00, run_after=2023-06-14 00:00:00+00:00
2024-05-22 00:31:18,446 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
2024-05-22 00:31:18,446 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 00:31:18,446 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 00:31:18,446 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 00:31:18,447 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
2024-05-22 00:31:18,450 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 00:31:18,451 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:31:18,451 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 00:31:18,452 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:31:18,452 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 00:31:18,453 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:31:18,454 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:35:23,719 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:35:27,859 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:40:32,847 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:40:32,848 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:40:32,848 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:40:32,871 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:35:30.164146+00:00, run_end_date=2024-05-22 00:40:32.202883+00:00, run_duration=302.038737, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=313, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 00:31:18.448929+00:00, queued_by_job_id=276, pid=77195
2024-05-22 00:40:32,871 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:31:20.449165+00:00, run_end_date=2024-05-22 00:35:22.951493+00:00, run_duration=242.502328, state=success, executor_state=success, try_number=1, max_tries=2, job_id=311, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 00:31:18.448929+00:00, queued_by_job_id=276, pid=77008
2024-05-22 00:40:32,872 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:35:25.897628+00:00, run_end_date=2024-05-22 00:35:27.118184+00:00, run_duration=1.220556, state=success, executor_state=success, try_number=1, max_tries=2, job_id=312, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 00:31:18.448929+00:00, queued_by_job_id=276, pid=77171
2024-05-22 00:40:32,915 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 00:40:32,936 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-22 00:00:00+00:00, run_after=2023-06-23 00:00:00+00:00
2024-05-22 00:40:33,030 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-14 00:00:00+00:00: scheduled__2023-06-14T00:00:00+00:00, state:running, queued_at: 2024-05-21 23:39:17.029635+00:00. externally triggered: False> failed
2024-05-22 00:40:33,031 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-14 00:00:00+00:00, run_id=scheduled__2023-06-14T00:00:00+00:00, run_start_date=2024-05-21 23:39:17.042607+00:00, run_end_date=2024-05-22 00:40:33.030955+00:00, run_duration=3675.988348, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-14 00:00:00+00:00, data_interval_end=2023-06-15 00:00:00+00:00, dag_hash=1cd3bf9f538d34c8311400c12537449f
2024-05-22 00:40:33,036 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-15 00:00:00+00:00, run_after=2023-06-16 00:00:00+00:00
2024-05-22 00:40:33,044 ERROR - Marking run <DagRun extract_311_data_dag @ 2024-05-21 23:22:14.737669+00:00: manual__2024-05-21T23:22:14.737669+00:00, state:running, queued_at: 2024-05-21 23:22:14.746948+00:00. externally triggered: True> failed
2024-05-22 00:40:33,044 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2024-05-21 23:22:14.737669+00:00, run_id=manual__2024-05-21T23:22:14.737669+00:00, run_start_date=2024-05-21 23:28:15.651415+00:00, run_end_date=2024-05-22 00:40:33.044613+00:00, run_duration=4337.393198, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-05-20 00:00:00+00:00, data_interval_end=2024-05-21 00:00:00+00:00, dag_hash=1cd3bf9f538d34c8311400c12537449f
2024-05-22 00:40:33,080 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-19T00:00:00+00:00 [scheduled]>
2024-05-22 00:40:33,080 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 00:40:33,081 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 00:40:33,081 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 00:40:33,081 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-19T00:00:00+00:00 [scheduled]>
2024-05-22 00:40:33,085 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 00:40:33,085 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:40:33,085 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 00:40:33,086 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:40:33,086 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 00:40:33,086 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:40:33,088 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:42:26,937 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:42:30,961 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:47:36,106 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:47:36,106 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:47:36,107 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:47:36,115 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:40:35.155502+00:00, run_end_date=2024-05-22 00:42:26.257881+00:00, run_duration=111.102379, state=success, executor_state=success, try_number=1, max_tries=2, job_id=314, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 00:40:33.082877+00:00, queued_by_job_id=276, pid=77394
2024-05-22 00:47:36,116 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:42:28.930832+00:00, run_end_date=2024-05-22 00:42:30.351264+00:00, run_duration=1.420432, state=success, executor_state=success, try_number=1, max_tries=2, job_id=315, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 00:40:33.082877+00:00, queued_by_job_id=276, pid=77477
2024-05-22 00:47:36,116 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:42:33.238510+00:00, run_end_date=2024-05-22 00:47:35.212767+00:00, run_duration=301.974257, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=316, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 00:40:33.082877+00:00, queued_by_job_id=276, pid=77501
2024-05-22 00:47:36,152 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 00:47:36,172 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-23 00:00:00+00:00, run_after=2023-06-24 00:00:00+00:00
2024-05-22 00:47:36,322 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-15 00:00:00+00:00: scheduled__2023-06-15T00:00:00+00:00, state:running, queued_at: 2024-05-21 23:44:19.825325+00:00. externally triggered: False> failed
2024-05-22 00:47:36,323 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-15 00:00:00+00:00, run_id=scheduled__2023-06-15T00:00:00+00:00, run_start_date=2024-05-21 23:44:19.838287+00:00, run_end_date=2024-05-22 00:47:36.322932+00:00, run_duration=3796.484645, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-15 00:00:00+00:00, data_interval_end=2023-06-16 00:00:00+00:00, dag_hash=70641aef7c8b16c79a5de5de2cc7e8ff
2024-05-22 00:47:36,328 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-16 00:00:00+00:00, run_after=2023-06-17 00:00:00+00:00
2024-05-22 00:47:36,336 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-11 00:00:00+00:00: scheduled__2023-06-11T00:00:00+00:00, state:running, queued_at: 2024-05-21 23:06:24.659248+00:00. externally triggered: False> failed
2024-05-22 00:47:36,337 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-11 00:00:00+00:00, run_id=scheduled__2023-06-11T00:00:00+00:00, run_start_date=2024-05-21 23:06:24.672081+00:00, run_end_date=2024-05-22 00:47:36.337299+00:00, run_duration=6071.665218, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-11 00:00:00+00:00, data_interval_end=2023-06-12 00:00:00+00:00, dag_hash=70641aef7c8b16c79a5de5de2cc7e8ff
2024-05-22 00:47:36,341 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-12 00:00:00+00:00, run_after=2023-06-13 00:00:00+00:00
2024-05-22 00:47:36,350 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-10 00:00:00+00:00: scheduled__2023-06-10T00:00:00+00:00, state:running, queued_at: 2024-05-21 22:48:57.256460+00:00. externally triggered: False> failed
2024-05-22 00:47:36,350 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-10 00:00:00+00:00, run_id=scheduled__2023-06-10T00:00:00+00:00, run_start_date=2024-05-21 22:48:57.270552+00:00, run_end_date=2024-05-22 00:47:36.350695+00:00, run_duration=7119.080143, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-10 00:00:00+00:00, data_interval_end=2023-06-11 00:00:00+00:00, dag_hash=70641aef7c8b16c79a5de5de2cc7e8ff
2024-05-22 00:47:36,354 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-11 00:00:00+00:00, run_after=2023-06-12 00:00:00+00:00
2024-05-22 00:47:36,367 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-20T00:00:00+00:00 [scheduled]>
2024-05-22 00:47:36,368 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 00:47:36,368 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 00:47:36,368 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 00:47:36,369 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-20T00:00:00+00:00 [scheduled]>
2024-05-22 00:47:36,372 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 00:47:36,372 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:47:36,373 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 00:47:36,374 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:47:36,380 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 00:47:36,382 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:47:36,388 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:52:06,621 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:52:10,678 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:57:15,550 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:57:15,551 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:57:15,551 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 00:57:15,557 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:52:12.823578+00:00, run_end_date=2024-05-22 00:57:14.912013+00:00, run_duration=302.088435, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=319, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 00:47:36.370441+00:00, queued_by_job_id=276, pid=78381
2024-05-22 00:57:15,558 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:47:38.521000+00:00, run_end_date=2024-05-22 00:52:05.910164+00:00, run_duration=267.389164, state=success, executor_state=success, try_number=1, max_tries=2, job_id=317, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 00:47:36.370441+00:00, queued_by_job_id=276, pid=78163
2024-05-22 00:57:15,558 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:52:08.522332+00:00, run_end_date=2024-05-22 00:52:10.043374+00:00, run_duration=1.521042, state=success, executor_state=success, try_number=1, max_tries=2, job_id=318, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 00:47:36.370441+00:00, queued_by_job_id=276, pid=78357
2024-05-22 00:57:15,592 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 00:57:15,610 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-24 00:00:00+00:00, run_after=2023-06-25 00:00:00+00:00
2024-05-22 00:57:15,703 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-16 00:00:00+00:00: scheduled__2023-06-16T00:00:00+00:00, state:running, queued_at: 2024-05-21 23:56:03.078406+00:00. externally triggered: False> failed
2024-05-22 00:57:15,703 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-16 00:00:00+00:00, run_id=scheduled__2023-06-16T00:00:00+00:00, run_start_date=2024-05-21 23:56:03.091651+00:00, run_end_date=2024-05-22 00:57:15.703594+00:00, run_duration=3672.611943, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-16 00:00:00+00:00, data_interval_end=2023-06-17 00:00:00+00:00, dag_hash=18a457260827ca2a3098ea898564677e
2024-05-22 00:57:15,707 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-17 00:00:00+00:00, run_after=2023-06-18 00:00:00+00:00
2024-05-22 00:57:15,717 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
2024-05-22 00:57:15,717 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 00:57:15,718 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 00:57:15,718 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 00:57:15,718 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
2024-05-22 00:57:15,722 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 00:57:15,723 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:57:15,723 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 00:57:15,724 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:57:15,724 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 00:57:15,724 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:57:15,727 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:58:33,659 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 00:58:37,139 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:03:42,026 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:03:42,026 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:03:42,026 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:03:42,032 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:57:17.625729+00:00, run_end_date=2024-05-22 00:58:33.118428+00:00, run_duration=75.492699, state=success, executor_state=success, try_number=1, max_tries=2, job_id=320, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 00:57:15.721389+00:00, queued_by_job_id=276, pid=78583
2024-05-22 01:03:42,032 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:58:35.359367+00:00, run_end_date=2024-05-22 00:58:36.503504+00:00, run_duration=1.144137, state=success, executor_state=success, try_number=1, max_tries=2, job_id=321, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 00:57:15.721389+00:00, queued_by_job_id=276, pid=78644
2024-05-22 01:03:42,034 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 00:58:39.028948+00:00, run_end_date=2024-05-22 01:03:41.199771+00:00, run_duration=302.170823, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=322, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 00:57:15.721389+00:00, queued_by_job_id=276, pid=78672
2024-05-22 01:03:42,070 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 01:03:42,092 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-25 00:00:00+00:00, run_after=2023-06-26 00:00:00+00:00
2024-05-22 01:03:42,270 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-17 00:00:00+00:00: scheduled__2023-06-17T00:00:00+00:00, state:running, queued_at: 2024-05-22 00:07:32.118500+00:00. externally triggered: False> failed
2024-05-22 01:03:42,273 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-17 00:00:00+00:00, run_id=scheduled__2023-06-17T00:00:00+00:00, run_start_date=2024-05-22 00:07:32.136155+00:00, run_end_date=2024-05-22 01:03:42.273089+00:00, run_duration=3370.136934, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-17 00:00:00+00:00, data_interval_end=2023-06-18 00:00:00+00:00, dag_hash=0a820e509818fbe2822651155f04ba4f
2024-05-22 01:03:42,285 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-18 00:00:00+00:00, run_after=2023-06-19 00:00:00+00:00
2024-05-22 01:03:42,318 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-22T00:00:00+00:00 [scheduled]>
2024-05-22 01:03:42,319 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 01:03:42,319 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 01:03:42,319 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 01:03:42,319 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-22T00:00:00+00:00 [scheduled]>
2024-05-22 01:03:42,339 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 01:03:42,344 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:03:42,345 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 01:03:42,345 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:03:42,346 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 01:03:42,349 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:03:42,354 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:09:55,067 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:09:58,948 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:15:03,674 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:15:03,675 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:15:03,675 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:15:03,700 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:03:44.339196+00:00, run_end_date=2024-05-22 01:09:54.410902+00:00, run_duration=370.071706, state=success, executor_state=success, try_number=1, max_tries=2, job_id=323, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 01:03:42.327331+00:00, queued_by_job_id=276, pid=78888
2024-05-22 01:15:03,701 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:09:56.973053+00:00, run_end_date=2024-05-22 01:09:58.350794+00:00, run_duration=1.377741, state=success, executor_state=success, try_number=1, max_tries=2, job_id=324, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 01:03:42.327331+00:00, queued_by_job_id=276, pid=79126
2024-05-22 01:15:03,702 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:10:01.008949+00:00, run_end_date=2024-05-22 01:15:03.026673+00:00, run_duration=302.017724, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=325, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 01:03:42.327331+00:00, queued_by_job_id=276, pid=79150
2024-05-22 01:15:03,794 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 01:15:03,848 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-26 00:00:00+00:00, run_after=2023-06-27 00:00:00+00:00
2024-05-22 01:15:03,950 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-18 00:00:00+00:00: scheduled__2023-06-18T00:00:00+00:00, state:running, queued_at: 2024-05-22 00:14:36.334764+00:00. externally triggered: False> failed
2024-05-22 01:15:03,951 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-18 00:00:00+00:00, run_id=scheduled__2023-06-18T00:00:00+00:00, run_start_date=2024-05-22 00:14:36.349257+00:00, run_end_date=2024-05-22 01:15:03.951614+00:00, run_duration=3627.602357, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-18 00:00:00+00:00, data_interval_end=2023-06-19 00:00:00+00:00, dag_hash=cf514ca8e8017adcf71a6a6430de1487
2024-05-22 01:15:03,955 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-19 00:00:00+00:00, run_after=2023-06-20 00:00:00+00:00
2024-05-22 01:15:03,965 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-23T00:00:00+00:00 [scheduled]>
2024-05-22 01:15:03,966 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 01:15:03,966 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 01:15:03,966 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 01:15:03,966 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-23T00:00:00+00:00 [scheduled]>
2024-05-22 01:15:03,969 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 01:15:03,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:15:03,970 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 01:15:03,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:15:03,971 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 01:15:03,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:15:03,972 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:18:46,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:18:50,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:23:54,648 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:23:54,649 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:23:54,650 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:23:54,656 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:18:48.073769+00:00, run_end_date=2024-05-22 01:18:49.315865+00:00, run_duration=1.242096, state=success, executor_state=success, try_number=1, max_tries=2, job_id=327, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 01:15:03.967794+00:00, queued_by_job_id=276, pid=79501
2024-05-22 01:23:54,658 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:18:51.982757+00:00, run_end_date=2024-05-22 01:23:53.886408+00:00, run_duration=301.903651, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=328, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 01:15:03.967794+00:00, queued_by_job_id=276, pid=79525
2024-05-22 01:23:54,659 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:15:06.142070+00:00, run_end_date=2024-05-22 01:18:45.712346+00:00, run_duration=219.570276, state=success, executor_state=success, try_number=1, max_tries=2, job_id=326, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 01:15:03.967794+00:00, queued_by_job_id=276, pid=79353
2024-05-22 01:23:54,699 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 01:23:54,726 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-27 00:00:00+00:00, run_after=2023-06-28 00:00:00+00:00
2024-05-22 01:23:54,841 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-19 00:00:00+00:00: scheduled__2023-06-19T00:00:00+00:00, state:running, queued_at: 2024-05-22 00:22:42.282993+00:00. externally triggered: False> failed
2024-05-22 01:23:54,842 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-19 00:00:00+00:00, run_id=scheduled__2023-06-19T00:00:00+00:00, run_start_date=2024-05-22 00:22:42.313169+00:00, run_end_date=2024-05-22 01:23:54.842139+00:00, run_duration=3672.52897, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-19 00:00:00+00:00, data_interval_end=2023-06-20 00:00:00+00:00, dag_hash=1087a84ec0e0269ae1322c70a2f45bc1
2024-05-22 01:23:54,848 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-20 00:00:00+00:00, run_after=2023-06-21 00:00:00+00:00
2024-05-22 01:23:54,861 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-24T00:00:00+00:00 [scheduled]>
2024-05-22 01:23:54,861 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 01:23:54,862 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 01:23:54,863 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 01:23:54,864 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-24T00:00:00+00:00 [scheduled]>
2024-05-22 01:23:54,867 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 01:23:54,867 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:23:54,867 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 01:23:54,868 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:23:54,868 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 01:23:54,869 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:23:54,871 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:29:59,002 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:30:03,733 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:35:08,497 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:35:08,497 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:35:08,497 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:35:08,504 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:30:05.780961+00:00, run_end_date=2024-05-22 01:35:07.800895+00:00, run_duration=302.019934, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=331, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 01:23:54.865138+00:00, queued_by_job_id=276, pid=79988
2024-05-22 01:35:08,504 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:23:56.825635+00:00, run_end_date=2024-05-22 01:29:58.388199+00:00, run_duration=361.562564, state=success, executor_state=success, try_number=1, max_tries=2, job_id=329, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 01:23:54.865138+00:00, queued_by_job_id=276, pid=79724
2024-05-22 01:35:08,505 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:30:01.244615+00:00, run_end_date=2024-05-22 01:30:03.096467+00:00, run_duration=1.851852, state=success, executor_state=success, try_number=1, max_tries=2, job_id=330, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 01:23:54.865138+00:00, queued_by_job_id=276, pid=79958
2024-05-22 01:35:08,580 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 01:35:08,602 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-28 00:00:00+00:00, run_after=2023-06-29 00:00:00+00:00
2024-05-22 01:35:08,728 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-20 00:00:00+00:00: scheduled__2023-06-20T00:00:00+00:00, state:running, queued_at: 2024-05-22 00:31:18.295393+00:00. externally triggered: False> failed
2024-05-22 01:35:08,730 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-20 00:00:00+00:00, run_id=scheduled__2023-06-20T00:00:00+00:00, run_start_date=2024-05-22 00:31:18.308821+00:00, run_end_date=2024-05-22 01:35:08.730410+00:00, run_duration=3830.421589, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-20 00:00:00+00:00, data_interval_end=2023-06-21 00:00:00+00:00, dag_hash=9b2486e081017c7cb5d6bc36e9c47426
2024-05-22 01:35:08,742 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-21 00:00:00+00:00, run_after=2023-06-22 00:00:00+00:00
2024-05-22 01:35:08,753 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-25T00:00:00+00:00 [scheduled]>
2024-05-22 01:35:08,753 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 01:35:08,754 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 01:35:08,754 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 01:35:08,755 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-25T00:00:00+00:00 [scheduled]>
2024-05-22 01:35:08,757 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 01:35:08,758 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:35:08,758 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 01:35:08,758 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:35:08,760 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 01:35:08,760 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:35:08,762 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:36:31,968 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:36:36,205 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:41:41,316 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:41:41,316 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:41:41,316 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:41:41,322 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:35:11.140890+00:00, run_end_date=2024-05-22 01:36:31.218018+00:00, run_duration=80.077128, state=success, executor_state=success, try_number=1, max_tries=2, job_id=332, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 01:35:08.756169+00:00, queued_by_job_id=276, pid=80187
2024-05-22 01:41:41,322 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:36:34.034745+00:00, run_end_date=2024-05-22 01:36:35.373871+00:00, run_duration=1.339126, state=success, executor_state=success, try_number=1, max_tries=2, job_id=333, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 01:35:08.756169+00:00, queued_by_job_id=276, pid=80249
2024-05-22 01:41:41,323 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:36:38.459491+00:00, run_end_date=2024-05-22 01:41:40.699635+00:00, run_duration=302.240144, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=334, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 01:35:08.756169+00:00, queued_by_job_id=276, pid=80273
2024-05-22 01:41:41,357 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 01:41:41,376 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-29 00:00:00+00:00, run_after=2023-06-30 00:00:00+00:00
2024-05-22 01:41:41,471 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-21 00:00:00+00:00: scheduled__2023-06-21T00:00:00+00:00, state:running, queued_at: 2024-05-22 00:40:32.929429+00:00. externally triggered: False> failed
2024-05-22 01:41:41,472 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-21 00:00:00+00:00, run_id=scheduled__2023-06-21T00:00:00+00:00, run_start_date=2024-05-22 00:40:32.944595+00:00, run_end_date=2024-05-22 01:41:41.471932+00:00, run_duration=3668.527337, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-21 00:00:00+00:00, data_interval_end=2023-06-22 00:00:00+00:00, dag_hash=b13dcbe2fa824299184676d4de59e712
2024-05-22 01:41:41,475 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-22 00:00:00+00:00, run_after=2023-06-23 00:00:00+00:00
2024-05-22 01:41:41,486 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
2024-05-22 01:41:41,486 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 01:41:41,486 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 01:41:41,487 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 01:41:41,487 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
2024-05-22 01:41:41,490 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 01:41:41,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:41:41,491 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 01:41:41,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:41:41,492 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 01:41:41,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:41:41,493 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:45:16,661 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:45:20,954 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:50:25,495 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:50:25,495 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:50:25,495 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:50:25,519 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:45:18.843681+00:00, run_end_date=2024-05-22 01:45:20.291217+00:00, run_duration=1.447536, state=success, executor_state=success, try_number=1, max_tries=2, job_id=336, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 01:41:41.489008+00:00, queued_by_job_id=276, pid=80619
2024-05-22 01:50:25,519 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:45:22.905475+00:00, run_end_date=2024-05-22 01:50:24.857760+00:00, run_duration=301.952285, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=337, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 01:41:41.489008+00:00, queued_by_job_id=276, pid=80644
2024-05-22 01:50:25,519 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:41:43.486633+00:00, run_end_date=2024-05-22 01:45:16.008993+00:00, run_duration=212.52236, state=success, executor_state=success, try_number=1, max_tries=2, job_id=335, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 01:41:41.489008+00:00, queued_by_job_id=276, pid=80471
2024-05-22 01:50:25,569 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 01:50:25,606 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-30 00:00:00+00:00, run_after=2023-07-01 00:00:00+00:00
2024-05-22 01:50:25,723 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-22 00:00:00+00:00: scheduled__2023-06-22T00:00:00+00:00, state:running, queued_at: 2024-05-22 00:47:36.165986+00:00. externally triggered: False> failed
2024-05-22 01:50:25,724 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-22 00:00:00+00:00, run_id=scheduled__2023-06-22T00:00:00+00:00, run_start_date=2024-05-22 00:47:36.180153+00:00, run_end_date=2024-05-22 01:50:25.724242+00:00, run_duration=3769.544089, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-22 00:00:00+00:00, data_interval_end=2023-06-23 00:00:00+00:00, dag_hash=8af0637a10e21c0398df657daa831e74
2024-05-22 01:50:25,728 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-23 00:00:00+00:00, run_after=2023-06-24 00:00:00+00:00
2024-05-22 01:50:25,742 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-27T00:00:00+00:00 [scheduled]>
2024-05-22 01:50:25,743 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 01:50:25,744 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 01:50:25,744 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 01:50:25,744 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-27T00:00:00+00:00 [scheduled]>
2024-05-22 01:50:25,748 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 01:50:25,748 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:50:25,749 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 01:50:25,749 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:50:25,749 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 01:50:25,750 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:50:25,751 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:53:03,130 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:53:07,189 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:58:12,030 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:58:12,030 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:58:12,030 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 01:58:12,036 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:53:05.117964+00:00, run_end_date=2024-05-22 01:53:06.489516+00:00, run_duration=1.371552, state=success, executor_state=success, try_number=1, max_tries=2, job_id=339, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 01:50:25.745821+00:00, queued_by_job_id=276, pid=80950
2024-05-22 01:58:12,037 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:53:09.254098+00:00, run_end_date=2024-05-22 01:58:11.349634+00:00, run_duration=302.095536, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=340, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 01:50:25.745821+00:00, queued_by_job_id=276, pid=80974
2024-05-22 01:58:12,037 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:50:27.638165+00:00, run_end_date=2024-05-22 01:53:02.423488+00:00, run_duration=154.785323, state=success, executor_state=success, try_number=1, max_tries=2, job_id=338, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 01:50:25.745821+00:00, queued_by_job_id=276, pid=80843
2024-05-22 01:58:12,072 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 01:58:12,095 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-01 00:00:00+00:00, run_after=2023-07-02 00:00:00+00:00
2024-05-22 01:58:12,215 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-23 00:00:00+00:00: scheduled__2023-06-23T00:00:00+00:00, state:running, queued_at: 2024-05-22 00:57:15.605161+00:00. externally triggered: False> failed
2024-05-22 01:58:12,216 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-23 00:00:00+00:00, run_id=scheduled__2023-06-23T00:00:00+00:00, run_start_date=2024-05-22 00:57:15.619369+00:00, run_end_date=2024-05-22 01:58:12.216082+00:00, run_duration=3656.596713, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-23 00:00:00+00:00, data_interval_end=2023-06-24 00:00:00+00:00, dag_hash=0ada0bdc616154a87052409b5bf1d4a5
2024-05-22 01:58:12,229 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-24 00:00:00+00:00, run_after=2023-06-25 00:00:00+00:00
2024-05-22 01:58:12,251 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
2024-05-22 01:58:12,252 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 01:58:12,252 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 01:58:12,252 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 01:58:12,252 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
2024-05-22 01:58:12,256 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 01:58:12,257 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:58:12,257 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 01:58:12,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:58:12,258 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 01:58:12,259 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 01:58:12,260 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:07:26,344 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:07:30,452 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:12:35,374 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:12:35,375 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:12:35,375 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:12:35,385 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-06-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 01:58:14.226248+00:00, run_end_date=2024-05-22 02:07:25.698819+00:00, run_duration=551.472571, state=success, executor_state=success, try_number=1, max_tries=2, job_id=341, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 01:58:12.254176+00:00, queued_by_job_id=276, pid=81173
2024-05-22 02:12:35,386 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:07:32.464566+00:00, run_end_date=2024-05-22 02:12:34.587008+00:00, run_duration=302.122442, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=343, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 01:58:12.254176+00:00, queued_by_job_id=276, pid=81544
2024-05-22 02:12:35,387 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:07:28.371166+00:00, run_end_date=2024-05-22 02:07:29.681912+00:00, run_duration=1.310746, state=success, executor_state=success, try_number=1, max_tries=2, job_id=342, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 01:58:12.254176+00:00, queued_by_job_id=276, pid=81520
2024-05-22 02:12:35,423 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 02:12:35,445 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-02 00:00:00+00:00, run_after=2023-07-03 00:00:00+00:00
2024-05-22 02:12:35,700 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-24 00:00:00+00:00: scheduled__2023-06-24T00:00:00+00:00, state:running, queued_at: 2024-05-22 01:03:42.085625+00:00. externally triggered: False> failed
2024-05-22 02:12:35,701 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-24 00:00:00+00:00, run_id=scheduled__2023-06-24T00:00:00+00:00, run_start_date=2024-05-22 01:03:42.101028+00:00, run_end_date=2024-05-22 02:12:35.701407+00:00, run_duration=4133.600379, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-24 00:00:00+00:00, data_interval_end=2023-06-25 00:00:00+00:00, dag_hash=a99ba4423c03df060709f52380ff57e9
2024-05-22 02:12:35,705 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-25 00:00:00+00:00, run_after=2023-06-26 00:00:00+00:00
2024-05-22 02:12:35,717 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
2024-05-22 02:12:35,718 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 02:12:35,718 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 02:12:35,718 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 02:12:35,719 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
2024-05-22 02:12:35,723 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 02:12:35,723 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:12:35,723 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 02:12:35,724 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:12:35,724 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 02:12:35,724 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:12:35,726 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:13:48,281 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:13:52,711 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:18:57,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:18:57,595 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:18:57,595 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:18:57,612 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-06-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:13:50.646427+00:00, run_end_date=2024-05-22 02:13:52.027650+00:00, run_duration=1.381223, state=success, executor_state=success, try_number=1, max_tries=2, job_id=345, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 02:12:35.720968+00:00, queued_by_job_id=276, pid=81807
2024-05-22 02:18:57,613 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:12:38.124399+00:00, run_end_date=2024-05-22 02:13:47.618394+00:00, run_duration=69.493995, state=success, executor_state=success, try_number=1, max_tries=2, job_id=344, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 02:12:35.720968+00:00, queued_by_job_id=276, pid=81744
2024-05-22 02:18:57,614 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:13:54.872020+00:00, run_end_date=2024-05-22 02:18:56.969872+00:00, run_duration=302.097852, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=346, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 02:12:35.720968+00:00, queued_by_job_id=276, pid=81831
2024-05-22 02:18:57,659 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 02:18:57,681 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-03 00:00:00+00:00, run_after=2023-07-04 00:00:00+00:00
2024-05-22 02:18:57,772 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-25 00:00:00+00:00: scheduled__2023-06-25T00:00:00+00:00, state:running, queued_at: 2024-05-22 01:15:03.834820+00:00. externally triggered: False> failed
2024-05-22 02:18:57,776 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-25 00:00:00+00:00, run_id=scheduled__2023-06-25T00:00:00+00:00, run_start_date=2024-05-22 01:15:03.855892+00:00, run_end_date=2024-05-22 02:18:57.776765+00:00, run_duration=3833.920873, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-25 00:00:00+00:00, data_interval_end=2023-06-26 00:00:00+00:00, dag_hash=959949975712ff1cb059987193f31073
2024-05-22 02:18:57,783 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-26 00:00:00+00:00, run_after=2023-06-27 00:00:00+00:00
2024-05-22 02:18:57,794 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
2024-05-22 02:18:57,795 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 02:18:57,796 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 02:18:57,797 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 02:18:57,798 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
2024-05-22 02:18:57,803 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 02:18:57,803 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:18:57,804 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 02:18:57,805 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:18:57,806 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 02:18:57,807 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:18:57,809 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:22:06,388 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:22:10,672 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:27:15,625 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:27:15,626 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:27:15,626 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:27:15,648 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-06-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:22:12.556835+00:00, run_end_date=2024-05-22 02:27:14.833994+00:00, run_duration=302.277159, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=349, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 02:18:57.801324+00:00, queued_by_job_id=276, pid=82200
2024-05-22 02:27:15,648 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:18:59.707349+00:00, run_end_date=2024-05-22 02:22:05.690558+00:00, run_duration=185.983209, state=success, executor_state=success, try_number=1, max_tries=2, job_id=347, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 02:18:57.801324+00:00, queued_by_job_id=276, pid=82046
2024-05-22 02:27:15,648 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:22:08.381263+00:00, run_end_date=2024-05-22 02:22:09.818425+00:00, run_duration=1.437162, state=success, executor_state=success, try_number=1, max_tries=2, job_id=348, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 02:18:57.801324+00:00, queued_by_job_id=276, pid=82176
2024-05-22 02:27:15,686 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 02:27:15,709 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-04 00:00:00+00:00, run_after=2023-07-05 00:00:00+00:00
2024-05-22 02:27:15,831 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-26 00:00:00+00:00: scheduled__2023-06-26T00:00:00+00:00, state:running, queued_at: 2024-05-22 01:23:54.716858+00:00. externally triggered: False> failed
2024-05-22 02:27:15,831 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-26 00:00:00+00:00, run_id=scheduled__2023-06-26T00:00:00+00:00, run_start_date=2024-05-22 01:23:54.741991+00:00, run_end_date=2024-05-22 02:27:15.831785+00:00, run_duration=3801.089794, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-26 00:00:00+00:00, data_interval_end=2023-06-27 00:00:00+00:00, dag_hash=efdbc9a0d027d40ddb99d2b919e47338
2024-05-22 02:27:15,835 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-27 00:00:00+00:00, run_after=2023-06-28 00:00:00+00:00
2024-05-22 02:27:15,848 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
2024-05-22 02:27:15,848 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 02:27:15,848 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 02:27:15,848 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 02:27:15,849 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
2024-05-22 02:27:15,853 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 02:27:15,853 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:27:15,854 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 02:27:15,855 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:27:15,856 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 02:27:15,856 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:27:15,858 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:34:16,450 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:34:20,418 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:39:25,230 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:39:25,230 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:39:25,230 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:39:25,235 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:27:17.746088+00:00, run_end_date=2024-05-22 02:34:15.866370+00:00, run_duration=418.120282, state=success, executor_state=success, try_number=1, max_tries=2, job_id=350, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 02:27:15.850553+00:00, queued_by_job_id=276, pid=82402
2024-05-22 02:39:25,236 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:34:18.372150+00:00, run_end_date=2024-05-22 02:34:19.591856+00:00, run_duration=1.219706, state=success, executor_state=success, try_number=1, max_tries=2, job_id=351, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 02:27:15.850553+00:00, queued_by_job_id=276, pid=82670
2024-05-22 02:39:25,236 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:34:22.328135+00:00, run_end_date=2024-05-22 02:39:24.529210+00:00, run_duration=302.201075, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=352, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 02:27:15.850553+00:00, queued_by_job_id=276, pid=82694
2024-05-22 02:39:25,269 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 02:39:25,288 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-05 00:00:00+00:00, run_after=2023-07-06 00:00:00+00:00
2024-05-22 02:39:25,383 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-27 00:00:00+00:00: scheduled__2023-06-27T00:00:00+00:00, state:running, queued_at: 2024-05-22 01:35:08.595359+00:00. externally triggered: False> failed
2024-05-22 02:39:25,383 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-27 00:00:00+00:00, run_id=scheduled__2023-06-27T00:00:00+00:00, run_start_date=2024-05-22 01:35:08.612142+00:00, run_end_date=2024-05-22 02:39:25.383775+00:00, run_duration=3856.771633, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-27 00:00:00+00:00, data_interval_end=2023-06-28 00:00:00+00:00, dag_hash=b0f5f29125d495a57ffb7b379befb0aa
2024-05-22 02:39:25,387 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-28 00:00:00+00:00, run_after=2023-06-29 00:00:00+00:00
2024-05-22 02:39:25,397 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
2024-05-22 02:39:25,397 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 02:39:25,398 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 02:39:25,398 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 02:39:25,398 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
2024-05-22 02:39:25,400 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 02:39:25,400 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:39:25,401 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 02:39:25,401 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:39:25,401 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 02:39:25,401 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:39:25,402 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:41:57,028 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:42:01,198 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:47:06,033 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:47:06,033 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:47:06,033 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:47:06,039 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:41:59.171515+00:00, run_end_date=2024-05-22 02:42:00.479428+00:00, run_duration=1.307913, state=success, executor_state=success, try_number=1, max_tries=2, job_id=354, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 02:39:25.398976+00:00, queued_by_job_id=276, pid=83004
2024-05-22 02:47:06,039 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:42:03.398625+00:00, run_end_date=2024-05-22 02:47:05.410098+00:00, run_duration=302.011473, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=355, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 02:39:25.398976+00:00, queued_by_job_id=276, pid=83029
2024-05-22 02:47:06,040 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:39:27.320809+00:00, run_end_date=2024-05-22 02:41:56.371434+00:00, run_duration=149.050625, state=success, executor_state=success, try_number=1, max_tries=2, job_id=353, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 02:39:25.398976+00:00, queued_by_job_id=276, pid=82896
2024-05-22 02:47:06,073 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 02:47:06,092 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-06 00:00:00+00:00, run_after=2023-07-07 00:00:00+00:00
2024-05-22 02:47:06,185 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-28 00:00:00+00:00: scheduled__2023-06-28T00:00:00+00:00, state:running, queued_at: 2024-05-22 01:41:41.370200+00:00. externally triggered: False> failed
2024-05-22 02:47:06,185 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-28 00:00:00+00:00, run_id=scheduled__2023-06-28T00:00:00+00:00, run_start_date=2024-05-22 01:41:41.383932+00:00, run_end_date=2024-05-22 02:47:06.185693+00:00, run_duration=3924.801761, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-28 00:00:00+00:00, data_interval_end=2023-06-29 00:00:00+00:00, dag_hash=cc74faedfde0eb9c7d5d26792c8a3a34
2024-05-22 02:47:06,189 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-29 00:00:00+00:00, run_after=2023-06-30 00:00:00+00:00
2024-05-22 02:47:06,212 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-03T00:00:00+00:00 [scheduled]>
2024-05-22 02:47:06,213 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 02:47:06,213 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 02:47:06,213 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 02:47:06,214 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-03T00:00:00+00:00 [scheduled]>
2024-05-22 02:47:06,221 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 02:47:06,221 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:47:06,221 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 02:47:06,221 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:47:06,222 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 02:47:06,222 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:47:06,224 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:49:35,329 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:49:38,918 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:54:43,724 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:54:43,724 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:54:43,724 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 02:54:43,729 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:49:40.964913+00:00, run_end_date=2024-05-22 02:54:42.980983+00:00, run_duration=302.01607, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=358, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 02:47:06.215646+00:00, queued_by_job_id=276, pid=83356
2024-05-22 02:54:43,730 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:47:08.069639+00:00, run_end_date=2024-05-22 02:49:34.553694+00:00, run_duration=146.484055, state=success, executor_state=success, try_number=1, max_tries=2, job_id=356, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 02:47:06.215646+00:00, queued_by_job_id=276, pid=83230
2024-05-22 02:54:43,730 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:49:37.041679+00:00, run_end_date=2024-05-22 02:49:38.233315+00:00, run_duration=1.191636, state=success, executor_state=success, try_number=1, max_tries=2, job_id=357, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 02:47:06.215646+00:00, queued_by_job_id=276, pid=83332
2024-05-22 02:54:43,767 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 02:54:43,787 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-07 00:00:00+00:00, run_after=2023-07-08 00:00:00+00:00
2024-05-22 02:54:43,898 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-29 00:00:00+00:00: scheduled__2023-06-29T00:00:00+00:00, state:running, queued_at: 2024-05-22 01:50:25.599119+00:00. externally triggered: False> failed
2024-05-22 02:54:43,898 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-29 00:00:00+00:00, run_id=scheduled__2023-06-29T00:00:00+00:00, run_start_date=2024-05-22 01:50:25.614878+00:00, run_end_date=2024-05-22 02:54:43.898482+00:00, run_duration=3858.283604, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-29 00:00:00+00:00, data_interval_end=2023-06-30 00:00:00+00:00, dag_hash=b287d5680498f51f988b6cff2cec4481
2024-05-22 02:54:43,901 INFO - Setting next_dagrun for extract_311_data_dag to 2023-06-30 00:00:00+00:00, run_after=2023-07-01 00:00:00+00:00
2024-05-22 02:54:43,912 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-04T00:00:00+00:00 [scheduled]>
2024-05-22 02:54:43,913 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 02:54:43,913 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 02:54:43,913 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 02:54:43,913 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-04T00:00:00+00:00 [scheduled]>
2024-05-22 02:54:43,916 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 02:54:43,916 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:54:43,916 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 02:54:43,916 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:54:43,917 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 02:54:43,917 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:54:43,918 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:56:28,804 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 02:56:32,678 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:01:37,183 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:01:37,183 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:01:37,184 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:01:37,202 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:54:45.930819+00:00, run_end_date=2024-05-22 02:56:28.083441+00:00, run_duration=102.152622, state=success, executor_state=success, try_number=1, max_tries=2, job_id=359, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 02:54:43.914378+00:00, queued_by_job_id=276, pid=83561
2024-05-22 03:01:37,203 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:56:30.677345+00:00, run_end_date=2024-05-22 02:56:32.044919+00:00, run_duration=1.367574, state=success, executor_state=success, try_number=1, max_tries=2, job_id=360, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 02:54:43.914378+00:00, queued_by_job_id=276, pid=83645
2024-05-22 03:01:37,203 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 02:56:34.620993+00:00, run_end_date=2024-05-22 03:01:36.565031+00:00, run_duration=301.944038, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=361, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 02:54:43.914378+00:00, queued_by_job_id=276, pid=83669
2024-05-22 03:01:37,236 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 03:01:37,256 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-08 00:00:00+00:00, run_after=2023-07-09 00:00:00+00:00
2024-05-22 03:01:37,340 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-06-30 00:00:00+00:00: scheduled__2023-06-30T00:00:00+00:00, state:running, queued_at: 2024-05-22 01:58:12.088880+00:00. externally triggered: False> failed
2024-05-22 03:01:37,340 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-06-30 00:00:00+00:00, run_id=scheduled__2023-06-30T00:00:00+00:00, run_start_date=2024-05-22 01:58:12.102370+00:00, run_end_date=2024-05-22 03:01:37.340845+00:00, run_duration=3805.238475, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-30 00:00:00+00:00, data_interval_end=2023-07-01 00:00:00+00:00, dag_hash=1f80f759a42962a662ebeb5adf2b0b55
2024-05-22 03:01:37,344 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-01 00:00:00+00:00, run_after=2023-07-02 00:00:00+00:00
2024-05-22 03:01:37,354 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-05T00:00:00+00:00 [scheduled]>
2024-05-22 03:01:37,354 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 03:01:37,354 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 03:01:37,355 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 03:01:37,355 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-05T00:00:00+00:00 [scheduled]>
2024-05-22 03:01:37,357 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 03:01:37,357 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:01:37,357 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 03:01:37,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:01:37,358 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 03:01:37,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:01:37,360 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:06:21,375 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:06:25,061 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:11:29,446 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:11:29,446 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:11:29,447 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:11:29,452 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:01:39.019831+00:00, run_end_date=2024-05-22 03:06:20.696486+00:00, run_duration=281.676655, state=success, executor_state=success, try_number=1, max_tries=2, job_id=362, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 03:01:37.355904+00:00, queued_by_job_id=276, pid=83870
2024-05-22 03:11:29,452 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:06:23.304838+00:00, run_end_date=2024-05-22 03:06:24.446475+00:00, run_duration=1.141637, state=success, executor_state=success, try_number=1, max_tries=2, job_id=363, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 03:01:37.355904+00:00, queued_by_job_id=276, pid=84055
2024-05-22 03:11:29,452 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:06:26.811393+00:00, run_end_date=2024-05-22 03:11:28.849056+00:00, run_duration=302.037663, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=364, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 03:01:37.355904+00:00, queued_by_job_id=276, pid=84079
2024-05-22 03:11:29,484 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 03:11:29,502 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-09 00:00:00+00:00, run_after=2023-07-10 00:00:00+00:00
2024-05-22 03:11:29,598 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-01 00:00:00+00:00: scheduled__2023-07-01T00:00:00+00:00, state:running, queued_at: 2024-05-22 02:12:35.438276+00:00. externally triggered: False> failed
2024-05-22 03:11:29,598 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-01 00:00:00+00:00, run_id=scheduled__2023-07-01T00:00:00+00:00, run_start_date=2024-05-22 02:12:35.457705+00:00, run_end_date=2024-05-22 03:11:29.598762+00:00, run_duration=3534.141057, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-01 00:00:00+00:00, data_interval_end=2023-07-02 00:00:00+00:00, dag_hash=1945cfb5d5f8e3b543fa841c0f792646
2024-05-22 03:11:29,602 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-02 00:00:00+00:00, run_after=2023-07-03 00:00:00+00:00
2024-05-22 03:11:29,613 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-06T00:00:00+00:00 [scheduled]>
2024-05-22 03:11:29,613 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 03:11:29,614 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 03:11:29,614 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 03:11:29,614 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-06T00:00:00+00:00 [scheduled]>
2024-05-22 03:11:29,617 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 03:11:29,617 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:11:29,617 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 03:11:29,617 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:11:29,618 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 03:11:29,618 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:11:29,619 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:13:48,430 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:13:52,864 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:18:57,215 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:18:57,215 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:18:57,215 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:18:57,221 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:11:31.605878+00:00, run_end_date=2024-05-22 03:13:47.799823+00:00, run_duration=136.193945, state=success, executor_state=success, try_number=1, max_tries=2, job_id=365, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 03:11:29.615212+00:00, queued_by_job_id=276, pid=84276
2024-05-22 03:18:57,221 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:13:50.784680+00:00, run_end_date=2024-05-22 03:13:52.168645+00:00, run_duration=1.383965, state=success, executor_state=success, try_number=1, max_tries=2, job_id=366, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 03:11:29.615212+00:00, queued_by_job_id=276, pid=84376
2024-05-22 03:18:57,221 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:13:54.781346+00:00, run_end_date=2024-05-22 03:18:56.608949+00:00, run_duration=301.827603, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=367, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 03:11:29.615212+00:00, queued_by_job_id=276, pid=84400
2024-05-22 03:18:57,254 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 03:18:57,272 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-10 00:00:00+00:00, run_after=2023-07-11 00:00:00+00:00
2024-05-22 03:18:57,362 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-02 00:00:00+00:00: scheduled__2023-07-02T00:00:00+00:00, state:running, queued_at: 2024-05-22 02:18:57.675496+00:00. externally triggered: False> failed
2024-05-22 03:18:57,363 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-02 00:00:00+00:00, run_id=scheduled__2023-07-02T00:00:00+00:00, run_start_date=2024-05-22 02:18:57.689469+00:00, run_end_date=2024-05-22 03:18:57.363020+00:00, run_duration=3599.673551, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-02 00:00:00+00:00, data_interval_end=2023-07-03 00:00:00+00:00, dag_hash=980105246e2a241884d37e2a43978259
2024-05-22 03:18:57,366 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-03 00:00:00+00:00, run_after=2023-07-04 00:00:00+00:00
2024-05-22 03:18:57,375 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-07T00:00:00+00:00 [scheduled]>
2024-05-22 03:18:57,375 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 03:18:57,376 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 03:18:57,376 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 03:18:57,376 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-07T00:00:00+00:00 [scheduled]>
2024-05-22 03:18:57,378 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 03:18:57,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:18:57,379 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 03:18:57,379 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:18:57,379 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 03:18:57,379 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:18:57,381 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:22:20,873 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:22:24,820 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:27:29,154 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:27:29,154 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:27:29,154 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:27:29,159 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:22:22.899944+00:00, run_end_date=2024-05-22 03:22:24.231169+00:00, run_duration=1.331225, state=success, executor_state=success, try_number=1, max_tries=2, job_id=369, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 03:18:57.377049+00:00, queued_by_job_id=276, pid=84742
2024-05-22 03:27:29,160 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:22:26.679432+00:00, run_end_date=2024-05-22 03:27:28.599761+00:00, run_duration=301.920329, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=370, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 03:18:57.377049+00:00, queued_by_job_id=276, pid=84767
2024-05-22 03:27:29,160 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:18:59.171936+00:00, run_end_date=2024-05-22 03:22:20.198813+00:00, run_duration=201.026877, state=success, executor_state=success, try_number=1, max_tries=2, job_id=368, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 03:18:57.377049+00:00, queued_by_job_id=276, pid=84603
2024-05-22 03:27:29,193 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 03:27:29,210 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-11 00:00:00+00:00, run_after=2023-07-12 00:00:00+00:00
2024-05-22 03:27:29,294 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-03 00:00:00+00:00: scheduled__2023-07-03T00:00:00+00:00, state:running, queued_at: 2024-05-22 02:27:15.701955+00:00. externally triggered: False> failed
2024-05-22 03:27:29,294 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-03 00:00:00+00:00, run_id=scheduled__2023-07-03T00:00:00+00:00, run_start_date=2024-05-22 02:27:15.719030+00:00, run_end_date=2024-05-22 03:27:29.294354+00:00, run_duration=3613.575324, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-03 00:00:00+00:00, data_interval_end=2023-07-04 00:00:00+00:00, dag_hash=760d146bddeb4a2ebf81c8fb98f875df
2024-05-22 03:27:29,297 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-04 00:00:00+00:00, run_after=2023-07-05 00:00:00+00:00
2024-05-22 03:27:29,306 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-08T00:00:00+00:00 [scheduled]>
2024-05-22 03:27:29,307 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 03:27:29,307 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 03:27:29,307 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 03:27:29,307 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-08T00:00:00+00:00 [scheduled]>
2024-05-22 03:27:29,309 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 03:27:29,309 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:27:29,310 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 03:27:29,310 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:27:29,310 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 03:27:29,310 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:27:29,312 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:36:18,219 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:36:22,306 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:41:27,109 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:41:27,109 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:41:27,109 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:41:27,127 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:36:24.493933+00:00, run_end_date=2024-05-22 03:41:26.472696+00:00, run_duration=301.978763, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=373, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 03:27:29.308280+00:00, queued_by_job_id=276, pid=85327
2024-05-22 03:41:27,128 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:27:31.361428+00:00, run_end_date=2024-05-22 03:36:17.523702+00:00, run_duration=526.162274, state=success, executor_state=success, try_number=1, max_tries=2, job_id=371, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 03:27:29.308280+00:00, queued_by_job_id=276, pid=84966
2024-05-22 03:41:27,128 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:36:20.312050+00:00, run_end_date=2024-05-22 03:36:21.661755+00:00, run_duration=1.349705, state=success, executor_state=success, try_number=1, max_tries=2, job_id=372, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 03:27:29.308280+00:00, queued_by_job_id=276, pid=85298
2024-05-22 03:41:27,163 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 03:41:27,182 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-12 00:00:00+00:00, run_after=2023-07-13 00:00:00+00:00
2024-05-22 03:41:27,279 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-04 00:00:00+00:00: scheduled__2023-07-04T00:00:00+00:00, state:running, queued_at: 2024-05-22 02:39:25.282601+00:00. externally triggered: False> failed
2024-05-22 03:41:27,279 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-04 00:00:00+00:00, run_id=scheduled__2023-07-04T00:00:00+00:00, run_start_date=2024-05-22 02:39:25.294885+00:00, run_end_date=2024-05-22 03:41:27.279344+00:00, run_duration=3721.984459, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-04 00:00:00+00:00, data_interval_end=2023-07-05 00:00:00+00:00, dag_hash=7357a9f95c5fa9dcae40ed23406786e5
2024-05-22 03:41:27,282 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-05 00:00:00+00:00, run_after=2023-07-06 00:00:00+00:00
2024-05-22 03:41:27,292 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-09T00:00:00+00:00 [scheduled]>
2024-05-22 03:41:27,292 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 03:41:27,293 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 03:41:27,293 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 03:41:27,293 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-09T00:00:00+00:00 [scheduled]>
2024-05-22 03:41:27,295 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 03:41:27,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:41:27,295 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 03:41:27,296 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:41:27,296 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 03:41:27,296 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:41:27,297 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:42:04,650 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:42:08,257 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:47:12,667 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:47:12,667 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:47:12,668 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:47:12,673 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:42:06.449801+00:00, run_end_date=2024-05-22 03:42:07.657194+00:00, run_duration=1.207393, state=success, executor_state=success, try_number=1, max_tries=2, job_id=375, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 03:41:27.294051+00:00, queued_by_job_id=276, pid=85563
2024-05-22 03:47:12,673 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:42:09.965602+00:00, run_end_date=2024-05-22 03:47:12.021558+00:00, run_duration=302.055956, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=376, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 03:41:27.294051+00:00, queued_by_job_id=276, pid=85587
2024-05-22 03:47:12,673 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:41:29.472477+00:00, run_end_date=2024-05-22 03:42:03.955057+00:00, run_duration=34.48258, state=success, executor_state=success, try_number=1, max_tries=2, job_id=374, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 03:41:27.294051+00:00, queued_by_job_id=276, pid=85526
2024-05-22 03:47:12,707 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 03:47:12,726 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-13 00:00:00+00:00, run_after=2023-07-14 00:00:00+00:00
2024-05-22 03:47:12,817 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-05 00:00:00+00:00: scheduled__2023-07-05T00:00:00+00:00, state:running, queued_at: 2024-05-22 02:47:06.086332+00:00. externally triggered: False> failed
2024-05-22 03:47:12,818 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-05 00:00:00+00:00, run_id=scheduled__2023-07-05T00:00:00+00:00, run_start_date=2024-05-22 02:47:06.098901+00:00, run_end_date=2024-05-22 03:47:12.818255+00:00, run_duration=3606.719354, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-05 00:00:00+00:00, data_interval_end=2023-07-06 00:00:00+00:00, dag_hash=c3a0a08f3304f4efaa216d226cd9e31d
2024-05-22 03:47:12,821 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-06 00:00:00+00:00, run_after=2023-07-07 00:00:00+00:00
2024-05-22 03:47:12,832 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-10T00:00:00+00:00 [scheduled]>
2024-05-22 03:47:12,832 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 03:47:12,833 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 03:47:12,833 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 03:47:12,833 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-10T00:00:00+00:00 [scheduled]>
2024-05-22 03:47:12,835 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 03:47:12,835 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:47:12,836 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 03:47:12,836 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:47:12,836 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 03:47:12,836 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:47:12,838 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:54:06,805 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:54:11,217 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:59:15,527 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:59:15,528 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:59:15,528 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 03:59:15,533 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:54:12.914217+00:00, run_end_date=2024-05-22 03:59:14.877184+00:00, run_duration=301.962967, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=379, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 03:47:12.834009+00:00, queued_by_job_id=276, pid=86092
2024-05-22 03:59:15,533 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:47:14.797015+00:00, run_end_date=2024-05-22 03:54:06.148001+00:00, run_duration=411.350986, state=success, executor_state=success, try_number=1, max_tries=2, job_id=377, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 03:47:12.834009+00:00, queued_by_job_id=276, pid=85800
2024-05-22 03:59:15,534 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:54:09.069987+00:00, run_end_date=2024-05-22 03:54:10.481795+00:00, run_duration=1.411808, state=success, executor_state=success, try_number=1, max_tries=2, job_id=378, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 03:47:12.834009+00:00, queued_by_job_id=276, pid=86067
2024-05-22 03:59:15,566 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 03:59:15,586 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-14 00:00:00+00:00, run_after=2023-07-15 00:00:00+00:00
2024-05-22 03:59:15,676 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-06 00:00:00+00:00: scheduled__2023-07-06T00:00:00+00:00, state:running, queued_at: 2024-05-22 02:54:43.780574+00:00. externally triggered: False> failed
2024-05-22 03:59:15,676 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-06 00:00:00+00:00, run_id=scheduled__2023-07-06T00:00:00+00:00, run_start_date=2024-05-22 02:54:43.794937+00:00, run_end_date=2024-05-22 03:59:15.676909+00:00, run_duration=3871.881972, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-06 00:00:00+00:00, data_interval_end=2023-07-07 00:00:00+00:00, dag_hash=544245bd3a8edbdc76b40ff8c2ec50a3
2024-05-22 03:59:15,679 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-07 00:00:00+00:00, run_after=2023-07-08 00:00:00+00:00
2024-05-22 03:59:15,692 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-11T00:00:00+00:00 [scheduled]>
2024-05-22 03:59:15,692 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 03:59:15,692 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 03:59:15,693 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 03:59:15,693 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-11T00:00:00+00:00 [scheduled]>
2024-05-22 03:59:15,695 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 03:59:15,695 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:59:15,695 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 03:59:15,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:59:15,696 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 03:59:15,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 03:59:15,697 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:03:07,196 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:03:11,461 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:08:16,310 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:08:16,311 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:08:16,311 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:08:16,316 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 03:59:17.442894+00:00, run_end_date=2024-05-22 04:03:06.578097+00:00, run_duration=229.135203, state=success, executor_state=success, try_number=1, max_tries=2, job_id=380, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 03:59:15.693815+00:00, queued_by_job_id=276, pid=86290
2024-05-22 04:08:16,317 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:03:09.389698+00:00, run_end_date=2024-05-22 04:03:10.788229+00:00, run_duration=1.398531, state=success, executor_state=success, try_number=1, max_tries=2, job_id=381, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 03:59:15.693815+00:00, queued_by_job_id=276, pid=86470
2024-05-22 04:08:16,317 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:03:13.607664+00:00, run_end_date=2024-05-22 04:08:15.550836+00:00, run_duration=301.943172, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=382, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 03:59:15.693815+00:00, queued_by_job_id=276, pid=86494
2024-05-22 04:08:16,353 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 04:08:16,372 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-15 00:00:00+00:00, run_after=2023-07-16 00:00:00+00:00
2024-05-22 04:08:16,477 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-07 00:00:00+00:00: scheduled__2023-07-07T00:00:00+00:00, state:running, queued_at: 2024-05-22 03:01:37.249287+00:00. externally triggered: False> failed
2024-05-22 04:08:16,477 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-07 00:00:00+00:00, run_id=scheduled__2023-07-07T00:00:00+00:00, run_start_date=2024-05-22 03:01:37.262762+00:00, run_end_date=2024-05-22 04:08:16.477580+00:00, run_duration=3999.214818, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-07 00:00:00+00:00, data_interval_end=2023-07-08 00:00:00+00:00, dag_hash=6cdf639d5c9e005590e39f7bdc5d5f49
2024-05-22 04:08:16,480 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-08 00:00:00+00:00, run_after=2023-07-09 00:00:00+00:00
2024-05-22 04:08:16,492 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-12T00:00:00+00:00 [scheduled]>
2024-05-22 04:08:16,492 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 04:08:16,493 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 04:08:16,493 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 04:08:16,493 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-12T00:00:00+00:00 [scheduled]>
2024-05-22 04:08:16,495 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 04:08:16,495 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:08:16,496 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 04:08:16,496 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:08:16,496 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 04:08:16,497 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:08:16,498 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:12:47,532 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:12:51,119 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:17:55,535 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:17:55,535 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:17:55,535 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:17:55,555 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:08:18.617220+00:00, run_end_date=2024-05-22 04:12:46.908954+00:00, run_duration=268.291734, state=success, executor_state=success, try_number=1, max_tries=2, job_id=383, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 04:08:16.493944+00:00, queued_by_job_id=276, pid=86695
2024-05-22 04:17:55,556 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:12:49.322667+00:00, run_end_date=2024-05-22 04:12:50.558171+00:00, run_duration=1.235504, state=success, executor_state=success, try_number=1, max_tries=2, job_id=384, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 04:08:16.493944+00:00, queued_by_job_id=276, pid=86871
2024-05-22 04:17:55,556 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:12:52.962852+00:00, run_end_date=2024-05-22 04:17:54.910859+00:00, run_duration=301.948007, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=385, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 04:08:16.493944+00:00, queued_by_job_id=276, pid=86895
2024-05-22 04:17:55,590 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 04:17:55,610 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-16 00:00:00+00:00, run_after=2023-07-17 00:00:00+00:00
2024-05-22 04:17:55,702 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-08 00:00:00+00:00: scheduled__2023-07-08T00:00:00+00:00, state:running, queued_at: 2024-05-22 03:11:29.497471+00:00. externally triggered: False> failed
2024-05-22 04:17:55,703 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-08 00:00:00+00:00, run_id=scheduled__2023-07-08T00:00:00+00:00, run_start_date=2024-05-22 03:11:29.510139+00:00, run_end_date=2024-05-22 04:17:55.703127+00:00, run_duration=3986.192988, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-08 00:00:00+00:00, data_interval_end=2023-07-09 00:00:00+00:00, dag_hash=f381077fd42fbba3d3c97476923c3c37
2024-05-22 04:17:55,706 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-09 00:00:00+00:00, run_after=2023-07-10 00:00:00+00:00
2024-05-22 04:17:55,717 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-13T00:00:00+00:00 [scheduled]>
2024-05-22 04:17:55,717 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 04:17:55,717 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 04:17:55,717 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 04:17:55,718 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-13T00:00:00+00:00 [scheduled]>
2024-05-22 04:17:55,720 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 04:17:55,720 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:17:55,720 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 04:17:55,721 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:17:55,721 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 04:17:55,721 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:17:55,722 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:25:59,869 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:26:04,357 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:31:08,849 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:31:08,849 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:31:08,850 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:31:08,855 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:26:02.277657+00:00, run_end_date=2024-05-22 04:26:03.725228+00:00, run_duration=1.447571, state=success, executor_state=success, try_number=1, max_tries=2, job_id=387, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 04:17:55.718634+00:00, queued_by_job_id=276, pid=87401
2024-05-22 04:31:08,855 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:26:06.415302+00:00, run_end_date=2024-05-22 04:31:08.263243+00:00, run_duration=301.847941, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=388, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 04:17:55.718634+00:00, queued_by_job_id=276, pid=87430
2024-05-22 04:31:08,855 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:17:57.683021+00:00, run_end_date=2024-05-22 04:25:59.194389+00:00, run_duration=481.511368, state=success, executor_state=success, try_number=1, max_tries=2, job_id=386, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 04:17:55.718634+00:00, queued_by_job_id=276, pid=87098
2024-05-22 04:31:08,889 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 04:31:08,910 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-17 00:00:00+00:00, run_after=2023-07-18 00:00:00+00:00
2024-05-22 04:31:09,003 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-09 00:00:00+00:00: scheduled__2023-07-09T00:00:00+00:00, state:running, queued_at: 2024-05-22 03:18:57.267047+00:00. externally triggered: False> failed
2024-05-22 04:31:09,004 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-09 00:00:00+00:00, run_id=scheduled__2023-07-09T00:00:00+00:00, run_start_date=2024-05-22 03:18:57.279779+00:00, run_end_date=2024-05-22 04:31:09.004302+00:00, run_duration=4331.724523, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-09 00:00:00+00:00, data_interval_end=2023-07-10 00:00:00+00:00, dag_hash=987ab49e9cc3eaf33b4e54fadba57d4a
2024-05-22 04:31:09,007 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-10 00:00:00+00:00, run_after=2023-07-11 00:00:00+00:00
2024-05-22 04:31:09,018 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-14T00:00:00+00:00 [scheduled]>
2024-05-22 04:31:09,018 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 04:31:09,018 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 04:31:09,018 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 04:31:09,018 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-14T00:00:00+00:00 [scheduled]>
2024-05-22 04:31:09,021 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 04:31:09,021 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:31:09,021 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 04:31:09,021 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:31:09,022 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 04:31:09,022 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:31:09,023 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:34:03,635 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:34:07,843 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:39:12,292 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:39:12,293 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:39:12,293 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:39:12,298 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:34:09.725542+00:00, run_end_date=2024-05-22 04:39:11.682064+00:00, run_duration=301.956522, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=391, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 04:31:09.019479+00:00, queued_by_job_id=276, pid=87771
2024-05-22 04:39:12,299 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:31:11.441172+00:00, run_end_date=2024-05-22 04:34:02.906269+00:00, run_duration=171.465097, state=success, executor_state=success, try_number=1, max_tries=2, job_id=389, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 04:31:09.019479+00:00, queued_by_job_id=276, pid=87630
2024-05-22 04:39:12,299 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:34:05.777681+00:00, run_end_date=2024-05-22 04:34:07.148571+00:00, run_duration=1.37089, state=success, executor_state=success, try_number=1, max_tries=2, job_id=390, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 04:31:09.019479+00:00, queued_by_job_id=276, pid=87746
2024-05-22 04:39:12,333 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 04:39:12,353 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-18 00:00:00+00:00, run_after=2023-07-19 00:00:00+00:00
2024-05-22 04:39:12,447 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-10 00:00:00+00:00: scheduled__2023-07-10T00:00:00+00:00, state:running, queued_at: 2024-05-22 03:27:29.205328+00:00. externally triggered: False> failed
2024-05-22 04:39:12,448 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-10 00:00:00+00:00, run_id=scheduled__2023-07-10T00:00:00+00:00, run_start_date=2024-05-22 03:27:29.217653+00:00, run_end_date=2024-05-22 04:39:12.448223+00:00, run_duration=4303.23057, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-10 00:00:00+00:00, data_interval_end=2023-07-11 00:00:00+00:00, dag_hash=6a18151754e9c86e5a2a04a6e69cf3ee
2024-05-22 04:39:12,451 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-11 00:00:00+00:00, run_after=2023-07-12 00:00:00+00:00
2024-05-22 04:39:12,461 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-15T00:00:00+00:00 [scheduled]>
2024-05-22 04:39:12,461 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 04:39:12,461 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 04:39:12,462 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 04:39:12,462 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-15T00:00:00+00:00 [scheduled]>
2024-05-22 04:39:12,464 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 04:39:12,464 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:39:12,464 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 04:39:12,465 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:39:12,465 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 04:39:12,465 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:39:12,467 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:39:49,059 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:39:52,835 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:44:57,063 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:44:57,063 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:44:57,063 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:44:57,069 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:39:50.951779+00:00, run_end_date=2024-05-22 04:39:52.204379+00:00, run_duration=1.2526, state=success, executor_state=success, try_number=1, max_tries=2, job_id=393, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 04:39:12.462917+00:00, queued_by_job_id=276, pid=88009
2024-05-22 04:44:57,070 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:39:54.585815+00:00, run_end_date=2024-05-22 04:44:56.464187+00:00, run_duration=301.878372, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=394, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 04:39:12.462917+00:00, queued_by_job_id=276, pid=88033
2024-05-22 04:44:57,070 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:39:14.176617+00:00, run_end_date=2024-05-22 04:39:48.430266+00:00, run_duration=34.253649, state=success, executor_state=success, try_number=1, max_tries=2, job_id=392, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 04:39:12.462917+00:00, queued_by_job_id=276, pid=87968
2024-05-22 04:44:57,112 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 04:44:57,132 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-19 00:00:00+00:00, run_after=2023-07-20 00:00:00+00:00
2024-05-22 04:44:57,234 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-11 00:00:00+00:00: scheduled__2023-07-11T00:00:00+00:00, state:running, queued_at: 2024-05-22 03:41:27.175838+00:00. externally triggered: False> failed
2024-05-22 04:44:57,234 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-11 00:00:00+00:00, run_id=scheduled__2023-07-11T00:00:00+00:00, run_start_date=2024-05-22 03:41:27.189392+00:00, run_end_date=2024-05-22 04:44:57.234882+00:00, run_duration=3810.04549, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-11 00:00:00+00:00, data_interval_end=2023-07-12 00:00:00+00:00, dag_hash=b896115bd03ef3e33d4d9f1aea8602f9
2024-05-22 04:44:57,238 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-12 00:00:00+00:00, run_after=2023-07-13 00:00:00+00:00
2024-05-22 04:44:57,251 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-16T00:00:00+00:00 [scheduled]>
2024-05-22 04:44:57,251 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 04:44:57,251 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 04:44:57,251 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 04:44:57,252 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-16T00:00:00+00:00 [scheduled]>
2024-05-22 04:44:57,254 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 04:44:57,254 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:44:57,255 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 04:44:57,255 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:44:57,255 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 04:44:57,255 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:44:57,257 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:46:02,107 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:46:05,972 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:51:10,936 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:51:10,937 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:51:10,937 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:51:10,956 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:46:07.894903+00:00, run_end_date=2024-05-22 04:51:10.073072+00:00, run_duration=302.178169, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=397, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 04:44:57.252925+00:00, queued_by_job_id=276, pid=88313
2024-05-22 04:51:10,957 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:44:59.201319+00:00, run_end_date=2024-05-22 04:46:01.359039+00:00, run_duration=62.15772, state=success, executor_state=success, try_number=1, max_tries=2, job_id=395, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 04:44:57.252925+00:00, queued_by_job_id=276, pid=88230
2024-05-22 04:51:10,957 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:46:04.011838+00:00, run_end_date=2024-05-22 04:46:05.291487+00:00, run_duration=1.279649, state=success, executor_state=success, try_number=1, max_tries=2, job_id=396, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 04:44:57.252925+00:00, queued_by_job_id=276, pid=88288
2024-05-22 04:51:10,993 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 04:51:11,014 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-20 00:00:00+00:00, run_after=2023-07-21 00:00:00+00:00
2024-05-22 04:51:11,106 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-12 00:00:00+00:00: scheduled__2023-07-12T00:00:00+00:00, state:running, queued_at: 2024-05-22 03:47:12.719666+00:00. externally triggered: False> failed
2024-05-22 04:51:11,107 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-12 00:00:00+00:00, run_id=scheduled__2023-07-12T00:00:00+00:00, run_start_date=2024-05-22 03:47:12.733806+00:00, run_end_date=2024-05-22 04:51:11.107275+00:00, run_duration=3838.373469, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-12 00:00:00+00:00, data_interval_end=2023-07-13 00:00:00+00:00, dag_hash=e9cbc45baa6bd5b906edd2c71a3d1645
2024-05-22 04:51:11,110 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-13 00:00:00+00:00, run_after=2023-07-14 00:00:00+00:00
2024-05-22 04:51:11,123 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-17T00:00:00+00:00 [scheduled]>
2024-05-22 04:51:11,123 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 04:51:11,123 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 04:51:11,123 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 04:51:11,124 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-17T00:00:00+00:00 [scheduled]>
2024-05-22 04:51:11,126 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 04:51:11,126 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:51:11,127 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 04:51:11,127 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:51:11,127 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 04:51:11,127 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:51:11,129 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:51:59,929 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:52:04,387 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:57:08,999 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:57:08,999 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:57:08,999 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 04:57:09,014 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:52:02.269147+00:00, run_end_date=2024-05-22 04:52:03.686318+00:00, run_duration=1.417171, state=success, executor_state=success, try_number=1, max_tries=2, job_id=399, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 04:51:11.124803+00:00, queued_by_job_id=276, pid=88560
2024-05-22 04:57:09,016 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:52:06.073444+00:00, run_end_date=2024-05-22 04:57:08.162772+00:00, run_duration=302.089328, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=400, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 04:51:11.124803+00:00, queued_by_job_id=276, pid=88585
2024-05-22 04:57:09,017 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:51:12.910027+00:00, run_end_date=2024-05-22 04:51:59.299090+00:00, run_duration=46.389063, state=success, executor_state=success, try_number=1, max_tries=2, job_id=398, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 04:51:11.124803+00:00, queued_by_job_id=276, pid=88513
2024-05-22 04:57:09,054 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 04:57:09,076 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-21 00:00:00+00:00, run_after=2023-07-22 00:00:00+00:00
2024-05-22 04:57:09,182 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-13 00:00:00+00:00: scheduled__2023-07-13T00:00:00+00:00, state:running, queued_at: 2024-05-22 03:59:15.578924+00:00. externally triggered: False> failed
2024-05-22 04:57:09,182 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-13 00:00:00+00:00, run_id=scheduled__2023-07-13T00:00:00+00:00, run_start_date=2024-05-22 03:59:15.593863+00:00, run_end_date=2024-05-22 04:57:09.182822+00:00, run_duration=3473.588959, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-13 00:00:00+00:00, data_interval_end=2023-07-14 00:00:00+00:00, dag_hash=3f636153d63ec7e2468addeaa9349213
2024-05-22 04:57:09,185 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-14 00:00:00+00:00, run_after=2023-07-15 00:00:00+00:00
2024-05-22 04:57:09,200 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-18T00:00:00+00:00 [scheduled]>
2024-05-22 04:57:09,200 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 04:57:09,201 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 04:57:09,201 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 04:57:09,201 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-18T00:00:00+00:00 [scheduled]>
2024-05-22 04:57:09,204 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 04:57:09,204 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:57:09,204 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 04:57:09,204 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:57:09,205 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 04:57:09,205 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:57:09,206 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:58:43,633 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 04:58:47,360 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:03:52,239 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:03:52,240 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:03:52,240 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:03:52,246 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:57:11.473208+00:00, run_end_date=2024-05-22 04:58:42.982666+00:00, run_duration=91.509458, state=success, executor_state=success, try_number=1, max_tries=2, job_id=401, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 04:57:09.202249+00:00, queued_by_job_id=276, pid=88797
2024-05-22 05:03:52,247 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:58:45.638469+00:00, run_end_date=2024-05-22 04:58:46.775815+00:00, run_duration=1.137346, state=success, executor_state=success, try_number=1, max_tries=2, job_id=402, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 04:57:09.202249+00:00, queued_by_job_id=276, pid=88874
2024-05-22 05:03:52,247 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 04:58:49.396113+00:00, run_end_date=2024-05-22 05:03:51.458562+00:00, run_duration=302.062449, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=403, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 04:57:09.202249+00:00, queued_by_job_id=276, pid=88898
2024-05-22 05:03:52,283 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 05:03:52,303 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-22 00:00:00+00:00, run_after=2023-07-23 00:00:00+00:00
2024-05-22 05:03:52,402 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-14 00:00:00+00:00: scheduled__2023-07-14T00:00:00+00:00, state:running, queued_at: 2024-05-22 04:08:16.365903+00:00. externally triggered: False> failed
2024-05-22 05:03:52,403 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-14 00:00:00+00:00, run_id=scheduled__2023-07-14T00:00:00+00:00, run_start_date=2024-05-22 04:08:16.380422+00:00, run_end_date=2024-05-22 05:03:52.403327+00:00, run_duration=3336.022905, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-14 00:00:00+00:00, data_interval_end=2023-07-15 00:00:00+00:00, dag_hash=9a6b59c907e501b15c00fa845118b1f3
2024-05-22 05:03:52,407 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-15 00:00:00+00:00, run_after=2023-07-16 00:00:00+00:00
2024-05-22 05:03:52,420 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-19T00:00:00+00:00 [scheduled]>
2024-05-22 05:03:52,420 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 05:03:52,420 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 05:03:52,421 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 05:03:52,421 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-19T00:00:00+00:00 [scheduled]>
2024-05-22 05:03:52,423 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 05:03:52,423 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:03:52,424 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 05:03:52,424 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:03:52,424 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 05:03:52,424 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:03:52,426 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:07:17,204 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:07:21,617 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:12:26,244 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:12:26,245 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:12:26,245 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:12:26,250 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:03:54.345485+00:00, run_end_date=2024-05-22 05:07:16.520829+00:00, run_duration=202.175344, state=success, executor_state=success, try_number=1, max_tries=2, job_id=404, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 05:03:52.421884+00:00, queued_by_job_id=276, pid=89096
2024-05-22 05:12:26,250 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:07:19.530991+00:00, run_end_date=2024-05-22 05:07:20.953827+00:00, run_duration=1.422836, state=success, executor_state=success, try_number=1, max_tries=2, job_id=405, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 05:03:52.421884+00:00, queued_by_job_id=276, pid=89234
2024-05-22 05:12:26,250 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:07:23.625222+00:00, run_end_date=2024-05-22 05:12:25.555626+00:00, run_duration=301.930404, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=406, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 05:03:52.421884+00:00, queued_by_job_id=276, pid=89258
2024-05-22 05:12:26,285 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 05:12:26,304 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-23 00:00:00+00:00, run_after=2023-07-24 00:00:00+00:00
2024-05-22 05:12:26,402 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-15 00:00:00+00:00: scheduled__2023-07-15T00:00:00+00:00, state:running, queued_at: 2024-05-22 04:17:55.604167+00:00. externally triggered: False> failed
2024-05-22 05:12:26,402 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-15 00:00:00+00:00, run_id=scheduled__2023-07-15T00:00:00+00:00, run_start_date=2024-05-22 04:17:55.618108+00:00, run_end_date=2024-05-22 05:12:26.402365+00:00, run_duration=3270.784257, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-15 00:00:00+00:00, data_interval_end=2023-07-16 00:00:00+00:00, dag_hash=eb55b1a427e4a5d0368183dd6c8c5798
2024-05-22 05:12:26,405 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-16 00:00:00+00:00, run_after=2023-07-17 00:00:00+00:00
2024-05-22 05:12:26,416 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-20T00:00:00+00:00 [scheduled]>
2024-05-22 05:12:26,417 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 05:12:26,417 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 05:12:26,417 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 05:12:26,417 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-20T00:00:00+00:00 [scheduled]>
2024-05-22 05:12:26,419 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 05:12:26,419 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:12:26,420 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 05:12:26,420 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:12:26,420 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 05:12:26,420 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:12:26,421 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:13:44,920 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:13:48,651 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:18:53,321 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:18:53,322 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:18:53,322 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:18:53,329 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:12:28.238961+00:00, run_end_date=2024-05-22 05:13:44.300867+00:00, run_duration=76.061906, state=success, executor_state=success, try_number=1, max_tries=2, job_id=407, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 05:12:26.418086+00:00, queued_by_job_id=276, pid=89458
2024-05-22 05:18:53,330 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:13:46.596911+00:00, run_end_date=2024-05-22 05:13:48.056161+00:00, run_duration=1.45925, state=success, executor_state=success, try_number=1, max_tries=2, job_id=408, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 05:12:26.418086+00:00, queued_by_job_id=276, pid=89518
2024-05-22 05:18:53,330 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:13:50.471515+00:00, run_end_date=2024-05-22 05:18:52.555604+00:00, run_duration=302.084089, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=409, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 05:12:26.418086+00:00, queued_by_job_id=276, pid=89546
2024-05-22 05:18:53,365 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 05:18:53,384 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-24 00:00:00+00:00, run_after=2023-07-25 00:00:00+00:00
2024-05-22 05:18:53,515 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-16 00:00:00+00:00: scheduled__2023-07-16T00:00:00+00:00, state:running, queued_at: 2024-05-22 04:31:08.903097+00:00. externally triggered: False> failed
2024-05-22 05:18:53,516 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-16 00:00:00+00:00, run_id=scheduled__2023-07-16T00:00:00+00:00, run_start_date=2024-05-22 04:31:08.917802+00:00, run_end_date=2024-05-22 05:18:53.516253+00:00, run_duration=2864.598451, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-16 00:00:00+00:00, data_interval_end=2023-07-17 00:00:00+00:00, dag_hash=82afde47e5caec6d1bf8c825244411db
2024-05-22 05:18:53,519 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-17 00:00:00+00:00, run_after=2023-07-18 00:00:00+00:00
2024-05-22 05:18:53,529 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-21T00:00:00+00:00 [scheduled]>
2024-05-22 05:18:53,530 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 05:18:53,530 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 05:18:53,530 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 05:18:53,530 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-21T00:00:00+00:00 [scheduled]>
2024-05-22 05:18:53,532 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 05:18:53,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:18:53,533 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 05:18:53,533 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:18:53,534 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 05:18:53,534 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:18:53,536 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:21:34,381 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:21:38,171 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:26:43,092 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:26:43,092 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:26:43,093 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:26:43,119 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:18:55.330512+00:00, run_end_date=2024-05-22 05:21:33.669351+00:00, run_duration=158.338839, state=success, executor_state=success, try_number=1, max_tries=2, job_id=410, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 05:18:53.531266+00:00, queued_by_job_id=276, pid=89753
2024-05-22 05:26:43,119 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:21:36.165119+00:00, run_end_date=2024-05-22 05:21:37.521892+00:00, run_duration=1.356773, state=success, executor_state=success, try_number=1, max_tries=2, job_id=411, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 05:18:53.531266+00:00, queued_by_job_id=276, pid=89880
2024-05-22 05:26:43,119 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:21:40.377149+00:00, run_end_date=2024-05-22 05:26:42.438939+00:00, run_duration=302.06179, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=412, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 05:18:53.531266+00:00, queued_by_job_id=276, pid=89904
2024-05-22 05:26:43,156 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 05:26:43,189 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-25 00:00:00+00:00, run_after=2023-07-26 00:00:00+00:00
2024-05-22 05:26:43,343 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-17 00:00:00+00:00: scheduled__2023-07-17T00:00:00+00:00, state:running, queued_at: 2024-05-22 04:39:12.346099+00:00. externally triggered: False> failed
2024-05-22 05:26:43,343 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-17 00:00:00+00:00, run_id=scheduled__2023-07-17T00:00:00+00:00, run_start_date=2024-05-22 04:39:12.361517+00:00, run_end_date=2024-05-22 05:26:43.343609+00:00, run_duration=2850.982092, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-17 00:00:00+00:00, data_interval_end=2023-07-18 00:00:00+00:00, dag_hash=8f9865db25052bc213208df4799506fc
2024-05-22 05:26:43,347 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-18 00:00:00+00:00, run_after=2023-07-19 00:00:00+00:00
2024-05-22 05:26:43,359 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-22T00:00:00+00:00 [scheduled]>
2024-05-22 05:26:43,360 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 05:26:43,360 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 05:26:43,360 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 05:26:43,360 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-22T00:00:00+00:00 [scheduled]>
2024-05-22 05:26:43,362 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 05:26:43,362 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:26:43,363 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 05:26:43,363 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:26:43,363 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 05:26:43,363 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:26:43,365 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:29:31,268 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:29:35,089 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:34:39,640 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:34:39,641 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:34:39,641 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:34:39,646 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:29:33.162082+00:00, run_end_date=2024-05-22 05:29:34.434373+00:00, run_duration=1.272291, state=success, executor_state=success, try_number=1, max_tries=2, job_id=414, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 05:26:43.361140+00:00, queued_by_job_id=276, pid=90225
2024-05-22 05:34:39,647 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:29:36.982973+00:00, run_end_date=2024-05-22 05:34:38.968388+00:00, run_duration=301.985415, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=415, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 05:26:43.361140+00:00, queued_by_job_id=276, pid=90249
2024-05-22 05:34:39,647 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:26:45.462133+00:00, run_end_date=2024-05-22 05:29:30.608529+00:00, run_duration=165.146396, state=success, executor_state=success, try_number=1, max_tries=2, job_id=413, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 05:26:43.361140+00:00, queued_by_job_id=276, pid=90108
2024-05-22 05:34:39,681 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 05:34:39,701 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-26 00:00:00+00:00, run_after=2023-07-27 00:00:00+00:00
2024-05-22 05:34:39,796 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-18 00:00:00+00:00: scheduled__2023-07-18T00:00:00+00:00, state:running, queued_at: 2024-05-22 04:44:57.126079+00:00. externally triggered: False> failed
2024-05-22 05:34:39,797 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-18 00:00:00+00:00, run_id=scheduled__2023-07-18T00:00:00+00:00, run_start_date=2024-05-22 04:44:57.140423+00:00, run_end_date=2024-05-22 05:34:39.797164+00:00, run_duration=2982.656741, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-18 00:00:00+00:00, data_interval_end=2023-07-19 00:00:00+00:00, dag_hash=17084e52edd963e83fe00846b9f15785
2024-05-22 05:34:39,800 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-19 00:00:00+00:00, run_after=2023-07-20 00:00:00+00:00
2024-05-22 05:34:39,811 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-23T00:00:00+00:00 [scheduled]>
2024-05-22 05:34:39,811 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 05:34:39,811 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 05:34:39,811 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 05:34:39,811 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-23T00:00:00+00:00 [scheduled]>
2024-05-22 05:34:39,813 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 05:34:39,814 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:34:39,814 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 05:34:39,814 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:34:39,814 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 05:34:39,815 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:34:39,816 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:37:09,045 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:37:13,288 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:42:17,847 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:42:17,848 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:42:17,848 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:42:17,854 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:37:15.343443+00:00, run_end_date=2024-05-22 05:42:17.213116+00:00, run_duration=301.869673, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=418, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 05:34:39.812467+00:00, queued_by_job_id=276, pid=90580
2024-05-22 05:42:17,854 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:34:41.959379+00:00, run_end_date=2024-05-22 05:37:08.327394+00:00, run_duration=146.368015, state=success, executor_state=success, try_number=1, max_tries=2, job_id=416, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 05:34:39.812467+00:00, queued_by_job_id=276, pid=90449
2024-05-22 05:42:17,854 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:37:11.208197+00:00, run_end_date=2024-05-22 05:37:12.587875+00:00, run_duration=1.379678, state=success, executor_state=success, try_number=1, max_tries=2, job_id=417, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 05:34:39.812467+00:00, queued_by_job_id=276, pid=90556
2024-05-22 05:42:17,889 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 05:42:17,910 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-27 00:00:00+00:00, run_after=2023-07-28 00:00:00+00:00
2024-05-22 05:42:18,008 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-19 00:00:00+00:00: scheduled__2023-07-19T00:00:00+00:00, state:running, queued_at: 2024-05-22 04:51:11.006999+00:00. externally triggered: False> failed
2024-05-22 05:42:18,009 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-19 00:00:00+00:00, run_id=scheduled__2023-07-19T00:00:00+00:00, run_start_date=2024-05-22 04:51:11.021358+00:00, run_end_date=2024-05-22 05:42:18.009201+00:00, run_duration=3066.987843, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-19 00:00:00+00:00, data_interval_end=2023-07-20 00:00:00+00:00, dag_hash=e610a78050fb29b9230d7246c3e7abe9
2024-05-22 05:42:18,012 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-20 00:00:00+00:00, run_after=2023-07-21 00:00:00+00:00
2024-05-22 05:42:18,023 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-24T00:00:00+00:00 [scheduled]>
2024-05-22 05:42:18,024 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 05:42:18,024 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 05:42:18,024 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 05:42:18,024 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-24T00:00:00+00:00 [scheduled]>
2024-05-22 05:42:18,026 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 05:42:18,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:42:18,027 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 05:42:18,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:42:18,027 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 05:42:18,028 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:42:18,029 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:44:34,018 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:44:38,192 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:49:42,966 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:49:42,966 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:49:42,966 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:49:42,971 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:42:19.766156+00:00, run_end_date=2024-05-22 05:44:33.405029+00:00, run_duration=133.638873, state=success, executor_state=success, try_number=1, max_tries=2, job_id=419, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 05:42:18.025400+00:00, queued_by_job_id=276, pid=90776
2024-05-22 05:49:42,971 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:44:36.102875+00:00, run_end_date=2024-05-22 05:44:37.490329+00:00, run_duration=1.387454, state=success, executor_state=success, try_number=1, max_tries=2, job_id=420, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 05:42:18.025400+00:00, queued_by_job_id=276, pid=90873
2024-05-22 05:49:42,971 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:44:40.148112+00:00, run_end_date=2024-05-22 05:49:42.330370+00:00, run_duration=302.182258, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=421, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 05:42:18.025400+00:00, queued_by_job_id=276, pid=90897
2024-05-22 05:49:43,007 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 05:49:43,026 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-28 00:00:00+00:00, run_after=2023-07-29 00:00:00+00:00
2024-05-22 05:49:43,194 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-20 00:00:00+00:00: scheduled__2023-07-20T00:00:00+00:00, state:running, queued_at: 2024-05-22 04:57:09.068620+00:00. externally triggered: False> failed
2024-05-22 05:49:43,194 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-20 00:00:00+00:00, run_id=scheduled__2023-07-20T00:00:00+00:00, run_start_date=2024-05-22 04:57:09.084086+00:00, run_end_date=2024-05-22 05:49:43.194487+00:00, run_duration=3154.110401, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-20 00:00:00+00:00, data_interval_end=2023-07-21 00:00:00+00:00, dag_hash=75115cebefe4a0ce951b18341bfac850
2024-05-22 05:49:43,198 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-21 00:00:00+00:00, run_after=2023-07-22 00:00:00+00:00
2024-05-22 05:49:43,209 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-25T00:00:00+00:00 [scheduled]>
2024-05-22 05:49:43,210 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 05:49:43,210 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 05:49:43,210 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 05:49:43,210 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-25T00:00:00+00:00 [scheduled]>
2024-05-22 05:49:43,214 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 05:49:43,214 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:49:43,215 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 05:49:43,215 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:49:43,215 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 05:49:43,215 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:49:43,218 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:52:29,401 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:52:33,811 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:57:38,520 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:57:38,521 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:57:38,521 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 05:57:38,543 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:52:31.629917+00:00, run_end_date=2024-05-22 05:52:33.048624+00:00, run_duration=1.418707, state=success, executor_state=success, try_number=1, max_tries=2, job_id=423, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 05:49:43.212260+00:00, queued_by_job_id=276, pid=91215
2024-05-22 05:57:38,544 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:49:45.407656+00:00, run_end_date=2024-05-22 05:52:28.801131+00:00, run_duration=163.393475, state=success, executor_state=success, try_number=1, max_tries=2, job_id=422, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 05:49:43.212260+00:00, queued_by_job_id=276, pid=91096
2024-05-22 05:57:38,544 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:52:35.771476+00:00, run_end_date=2024-05-22 05:57:37.828124+00:00, run_duration=302.056648, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=424, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 05:49:43.212260+00:00, queued_by_job_id=276, pid=91239
2024-05-22 05:57:38,582 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 05:57:38,603 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-29 00:00:00+00:00, run_after=2023-07-30 00:00:00+00:00
2024-05-22 05:57:38,701 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-21 00:00:00+00:00: scheduled__2023-07-21T00:00:00+00:00, state:running, queued_at: 2024-05-22 05:03:52.297335+00:00. externally triggered: False> failed
2024-05-22 05:57:38,702 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-21 00:00:00+00:00, run_id=scheduled__2023-07-21T00:00:00+00:00, run_start_date=2024-05-22 05:03:52.311322+00:00, run_end_date=2024-05-22 05:57:38.702335+00:00, run_duration=3226.391013, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-21 00:00:00+00:00, data_interval_end=2023-07-22 00:00:00+00:00, dag_hash=55780393153765eb598988ce689d22e1
2024-05-22 05:57:38,705 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-22 00:00:00+00:00, run_after=2023-07-23 00:00:00+00:00
2024-05-22 05:57:38,716 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-26T00:00:00+00:00 [scheduled]>
2024-05-22 05:57:38,716 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 05:57:38,717 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 05:57:38,717 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 05:57:38,717 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-26T00:00:00+00:00 [scheduled]>
2024-05-22 05:57:38,719 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 05:57:38,719 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:57:38,720 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 05:57:38,720 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:57:38,720 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 05:57:38,720 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:57:38,722 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:58:42,659 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 05:58:46,773 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:03:51,448 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:03:51,448 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:03:51,449 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:03:51,458 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:57:40.827668+00:00, run_end_date=2024-05-22 05:58:42.011460+00:00, run_duration=61.183792, state=success, executor_state=success, try_number=1, max_tries=2, job_id=425, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 05:57:38.718271+00:00, queued_by_job_id=276, pid=91438
2024-05-22 06:03:51,459 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:58:48.700698+00:00, run_end_date=2024-05-22 06:03:50.828529+00:00, run_duration=302.127831, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=427, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 05:57:38.718271+00:00, queued_by_job_id=276, pid=91518
2024-05-22 06:03:51,459 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 05:58:44.641961+00:00, run_end_date=2024-05-22 05:58:46.032084+00:00, run_duration=1.390123, state=success, executor_state=success, try_number=1, max_tries=2, job_id=426, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 05:57:38.718271+00:00, queued_by_job_id=276, pid=91493
2024-05-22 06:03:51,502 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 06:03:51,530 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-30 00:00:00+00:00, run_after=2023-07-31 00:00:00+00:00
2024-05-22 06:03:51,664 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-22 00:00:00+00:00: scheduled__2023-07-22T00:00:00+00:00, state:running, queued_at: 2024-05-22 05:12:26.297642+00:00. externally triggered: False> failed
2024-05-22 06:03:51,664 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-22 00:00:00+00:00, run_id=scheduled__2023-07-22T00:00:00+00:00, run_start_date=2024-05-22 05:12:26.310994+00:00, run_end_date=2024-05-22 06:03:51.664840+00:00, run_duration=3085.353846, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-22 00:00:00+00:00, data_interval_end=2023-07-23 00:00:00+00:00, dag_hash=c5afedf8c9dbc680a9114662a3596319
2024-05-22 06:03:51,673 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-23 00:00:00+00:00, run_after=2023-07-24 00:00:00+00:00
2024-05-22 06:03:51,693 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-27T00:00:00+00:00 [scheduled]>
2024-05-22 06:03:51,694 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 06:03:51,694 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 06:03:51,695 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 06:03:51,695 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-27T00:00:00+00:00 [scheduled]>
2024-05-22 06:03:51,698 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 06:03:51,698 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:03:51,699 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 06:03:51,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:03:51,700 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 06:03:51,700 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:03:51,702 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:04:42,255 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:04:46,227 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:09:50,949 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:09:50,949 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:09:50,950 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:09:50,956 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:04:44.175518+00:00, run_end_date=2024-05-22 06:04:45.607353+00:00, run_duration=1.431835, state=success, executor_state=success, try_number=1, max_tries=2, job_id=429, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 06:03:51.695986+00:00, queued_by_job_id=276, pid=91768
2024-05-22 06:09:50,956 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:03:53.755147+00:00, run_end_date=2024-05-22 06:04:41.655357+00:00, run_duration=47.90021, state=success, executor_state=success, try_number=1, max_tries=2, job_id=428, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 06:03:51.695986+00:00, queued_by_job_id=276, pid=91721
2024-05-22 06:09:50,957 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:04:48.169762+00:00, run_end_date=2024-05-22 06:09:50.080289+00:00, run_duration=301.910527, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=430, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 06:03:51.695986+00:00, queued_by_job_id=276, pid=91793
2024-05-22 06:09:51,010 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 06:09:51,035 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-31 00:00:00+00:00, run_after=2023-08-01 00:00:00+00:00
2024-05-22 06:09:51,162 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-23 00:00:00+00:00: scheduled__2023-07-23T00:00:00+00:00, state:running, queued_at: 2024-05-22 05:18:53.378782+00:00. externally triggered: False> failed
2024-05-22 06:09:51,162 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-23 00:00:00+00:00, run_id=scheduled__2023-07-23T00:00:00+00:00, run_start_date=2024-05-22 05:18:53.392210+00:00, run_end_date=2024-05-22 06:09:51.162711+00:00, run_duration=3057.770501, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-23 00:00:00+00:00, data_interval_end=2023-07-24 00:00:00+00:00, dag_hash=e10b41070334e1f6b021e7f929663455
2024-05-22 06:09:51,166 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-24 00:00:00+00:00, run_after=2023-07-25 00:00:00+00:00
2024-05-22 06:09:51,179 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-28T00:00:00+00:00 [scheduled]>
2024-05-22 06:09:51,179 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 06:09:51,179 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 06:09:51,180 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 06:09:51,180 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-28T00:00:00+00:00 [scheduled]>
2024-05-22 06:09:51,182 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 06:09:51,183 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:09:51,183 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 06:09:51,183 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:09:51,184 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 06:09:51,184 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:09:51,185 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:10:36,051 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:10:39,923 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:15:44,537 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:15:44,537 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:15:44,537 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:15:44,543 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:10:41.879655+00:00, run_end_date=2024-05-22 06:15:43.859892+00:00, run_duration=301.980237, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=433, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 06:09:51.181123+00:00, queued_by_job_id=276, pid=92064
2024-05-22 06:15:44,543 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:09:52.994998+00:00, run_end_date=2024-05-22 06:10:35.389062+00:00, run_duration=42.394064, state=success, executor_state=success, try_number=1, max_tries=2, job_id=431, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 06:09:51.181123+00:00, queued_by_job_id=276, pid=91991
2024-05-22 06:15:44,544 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:10:38.018708+00:00, run_end_date=2024-05-22 06:10:39.271497+00:00, run_duration=1.252789, state=success, executor_state=success, try_number=1, max_tries=2, job_id=432, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 06:09:51.181123+00:00, queued_by_job_id=276, pid=92040
2024-05-22 06:15:44,577 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 06:15:44,598 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-01 00:00:00+00:00, run_after=2023-08-02 00:00:00+00:00
2024-05-22 06:15:44,696 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-24 00:00:00+00:00: scheduled__2023-07-24T00:00:00+00:00, state:running, queued_at: 2024-05-22 05:26:43.181015+00:00. externally triggered: False> failed
2024-05-22 06:15:44,696 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-24 00:00:00+00:00, run_id=scheduled__2023-07-24T00:00:00+00:00, run_start_date=2024-05-22 05:26:43.197301+00:00, run_end_date=2024-05-22 06:15:44.696779+00:00, run_duration=2941.499478, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-24 00:00:00+00:00, data_interval_end=2023-07-25 00:00:00+00:00, dag_hash=94466db901abd35f125cd506a132cfc2
2024-05-22 06:15:44,700 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-25 00:00:00+00:00, run_after=2023-07-26 00:00:00+00:00
2024-05-22 06:15:44,711 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-29T00:00:00+00:00 [scheduled]>
2024-05-22 06:15:44,711 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 06:15:44,712 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 06:15:44,712 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 06:15:44,712 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-29T00:00:00+00:00 [scheduled]>
2024-05-22 06:15:44,714 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 06:15:44,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:15:44,715 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 06:15:44,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:15:44,715 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 06:15:44,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:15:44,717 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:18:35,112 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:18:38,869 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:23:43,848 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:23:43,848 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:23:43,848 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:23:43,853 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:18:36.907496+00:00, run_end_date=2024-05-22 06:18:38.142638+00:00, run_duration=1.235142, state=success, executor_state=success, try_number=1, max_tries=2, job_id=435, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 06:15:44.712976+00:00, queued_by_job_id=276, pid=92379
2024-05-22 06:23:43,854 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:18:41.036625+00:00, run_end_date=2024-05-22 06:23:43.202955+00:00, run_duration=302.16633, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=436, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 06:15:44.712976+00:00, queued_by_job_id=276, pid=92403
2024-05-22 06:23:43,854 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-07-31T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:15:46.623035+00:00, run_end_date=2024-05-22 06:18:34.535156+00:00, run_duration=167.912121, state=success, executor_state=success, try_number=1, max_tries=2, job_id=434, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 06:15:44.712976+00:00, queued_by_job_id=276, pid=92263
2024-05-22 06:23:43,886 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 06:23:43,905 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-02 00:00:00+00:00, run_after=2023-08-03 00:00:00+00:00
2024-05-22 06:23:44,009 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-25 00:00:00+00:00: scheduled__2023-07-25T00:00:00+00:00, state:running, queued_at: 2024-05-22 05:34:39.694694+00:00. externally triggered: False> failed
2024-05-22 06:23:44,009 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-25 00:00:00+00:00, run_id=scheduled__2023-07-25T00:00:00+00:00, run_start_date=2024-05-22 05:34:39.708561+00:00, run_end_date=2024-05-22 06:23:44.009418+00:00, run_duration=2944.300857, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-25 00:00:00+00:00, data_interval_end=2023-07-26 00:00:00+00:00, dag_hash=69fb94243831b502e1afff972d917aa0
2024-05-22 06:23:44,012 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-26 00:00:00+00:00, run_after=2023-07-27 00:00:00+00:00
2024-05-22 06:23:44,097 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-30T00:00:00+00:00 [scheduled]>
2024-05-22 06:23:44,097 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 06:23:44,097 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 06:23:44,097 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 06:23:44,098 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-30T00:00:00+00:00 [scheduled]>
2024-05-22 06:23:44,100 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 06:23:44,100 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:23:44,100 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 06:23:44,100 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:23:44,101 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 06:23:44,101 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:23:44,102 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:25:09,740 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:25:13,434 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:30:18,191 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:30:18,191 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:30:18,191 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:30:18,222 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:25:15.415665+00:00, run_end_date=2024-05-22 06:30:17.444493+00:00, run_duration=302.028828, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=439, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 06:23:44.098746+00:00, queued_by_job_id=276, pid=92708
2024-05-22 06:30:18,223 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:23:46.318511+00:00, run_end_date=2024-05-22 06:25:09.075893+00:00, run_duration=82.757382, state=success, executor_state=success, try_number=1, max_tries=2, job_id=437, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 06:23:44.098746+00:00, queued_by_job_id=276, pid=92607
2024-05-22 06:30:18,223 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-07-31T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:25:11.668128+00:00, run_end_date=2024-05-22 06:25:12.800510+00:00, run_duration=1.132382, state=success, executor_state=success, try_number=1, max_tries=2, job_id=438, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 06:23:44.098746+00:00, queued_by_job_id=276, pid=92684
2024-05-22 06:30:18,258 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 06:30:18,279 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-03 00:00:00+00:00, run_after=2023-08-04 00:00:00+00:00
2024-05-22 06:30:18,367 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-26 00:00:00+00:00: scheduled__2023-07-26T00:00:00+00:00, state:running, queued_at: 2024-05-22 05:42:17.903711+00:00. externally triggered: False> failed
2024-05-22 06:30:18,367 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-26 00:00:00+00:00, run_id=scheduled__2023-07-26T00:00:00+00:00, run_start_date=2024-05-22 05:42:17.918398+00:00, run_end_date=2024-05-22 06:30:18.367507+00:00, run_duration=2880.449109, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-26 00:00:00+00:00, data_interval_end=2023-07-27 00:00:00+00:00, dag_hash=aa591f6e9c609c1f0313bdfbff680faa
2024-05-22 06:30:18,370 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-27 00:00:00+00:00, run_after=2023-07-28 00:00:00+00:00
2024-05-22 06:30:18,381 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-31T00:00:00+00:00 [scheduled]>
2024-05-22 06:30:18,381 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 06:30:18,381 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 06:30:18,381 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 06:30:18,382 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-07-31T00:00:00+00:00 [scheduled]>
2024-05-22 06:30:18,384 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 06:30:18,384 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:30:18,384 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 06:30:18,384 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:30:18,385 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 06:30:18,385 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:30:18,386 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:32:38,033 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:32:41,797 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:37:46,237 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:37:46,238 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:37:46,238 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:37:46,251 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:30:20.443008+00:00, run_end_date=2024-05-22 06:32:37.463533+00:00, run_duration=137.020525, state=success, executor_state=success, try_number=1, max_tries=2, job_id=440, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 06:30:18.382652+00:00, queued_by_job_id=276, pid=92907
2024-05-22 06:37:46,252 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:32:39.710334+00:00, run_end_date=2024-05-22 06:32:41.164955+00:00, run_duration=1.454621, state=success, executor_state=success, try_number=1, max_tries=2, job_id=441, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 06:30:18.382652+00:00, queued_by_job_id=276, pid=93021
2024-05-22 06:37:46,252 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-07-31T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:32:43.645051+00:00, run_end_date=2024-05-22 06:37:45.570581+00:00, run_duration=301.92553, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=442, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 06:30:18.382652+00:00, queued_by_job_id=276, pid=93045
2024-05-22 06:37:46,286 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 06:37:46,305 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-04 00:00:00+00:00, run_after=2023-08-05 00:00:00+00:00
2024-05-22 06:37:46,395 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-27 00:00:00+00:00: scheduled__2023-07-27T00:00:00+00:00, state:running, queued_at: 2024-05-22 05:49:43.020784+00:00. externally triggered: False> failed
2024-05-22 06:37:46,395 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-27 00:00:00+00:00, run_id=scheduled__2023-07-27T00:00:00+00:00, run_start_date=2024-05-22 05:49:43.039320+00:00, run_end_date=2024-05-22 06:37:46.395610+00:00, run_duration=2883.35629, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-27 00:00:00+00:00, data_interval_end=2023-07-28 00:00:00+00:00, dag_hash=5f4a633df2695fec55d87fd1c22edd24
2024-05-22 06:37:46,398 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-28 00:00:00+00:00, run_after=2023-07-29 00:00:00+00:00
2024-05-22 06:37:46,408 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-01T00:00:00+00:00 [scheduled]>
2024-05-22 06:37:46,408 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 06:37:46,408 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 06:37:46,408 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 06:37:46,409 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-01T00:00:00+00:00 [scheduled]>
2024-05-22 06:37:46,411 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 06:37:46,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:37:46,411 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 06:37:46,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:37:46,412 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 06:37:46,412 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:37:46,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:38:27,070 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:38:31,238 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:43:35,698 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:43:35,698 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:43:35,699 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:43:35,705 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:38:29.286526+00:00, run_end_date=2024-05-22 06:38:30.487436+00:00, run_duration=1.20091, state=success, executor_state=success, try_number=1, max_tries=2, job_id=444, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 06:37:46.409708+00:00, queued_by_job_id=276, pid=93292
2024-05-22 06:43:35,705 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:38:32.908343+00:00, run_end_date=2024-05-22 06:43:34.916915+00:00, run_duration=302.008572, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=445, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 06:37:46.409708+00:00, queued_by_job_id=276, pid=93316
2024-05-22 06:43:35,705 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:37:48.254629+00:00, run_end_date=2024-05-22 06:38:26.387995+00:00, run_duration=38.133366, state=success, executor_state=success, try_number=1, max_tries=2, job_id=443, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 06:37:46.409708+00:00, queued_by_job_id=276, pid=93249
2024-05-22 06:43:35,738 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 06:43:35,756 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-05 00:00:00+00:00, run_after=2023-08-06 00:00:00+00:00
2024-05-22 06:43:35,840 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-28 00:00:00+00:00: scheduled__2023-07-28T00:00:00+00:00, state:running, queued_at: 2024-05-22 05:57:38.595934+00:00. externally triggered: False> failed
2024-05-22 06:43:35,841 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-28 00:00:00+00:00, run_id=scheduled__2023-07-28T00:00:00+00:00, run_start_date=2024-05-22 05:57:38.611169+00:00, run_end_date=2024-05-22 06:43:35.841086+00:00, run_duration=2757.229917, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-28 00:00:00+00:00, data_interval_end=2023-07-29 00:00:00+00:00, dag_hash=ca7a3944b30b334b1e437e8490c0674f
2024-05-22 06:43:35,844 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-29 00:00:00+00:00, run_after=2023-07-30 00:00:00+00:00
2024-05-22 06:43:35,854 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-02T00:00:00+00:00 [scheduled]>
2024-05-22 06:43:35,854 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 06:43:35,854 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 06:43:35,855 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 06:43:35,855 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-02T00:00:00+00:00 [scheduled]>
2024-05-22 06:43:35,857 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 06:43:35,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:43:35,858 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 06:43:35,858 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:43:35,858 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 06:43:35,858 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:43:35,859 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:45:36,479 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:45:40,446 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:50:45,112 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:50:45,112 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:50:45,112 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 06:50:45,118 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:45:42.472490+00:00, run_end_date=2024-05-22 06:50:44.416078+00:00, run_duration=301.943588, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=448, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 06:43:35.855943+00:00, queued_by_job_id=276, pid=93875
2024-05-22 06:50:45,118 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:43:37.568044+00:00, run_end_date=2024-05-22 06:45:35.843797+00:00, run_duration=118.275753, state=success, executor_state=success, try_number=1, max_tries=2, job_id=446, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 06:43:35.855943+00:00, queued_by_job_id=276, pid=93761
2024-05-22 06:50:45,119 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:45:38.305876+00:00, run_end_date=2024-05-22 06:45:39.678882+00:00, run_duration=1.373006, state=success, executor_state=success, try_number=1, max_tries=2, job_id=447, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 06:43:35.855943+00:00, queued_by_job_id=276, pid=93851
2024-05-22 06:50:45,155 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 06:50:45,182 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-06 00:00:00+00:00, run_after=2023-08-07 00:00:00+00:00
2024-05-22 06:50:45,288 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-29 00:00:00+00:00: scheduled__2023-07-29T00:00:00+00:00, state:running, queued_at: 2024-05-22 06:03:51.521891+00:00. externally triggered: False> failed
2024-05-22 06:50:45,288 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-29 00:00:00+00:00, run_id=scheduled__2023-07-29T00:00:00+00:00, run_start_date=2024-05-22 06:03:51.539511+00:00, run_end_date=2024-05-22 06:50:45.288487+00:00, run_duration=2813.748976, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-29 00:00:00+00:00, data_interval_end=2023-07-30 00:00:00+00:00, dag_hash=ccc755c14ecc5b4887c934fd6fd83f47
2024-05-22 06:50:45,292 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-30 00:00:00+00:00, run_after=2023-07-31 00:00:00+00:00
2024-05-22 06:50:45,308 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-03T00:00:00+00:00 [scheduled]>
2024-05-22 06:50:45,309 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 06:50:45,309 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 06:50:45,309 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 06:50:45,309 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-03T00:00:00+00:00 [scheduled]>
2024-05-22 06:50:45,312 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 06:50:45,312 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:50:45,313 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 06:50:45,313 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:50:45,313 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 06:50:45,313 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:50:45,315 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:55:30,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 06:55:34,398 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:00:38,740 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:00:38,741 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:00:38,741 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:00:38,763 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:50:47.258530+00:00, run_end_date=2024-05-22 06:55:29.659146+00:00, run_duration=282.400616, state=success, executor_state=success, try_number=1, max_tries=2, job_id=449, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 06:50:45.310908+00:00, queued_by_job_id=276, pid=94074
2024-05-22 07:00:38,764 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:55:32.596381+00:00, run_end_date=2024-05-22 06:55:33.754039+00:00, run_duration=1.157658, state=success, executor_state=success, try_number=1, max_tries=2, job_id=450, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 06:50:45.310908+00:00, queued_by_job_id=276, pid=94263
2024-05-22 07:00:38,764 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 06:55:36.160419+00:00, run_end_date=2024-05-22 07:00:38.033649+00:00, run_duration=301.87323, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=451, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 06:50:45.310908+00:00, queued_by_job_id=276, pid=94287
2024-05-22 07:00:38,816 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 07:00:38,852 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-07 00:00:00+00:00, run_after=2023-08-08 00:00:00+00:00
2024-05-22 07:00:38,968 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-30 00:00:00+00:00: scheduled__2023-07-30T00:00:00+00:00, state:running, queued_at: 2024-05-22 06:09:51.027671+00:00. externally triggered: False> failed
2024-05-22 07:00:38,968 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-30 00:00:00+00:00, run_id=scheduled__2023-07-30T00:00:00+00:00, run_start_date=2024-05-22 06:09:51.044663+00:00, run_end_date=2024-05-22 07:00:38.968494+00:00, run_duration=3047.923831, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-30 00:00:00+00:00, data_interval_end=2023-07-31 00:00:00+00:00, dag_hash=37943905a0f0f95417c7544a46474bc6
2024-05-22 07:00:38,972 INFO - Setting next_dagrun for extract_311_data_dag to 2023-07-31 00:00:00+00:00, run_after=2023-08-01 00:00:00+00:00
2024-05-22 07:00:38,985 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-04T00:00:00+00:00 [scheduled]>
2024-05-22 07:00:38,986 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 07:00:38,986 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 07:00:38,986 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 07:00:38,986 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-04T00:00:00+00:00 [scheduled]>
2024-05-22 07:00:38,989 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 07:00:38,989 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:00:38,990 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 07:00:38,990 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:00:38,990 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 07:00:38,990 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:00:38,992 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:05:33,691 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:05:37,432 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:10:42,087 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:10:42,088 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:10:42,088 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:10:42,093 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:05:35.585522+00:00, run_end_date=2024-05-22 07:05:36.742678+00:00, run_duration=1.157156, state=success, executor_state=success, try_number=1, max_tries=2, job_id=453, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 07:00:38.987670+00:00, queued_by_job_id=276, pid=94681
2024-05-22 07:10:42,093 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:00:41.242940+00:00, run_end_date=2024-05-22 07:05:33.030380+00:00, run_duration=291.78744, state=success, executor_state=success, try_number=1, max_tries=2, job_id=452, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 07:00:38.987670+00:00, queued_by_job_id=276, pid=94487
2024-05-22 07:10:42,094 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:05:39.414088+00:00, run_end_date=2024-05-22 07:10:41.488346+00:00, run_duration=302.074258, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=454, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 07:00:38.987670+00:00, queued_by_job_id=276, pid=94705
2024-05-22 07:10:42,130 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 07:10:42,152 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-08 00:00:00+00:00, run_after=2023-08-09 00:00:00+00:00
2024-05-22 07:10:42,257 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-07-31 00:00:00+00:00: scheduled__2023-07-31T00:00:00+00:00, state:running, queued_at: 2024-05-22 06:15:44.591610+00:00. externally triggered: False> failed
2024-05-22 07:10:42,257 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-07-31 00:00:00+00:00, run_id=scheduled__2023-07-31T00:00:00+00:00, run_start_date=2024-05-22 06:15:44.604596+00:00, run_end_date=2024-05-22 07:10:42.257650+00:00, run_duration=3297.653054, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:00:00+00:00, data_interval_end=2023-08-01 00:00:00+00:00, dag_hash=e163f6de294c1631b4ce07656c55024e
2024-05-22 07:10:42,261 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-01 00:00:00+00:00, run_after=2023-08-02 00:00:00+00:00
2024-05-22 07:10:42,272 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-05T00:00:00+00:00 [scheduled]>
2024-05-22 07:10:42,272 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 07:10:42,272 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 07:10:42,273 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 07:10:42,273 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-05T00:00:00+00:00 [scheduled]>
2024-05-22 07:10:42,275 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 07:10:42,276 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:10:42,276 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 07:10:42,276 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:10:42,277 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 07:10:42,277 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:10:42,279 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:12:30,322 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:12:34,415 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:17:38,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:17:38,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:17:38,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:17:38,796 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:12:36.268751+00:00, run_end_date=2024-05-22 07:17:38.154485+00:00, run_duration=301.885734, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=457, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 07:10:42.274007+00:00, queued_by_job_id=276, pid=95397
2024-05-22 07:17:38,796 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:10:44.123756+00:00, run_end_date=2024-05-22 07:12:29.657032+00:00, run_duration=105.533276, state=success, executor_state=success, try_number=1, max_tries=2, job_id=455, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 07:10:42.274007+00:00, queued_by_job_id=276, pid=95291
2024-05-22 07:17:38,796 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:12:32.514998+00:00, run_end_date=2024-05-22 07:12:33.712739+00:00, run_duration=1.197741, state=success, executor_state=success, try_number=1, max_tries=2, job_id=456, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 07:10:42.274007+00:00, queued_by_job_id=276, pid=95373
2024-05-22 07:17:38,829 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 07:17:38,849 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-09 00:00:00+00:00, run_after=2023-08-10 00:00:00+00:00
2024-05-22 07:17:38,942 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-01 00:00:00+00:00: scheduled__2023-08-01T00:00:00+00:00, state:running, queued_at: 2024-05-22 06:23:43.898988+00:00. externally triggered: False> failed
2024-05-22 07:17:38,943 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-01 00:00:00+00:00, run_id=scheduled__2023-08-01T00:00:00+00:00, run_start_date=2024-05-22 06:23:43.911371+00:00, run_end_date=2024-05-22 07:17:38.943021+00:00, run_duration=3235.03165, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-01 00:00:00+00:00, data_interval_end=2023-08-02 00:00:00+00:00, dag_hash=340531841b82658bef75dfc30191a8fc
2024-05-22 07:17:38,946 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-02 00:00:00+00:00, run_after=2023-08-03 00:00:00+00:00
2024-05-22 07:17:38,957 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-06T00:00:00+00:00 [scheduled]>
2024-05-22 07:17:38,957 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 07:17:38,958 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 07:17:38,958 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 07:17:38,958 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-06T00:00:00+00:00 [scheduled]>
2024-05-22 07:17:38,960 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 07:17:38,961 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:17:38,961 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 07:17:38,961 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:17:38,962 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 07:17:38,962 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:17:38,963 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:18:32,261 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:18:36,570 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:23:40,917 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:23:40,918 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:23:40,918 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:23:40,923 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:17:40.756493+00:00, run_end_date=2024-05-22 07:18:31.618852+00:00, run_duration=50.862359, state=success, executor_state=success, try_number=1, max_tries=2, job_id=458, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 07:17:38.959421+00:00, queued_by_job_id=276, pid=95600
2024-05-22 07:23:40,923 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:18:34.619054+00:00, run_end_date=2024-05-22 07:18:35.922323+00:00, run_duration=1.303269, state=success, executor_state=success, try_number=1, max_tries=2, job_id=459, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 07:17:38.959421+00:00, queued_by_job_id=276, pid=95651
2024-05-22 07:23:40,924 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:18:38.343453+00:00, run_end_date=2024-05-22 07:23:40.318753+00:00, run_duration=301.9753, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=460, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 07:17:38.959421+00:00, queued_by_job_id=276, pid=95675
2024-05-22 07:23:40,960 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 07:23:40,983 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-10 00:00:00+00:00, run_after=2023-08-11 00:00:00+00:00
2024-05-22 07:23:41,198 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-02 00:00:00+00:00: scheduled__2023-08-02T00:00:00+00:00, state:running, queued_at: 2024-05-22 06:30:18.271789+00:00. externally triggered: False> failed
2024-05-22 07:23:41,198 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-02 00:00:00+00:00, run_id=scheduled__2023-08-02T00:00:00+00:00, run_start_date=2024-05-22 06:30:18.286127+00:00, run_end_date=2024-05-22 07:23:41.198878+00:00, run_duration=3202.912751, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-02 00:00:00+00:00, data_interval_end=2023-08-03 00:00:00+00:00, dag_hash=f6169325cb4342ec77527336d257a2bf
2024-05-22 07:23:41,202 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-03 00:00:00+00:00, run_after=2023-08-04 00:00:00+00:00
2024-05-22 07:23:41,213 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-07T00:00:00+00:00 [scheduled]>
2024-05-22 07:23:41,213 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 07:23:41,214 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 07:23:41,214 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 07:23:41,214 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-07T00:00:00+00:00 [scheduled]>
2024-05-22 07:23:41,217 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 07:23:41,217 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:23:41,218 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 07:23:41,218 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:23:41,218 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 07:23:41,219 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:23:41,220 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:24:48,765 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:24:52,199 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:29:56,586 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:29:56,586 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:29:56,586 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:29:56,591 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:23:42.862399+00:00, run_end_date=2024-05-22 07:24:48.155423+00:00, run_duration=65.293024, state=success, executor_state=success, try_number=1, max_tries=2, job_id=461, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 07:23:41.215656+00:00, queued_by_job_id=276, pid=95874
2024-05-22 07:29:56,592 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:24:50.386587+00:00, run_end_date=2024-05-22 07:24:51.635888+00:00, run_duration=1.249301, state=success, executor_state=success, try_number=1, max_tries=2, job_id=462, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 07:23:41.215656+00:00, queued_by_job_id=276, pid=95930
2024-05-22 07:29:56,592 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:24:54.039440+00:00, run_end_date=2024-05-22 07:29:55.913496+00:00, run_duration=301.874056, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=463, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 07:23:41.215656+00:00, queued_by_job_id=276, pid=95954
2024-05-22 07:29:56,633 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 07:29:56,659 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-11 00:00:00+00:00, run_after=2023-08-12 00:00:00+00:00
2024-05-22 07:29:56,759 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-03 00:00:00+00:00: scheduled__2023-08-03T00:00:00+00:00, state:running, queued_at: 2024-05-22 06:37:46.299226+00:00. externally triggered: False> failed
2024-05-22 07:29:56,759 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-03 00:00:00+00:00, run_id=scheduled__2023-08-03T00:00:00+00:00, run_start_date=2024-05-22 06:37:46.312241+00:00, run_end_date=2024-05-22 07:29:56.759741+00:00, run_duration=3130.4475, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-03 00:00:00+00:00, data_interval_end=2023-08-04 00:00:00+00:00, dag_hash=fb3b748337b9fbde7eb2929ec4687d8b
2024-05-22 07:29:56,763 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-04 00:00:00+00:00, run_after=2023-08-05 00:00:00+00:00
2024-05-22 07:29:56,775 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-08T00:00:00+00:00 [scheduled]>
2024-05-22 07:29:56,776 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 07:29:56,776 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 07:29:56,776 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 07:29:56,776 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-08T00:00:00+00:00 [scheduled]>
2024-05-22 07:29:56,779 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 07:29:56,779 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:29:56,780 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 07:29:56,780 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:29:56,780 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 07:29:56,780 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:29:56,782 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:30:49,611 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:30:53,410 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:35:57,814 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:35:57,814 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:35:57,815 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:35:57,835 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:29:58.838105+00:00, run_end_date=2024-05-22 07:30:48.940860+00:00, run_duration=50.102755, state=success, executor_state=success, try_number=1, max_tries=2, job_id=464, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 07:29:56.777525+00:00, queued_by_job_id=276, pid=96154
2024-05-22 07:35:57,835 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:30:51.620730+00:00, run_end_date=2024-05-22 07:30:52.799451+00:00, run_duration=1.178721, state=success, executor_state=success, try_number=1, max_tries=2, job_id=465, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 07:29:56.777525+00:00, queued_by_job_id=276, pid=96206
2024-05-22 07:35:57,835 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:30:55.147292+00:00, run_end_date=2024-05-22 07:35:57.118016+00:00, run_duration=301.970724, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=466, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 07:29:56.777525+00:00, queued_by_job_id=276, pid=96230
2024-05-22 07:35:57,871 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 07:35:57,893 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-12 00:00:00+00:00, run_after=2023-08-13 00:00:00+00:00
2024-05-22 07:35:57,990 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-04 00:00:00+00:00: scheduled__2023-08-04T00:00:00+00:00, state:running, queued_at: 2024-05-22 06:43:35.750888+00:00. externally triggered: False> failed
2024-05-22 07:35:57,990 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-04 00:00:00+00:00, run_id=scheduled__2023-08-04T00:00:00+00:00, run_start_date=2024-05-22 06:43:35.762711+00:00, run_end_date=2024-05-22 07:35:57.990862+00:00, run_duration=3142.228151, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-04 00:00:00+00:00, data_interval_end=2023-08-05 00:00:00+00:00, dag_hash=e8c168f81c81ca54f64c963ac5fb901c
2024-05-22 07:35:57,994 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-05 00:00:00+00:00, run_after=2023-08-06 00:00:00+00:00
2024-05-22 07:35:58,009 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-09T00:00:00+00:00 [scheduled]>
2024-05-22 07:35:58,009 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 07:35:58,010 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 07:35:58,010 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 07:35:58,010 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-09T00:00:00+00:00 [scheduled]>
2024-05-22 07:35:58,013 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 07:35:58,013 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:35:58,014 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 07:35:58,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:35:58,015 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 07:35:58,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:35:58,017 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:41:14,928 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:41:18,621 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:46:23,021 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:46:23,021 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:46:23,022 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:46:23,027 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:41:16.782294+00:00, run_end_date=2024-05-22 07:41:17.956950+00:00, run_duration=1.174656, state=success, executor_state=success, try_number=1, max_tries=2, job_id=468, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 07:35:58.011602+00:00, queued_by_job_id=276, pid=96635
2024-05-22 07:46:23,027 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:41:20.273360+00:00, run_end_date=2024-05-22 07:46:22.323695+00:00, run_duration=302.050335, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=469, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 07:35:58.011602+00:00, queued_by_job_id=276, pid=96659
2024-05-22 07:46:23,028 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:36:00.120027+00:00, run_end_date=2024-05-22 07:41:14.210550+00:00, run_duration=314.090523, state=success, executor_state=success, try_number=1, max_tries=2, job_id=467, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 07:35:58.011602+00:00, queued_by_job_id=276, pid=96433
2024-05-22 07:46:23,064 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 07:46:23,086 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-13 00:00:00+00:00, run_after=2023-08-14 00:00:00+00:00
2024-05-22 07:46:23,180 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-05 00:00:00+00:00: scheduled__2023-08-05T00:00:00+00:00, state:running, queued_at: 2024-05-22 06:50:45.173068+00:00. externally triggered: False> failed
2024-05-22 07:46:23,180 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-05 00:00:00+00:00, run_id=scheduled__2023-08-05T00:00:00+00:00, run_start_date=2024-05-22 06:50:45.190026+00:00, run_end_date=2024-05-22 07:46:23.180460+00:00, run_duration=3337.990434, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-05 00:00:00+00:00, data_interval_end=2023-08-06 00:00:00+00:00, dag_hash=c0c469fdbb2d43c91fc0b350a571a3db
2024-05-22 07:46:23,184 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-06 00:00:00+00:00, run_after=2023-08-07 00:00:00+00:00
2024-05-22 07:46:23,195 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-10T00:00:00+00:00 [scheduled]>
2024-05-22 07:46:23,195 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 07:46:23,196 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 07:46:23,196 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 07:46:23,196 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-10T00:00:00+00:00 [scheduled]>
2024-05-22 07:46:23,199 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 07:46:23,199 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:46:23,199 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 07:46:23,200 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:46:23,200 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 07:46:23,200 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:46:23,202 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:50:15,686 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:50:19,976 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:55:24,753 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:55:24,753 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:55:24,754 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 07:55:24,776 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:50:21.932481+00:00, run_end_date=2024-05-22 07:55:24.079462+00:00, run_duration=302.146981, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=472, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 07:46:23.197286+00:00, queued_by_job_id=276, pid=97041
2024-05-22 07:55:24,777 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:46:25.043043+00:00, run_end_date=2024-05-22 07:50:15.073012+00:00, run_duration=230.029969, state=success, executor_state=success, try_number=1, max_tries=2, job_id=470, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 07:46:23.197286+00:00, queued_by_job_id=276, pid=96858
2024-05-22 07:55:24,778 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:50:17.758664+00:00, run_end_date=2024-05-22 07:50:19.152506+00:00, run_duration=1.393842, state=success, executor_state=success, try_number=1, max_tries=2, job_id=471, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 07:46:23.197286+00:00, queued_by_job_id=276, pid=97017
2024-05-22 07:55:24,819 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 07:55:24,839 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-14 00:00:00+00:00, run_after=2023-08-15 00:00:00+00:00
2024-05-22 07:55:24,928 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-06 00:00:00+00:00: scheduled__2023-08-06T00:00:00+00:00, state:running, queued_at: 2024-05-22 07:00:38.841709+00:00. externally triggered: False> failed
2024-05-22 07:55:24,929 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-06 00:00:00+00:00, run_id=scheduled__2023-08-06T00:00:00+00:00, run_start_date=2024-05-22 07:00:38.859852+00:00, run_end_date=2024-05-22 07:55:24.929249+00:00, run_duration=3286.069397, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-06 00:00:00+00:00, data_interval_end=2023-08-07 00:00:00+00:00, dag_hash=394eb96a69674ed1e13d43581daa6c9b
2024-05-22 07:55:24,932 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-07 00:00:00+00:00, run_after=2023-08-08 00:00:00+00:00
2024-05-22 07:55:24,943 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-11T00:00:00+00:00 [scheduled]>
2024-05-22 07:55:24,943 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 07:55:24,944 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 07:55:24,944 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 07:55:24,944 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-11T00:00:00+00:00 [scheduled]>
2024-05-22 07:55:24,947 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 07:55:24,947 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:55:24,947 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 07:55:24,947 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:55:24,948 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 07:55:24,948 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:55:24,949 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:56:57,580 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 07:57:01,957 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:02:06,669 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:02:06,670 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:02:06,670 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:02:06,677 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:55:26.705672+00:00, run_end_date=2024-05-22 07:56:56.938838+00:00, run_duration=90.233166, state=success, executor_state=success, try_number=1, max_tries=2, job_id=473, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 07:55:24.945619+00:00, queued_by_job_id=276, pid=97241
2024-05-22 08:02:06,678 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:56:59.735272+00:00, run_end_date=2024-05-22 07:57:01.004764+00:00, run_duration=1.269492, state=success, executor_state=success, try_number=1, max_tries=2, job_id=474, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 07:55:24.945619+00:00, queued_by_job_id=276, pid=97312
2024-05-22 08:02:06,678 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 07:57:04.038355+00:00, run_end_date=2024-05-22 08:02:05.991824+00:00, run_duration=301.953469, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=475, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 07:55:24.945619+00:00, queued_by_job_id=276, pid=97337
2024-05-22 08:02:06,723 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 08:02:06,746 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-15 00:00:00+00:00, run_after=2023-08-16 00:00:00+00:00
2024-05-22 08:02:06,840 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-07 00:00:00+00:00: scheduled__2023-08-07T00:00:00+00:00, state:running, queued_at: 2024-05-22 07:10:42.144839+00:00. externally triggered: False> failed
2024-05-22 08:02:06,841 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-07 00:00:00+00:00, run_id=scheduled__2023-08-07T00:00:00+00:00, run_start_date=2024-05-22 07:10:42.160692+00:00, run_end_date=2024-05-22 08:02:06.841196+00:00, run_duration=3084.680504, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-07 00:00:00+00:00, data_interval_end=2023-08-08 00:00:00+00:00, dag_hash=897cd53f50573a35547a0727215e9424
2024-05-22 08:02:06,844 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-08 00:00:00+00:00, run_after=2023-08-09 00:00:00+00:00
2024-05-22 08:02:06,855 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-12T00:00:00+00:00 [scheduled]>
2024-05-22 08:02:06,855 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 08:02:06,855 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 08:02:06,855 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 08:02:06,856 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-12T00:00:00+00:00 [scheduled]>
2024-05-22 08:02:06,858 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 08:02:06,858 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:02:06,858 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 08:02:06,859 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:02:06,859 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 08:02:06,859 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:02:06,861 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:07:05,099 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:07:08,944 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:12:13,492 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:12:13,493 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:12:13,493 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:12:13,533 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:07:07.057889+00:00, run_end_date=2024-05-22 08:07:08.314313+00:00, run_duration=1.256424, state=success, executor_state=success, try_number=1, max_tries=2, job_id=477, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 08:02:06.856808+00:00, queued_by_job_id=276, pid=97735
2024-05-22 08:12:13,534 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:02:08.793436+00:00, run_end_date=2024-05-22 08:07:04.340058+00:00, run_duration=295.546622, state=success, executor_state=success, try_number=1, max_tries=2, job_id=476, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 08:02:06.856808+00:00, queued_by_job_id=276, pid=97538
2024-05-22 08:12:13,534 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:07:10.742925+00:00, run_end_date=2024-05-22 08:12:12.893569+00:00, run_duration=302.150644, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=478, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 08:02:06.856808+00:00, queued_by_job_id=276, pid=97760
2024-05-22 08:12:13,568 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 08:12:13,588 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-16 00:00:00+00:00, run_after=2023-08-17 00:00:00+00:00
2024-05-22 08:12:13,685 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-08 00:00:00+00:00: scheduled__2023-08-08T00:00:00+00:00, state:running, queued_at: 2024-05-22 07:17:38.843483+00:00. externally triggered: False> failed
2024-05-22 08:12:13,685 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-08 00:00:00+00:00, run_id=scheduled__2023-08-08T00:00:00+00:00, run_start_date=2024-05-22 07:17:38.857198+00:00, run_end_date=2024-05-22 08:12:13.685648+00:00, run_duration=3274.82845, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-08 00:00:00+00:00, data_interval_end=2023-08-09 00:00:00+00:00, dag_hash=91866e5a2c630dd28d6fd4f2bda02131
2024-05-22 08:12:13,689 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-09 00:00:00+00:00, run_after=2023-08-10 00:00:00+00:00
2024-05-22 08:12:13,700 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-13T00:00:00+00:00 [scheduled]>
2024-05-22 08:12:13,700 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 08:12:13,700 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 08:12:13,700 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 08:12:13,701 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-13T00:00:00+00:00 [scheduled]>
2024-05-22 08:12:13,703 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 08:12:13,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:12:13,704 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 08:12:13,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:12:13,705 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 08:12:13,705 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:12:13,707 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:18:04,338 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:18:08,132 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:23:12,834 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:23:12,834 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:23:12,835 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:23:12,842 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:18:09.913555+00:00, run_end_date=2024-05-22 08:23:12.029525+00:00, run_duration=302.11597, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=481, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 08:12:13.702000+00:00, queued_by_job_id=276, pid=98239
2024-05-22 08:23:12,843 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:18:06.178493+00:00, run_end_date=2024-05-22 08:18:07.410565+00:00, run_duration=1.232072, state=success, executor_state=success, try_number=1, max_tries=2, job_id=480, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 08:12:13.702000+00:00, queued_by_job_id=276, pid=98214
2024-05-22 08:23:12,843 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:12:15.742638+00:00, run_end_date=2024-05-22 08:18:03.732028+00:00, run_duration=347.98939, state=success, executor_state=success, try_number=1, max_tries=2, job_id=479, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 08:12:13.702000+00:00, queued_by_job_id=276, pid=97975
2024-05-22 08:23:12,894 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 08:23:12,926 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-17 00:00:00+00:00, run_after=2023-08-18 00:00:00+00:00
2024-05-22 08:23:13,038 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-09 00:00:00+00:00: scheduled__2023-08-09T00:00:00+00:00, state:running, queued_at: 2024-05-22 07:23:40.975121+00:00. externally triggered: False> failed
2024-05-22 08:23:13,039 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-09 00:00:00+00:00, run_id=scheduled__2023-08-09T00:00:00+00:00, run_start_date=2024-05-22 07:23:40.995508+00:00, run_end_date=2024-05-22 08:23:13.039047+00:00, run_duration=3572.043539, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-09 00:00:00+00:00, data_interval_end=2023-08-10 00:00:00+00:00, dag_hash=c70626acdd67a3a9a3b886dea89d23d8
2024-05-22 08:23:13,042 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-10 00:00:00+00:00, run_after=2023-08-11 00:00:00+00:00
2024-05-22 08:23:13,059 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-14T00:00:00+00:00 [scheduled]>
2024-05-22 08:23:13,059 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 08:23:13,060 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 08:23:13,060 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 08:23:13,060 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-14T00:00:00+00:00 [scheduled]>
2024-05-22 08:23:13,064 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 08:23:13,065 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:23:13,065 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 08:23:13,065 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:23:13,066 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 08:23:13,066 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:23:13,068 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:26:07,219 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:26:11,043 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:31:15,979 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:31:15,980 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:31:15,980 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:31:15,985 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:26:13.239327+00:00, run_end_date=2024-05-22 08:31:15.285883+00:00, run_duration=302.046556, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=484, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 08:23:13.061484+00:00, queued_by_job_id=276, pid=98584
2024-05-22 08:31:15,986 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:26:08.903802+00:00, run_end_date=2024-05-22 08:26:10.310379+00:00, run_duration=1.406577, state=success, executor_state=success, try_number=1, max_tries=2, job_id=483, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 08:23:13.061484+00:00, queued_by_job_id=276, pid=98560
2024-05-22 08:31:15,986 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:23:15.195996+00:00, run_end_date=2024-05-22 08:26:06.661039+00:00, run_duration=171.465043, state=success, executor_state=success, try_number=1, max_tries=2, job_id=482, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 08:23:13.061484+00:00, queued_by_job_id=276, pid=98436
2024-05-22 08:31:16,051 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 08:31:16,082 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-18 00:00:00+00:00, run_after=2023-08-19 00:00:00+00:00
2024-05-22 08:31:16,242 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-10 00:00:00+00:00: scheduled__2023-08-10T00:00:00+00:00, state:running, queued_at: 2024-05-22 07:29:56.652337+00:00. externally triggered: False> failed
2024-05-22 08:31:16,243 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-10 00:00:00+00:00, run_id=scheduled__2023-08-10T00:00:00+00:00, run_start_date=2024-05-22 07:29:56.666672+00:00, run_end_date=2024-05-22 08:31:16.243182+00:00, run_duration=3679.57651, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-10 00:00:00+00:00, data_interval_end=2023-08-11 00:00:00+00:00, dag_hash=b59c19f9cc500232e73754b16d60d52c
2024-05-22 08:31:16,251 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-11 00:00:00+00:00, run_after=2023-08-12 00:00:00+00:00
2024-05-22 08:31:16,268 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-15T00:00:00+00:00 [scheduled]>
2024-05-22 08:31:16,269 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 08:31:16,269 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 08:31:16,269 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 08:31:16,269 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-15T00:00:00+00:00 [scheduled]>
2024-05-22 08:31:16,272 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 08:31:16,272 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:31:16,273 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 08:31:16,273 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:31:16,274 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 08:31:16,274 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:31:16,275 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:33:21,675 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:33:25,159 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:38:30,178 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:38:30,178 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:38:30,178 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:38:30,183 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:33:27.477872+00:00, run_end_date=2024-05-22 08:38:29.574971+00:00, run_duration=302.097099, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=487, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 08:31:16.270576+00:00, queued_by_job_id=276, pid=98902
2024-05-22 08:38:30,184 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:31:18.276509+00:00, run_end_date=2024-05-22 08:33:20.834531+00:00, run_duration=122.558022, state=success, executor_state=success, try_number=1, max_tries=2, job_id=485, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 08:31:16.270576+00:00, queued_by_job_id=276, pid=98785
2024-05-22 08:38:30,184 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:33:23.351013+00:00, run_end_date=2024-05-22 08:33:24.476539+00:00, run_duration=1.125526, state=success, executor_state=success, try_number=1, max_tries=2, job_id=486, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 08:31:16.270576+00:00, queued_by_job_id=276, pid=98878
2024-05-22 08:38:30,216 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 08:38:30,236 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-19 00:00:00+00:00, run_after=2023-08-20 00:00:00+00:00
2024-05-22 08:38:30,322 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-11 00:00:00+00:00: scheduled__2023-08-11T00:00:00+00:00, state:running, queued_at: 2024-05-22 07:35:57.885321+00:00. externally triggered: False> failed
2024-05-22 08:38:30,323 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-11 00:00:00+00:00, run_id=scheduled__2023-08-11T00:00:00+00:00, run_start_date=2024-05-22 07:35:57.901963+00:00, run_end_date=2024-05-22 08:38:30.323073+00:00, run_duration=3752.42111, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-11 00:00:00+00:00, data_interval_end=2023-08-12 00:00:00+00:00, dag_hash=1133d1955f5f0534d15692421d446375
2024-05-22 08:38:30,326 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-12 00:00:00+00:00, run_after=2023-08-13 00:00:00+00:00
2024-05-22 08:38:30,336 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-16T00:00:00+00:00 [scheduled]>
2024-05-22 08:38:30,336 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 08:38:30,336 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 08:38:30,337 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 08:38:30,337 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-16T00:00:00+00:00 [scheduled]>
2024-05-22 08:38:30,339 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 08:38:30,339 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:38:30,340 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 08:38:30,340 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:38:30,340 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 08:38:30,341 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:38:30,342 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:41:35,596 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:41:39,579 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:46:44,118 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:46:44,118 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:46:44,118 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:46:44,137 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:38:32.492294+00:00, run_end_date=2024-05-22 08:41:34.870076+00:00, run_duration=182.377782, state=success, executor_state=success, try_number=1, max_tries=2, job_id=488, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 08:38:30.338130+00:00, queued_by_job_id=276, pid=99101
2024-05-22 08:46:44,138 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:41:37.526277+00:00, run_end_date=2024-05-22 08:41:38.946670+00:00, run_duration=1.420393, state=success, executor_state=success, try_number=1, max_tries=2, job_id=489, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 08:38:30.338130+00:00, queued_by_job_id=276, pid=99228
2024-05-22 08:46:44,138 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:41:41.363168+00:00, run_end_date=2024-05-22 08:46:43.483085+00:00, run_duration=302.119917, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=490, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 08:38:30.338130+00:00, queued_by_job_id=276, pid=99252
2024-05-22 08:46:44,173 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 08:46:44,194 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-20 00:00:00+00:00, run_after=2023-08-21 00:00:00+00:00
2024-05-22 08:46:44,287 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-12 00:00:00+00:00: scheduled__2023-08-12T00:00:00+00:00, state:running, queued_at: 2024-05-22 07:46:23.078133+00:00. externally triggered: False> failed
2024-05-22 08:46:44,287 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-12 00:00:00+00:00, run_id=scheduled__2023-08-12T00:00:00+00:00, run_start_date=2024-05-22 07:46:23.094144+00:00, run_end_date=2024-05-22 08:46:44.287604+00:00, run_duration=3621.19346, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-12 00:00:00+00:00, data_interval_end=2023-08-13 00:00:00+00:00, dag_hash=03c42bb97a99829c09db93266c816af5
2024-05-22 08:46:44,291 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-13 00:00:00+00:00, run_after=2023-08-14 00:00:00+00:00
2024-05-22 08:46:44,301 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-17T00:00:00+00:00 [scheduled]>
2024-05-22 08:46:44,301 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 08:46:44,301 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 08:46:44,301 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 08:46:44,302 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-17T00:00:00+00:00 [scheduled]>
2024-05-22 08:46:44,304 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 08:46:44,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:46:44,305 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 08:46:44,305 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:46:44,305 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 08:46:44,305 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:46:44,307 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:51:35,168 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:51:38,891 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:56:43,648 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:56:43,649 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:56:43,649 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 08:56:43,660 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:51:37.050262+00:00, run_end_date=2024-05-22 08:51:38.242632+00:00, run_duration=1.19237, state=success, executor_state=success, try_number=1, max_tries=2, job_id=492, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 08:46:44.302877+00:00, queued_by_job_id=276, pid=99643
2024-05-22 08:56:43,661 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:46:45.928697+00:00, run_end_date=2024-05-22 08:51:34.564121+00:00, run_duration=288.635424, state=success, executor_state=success, try_number=1, max_tries=2, job_id=491, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 08:46:44.302877+00:00, queued_by_job_id=276, pid=99453
2024-05-22 08:56:43,662 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:51:40.735616+00:00, run_end_date=2024-05-22 08:56:42.981302+00:00, run_duration=302.245686, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=493, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 08:46:44.302877+00:00, queued_by_job_id=276, pid=99667
2024-05-22 08:56:43,698 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 08:56:43,719 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-21 00:00:00+00:00, run_after=2023-08-22 00:00:00+00:00
2024-05-22 08:56:43,815 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-13 00:00:00+00:00: scheduled__2023-08-13T00:00:00+00:00, state:running, queued_at: 2024-05-22 07:55:24.832888+00:00. externally triggered: False> failed
2024-05-22 08:56:43,815 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-13 00:00:00+00:00, run_id=scheduled__2023-08-13T00:00:00+00:00, run_start_date=2024-05-22 07:55:24.846425+00:00, run_end_date=2024-05-22 08:56:43.815853+00:00, run_duration=3678.969428, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-13 00:00:00+00:00, data_interval_end=2023-08-14 00:00:00+00:00, dag_hash=5c059052d6ff1cdca4aa768722986197
2024-05-22 08:56:43,819 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-14 00:00:00+00:00, run_after=2023-08-15 00:00:00+00:00
2024-05-22 08:56:43,829 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-18T00:00:00+00:00 [scheduled]>
2024-05-22 08:56:43,829 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 08:56:43,829 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 08:56:43,830 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 08:56:43,830 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-18T00:00:00+00:00 [scheduled]>
2024-05-22 08:56:43,832 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 08:56:43,832 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:56:43,833 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 08:56:43,833 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:56:43,834 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 08:56:43,834 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:56:43,835 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:57:35,865 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 08:57:39,693 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:02:44,251 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:02:44,251 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:02:44,251 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:02:44,256 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:56:45.605307+00:00, run_end_date=2024-05-22 08:57:35.208900+00:00, run_duration=49.603593, state=success, executor_state=success, try_number=1, max_tries=2, job_id=494, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 08:56:43.831285+00:00, queued_by_job_id=276, pid=99864
2024-05-22 09:02:44,257 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:57:37.837082+00:00, run_end_date=2024-05-22 08:57:39.032499+00:00, run_duration=1.195417, state=success, executor_state=success, try_number=1, max_tries=2, job_id=495, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 08:56:43.831285+00:00, queued_by_job_id=276, pid=99912
2024-05-22 09:02:44,257 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 08:57:41.568854+00:00, run_end_date=2024-05-22 09:02:43.647435+00:00, run_duration=302.078581, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=496, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 08:56:43.831285+00:00, queued_by_job_id=276, pid=99936
2024-05-22 09:02:44,292 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 09:02:44,312 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-22 00:00:00+00:00, run_after=2023-08-23 00:00:00+00:00
2024-05-22 09:02:44,404 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-14 00:00:00+00:00: scheduled__2023-08-14T00:00:00+00:00, state:running, queued_at: 2024-05-22 08:02:06.738848+00:00. externally triggered: False> failed
2024-05-22 09:02:44,405 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-14 00:00:00+00:00, run_id=scheduled__2023-08-14T00:00:00+00:00, run_start_date=2024-05-22 08:02:06.754200+00:00, run_end_date=2024-05-22 09:02:44.405177+00:00, run_duration=3637.650977, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-14 00:00:00+00:00, data_interval_end=2023-08-15 00:00:00+00:00, dag_hash=b5a2c697f635eef85b985be5e7596c6e
2024-05-22 09:02:44,408 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-15 00:00:00+00:00, run_after=2023-08-16 00:00:00+00:00
2024-05-22 09:02:44,419 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-19T00:00:00+00:00 [scheduled]>
2024-05-22 09:02:44,419 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 09:02:44,419 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 09:02:44,420 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 09:02:44,420 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-19T00:00:00+00:00 [scheduled]>
2024-05-22 09:02:44,423 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 09:02:44,423 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:02:44,423 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 09:02:44,423 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:02:44,424 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 09:02:44,424 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:02:44,426 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:03:36,475 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:03:40,545 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:08:45,048 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:08:45,048 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:08:45,049 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:08:45,062 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:03:38.425620+00:00, run_end_date=2024-05-22 09:03:39.854158+00:00, run_duration=1.428538, state=success, executor_state=success, try_number=1, max_tries=2, job_id=498, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 09:02:44.421066+00:00, queued_by_job_id=276, pid=100185
2024-05-22 09:08:45,062 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:02:46.139932+00:00, run_end_date=2024-05-22 09:03:35.813894+00:00, run_duration=49.673962, state=success, executor_state=success, try_number=1, max_tries=2, job_id=497, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 09:02:44.421066+00:00, queued_by_job_id=276, pid=100136
2024-05-22 09:08:45,062 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:03:42.505062+00:00, run_end_date=2024-05-22 09:08:44.424899+00:00, run_duration=301.919837, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=499, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 09:02:44.421066+00:00, queued_by_job_id=276, pid=100209
2024-05-22 09:08:45,109 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 09:08:45,142 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-23 00:00:00+00:00, run_after=2023-08-24 00:00:00+00:00
2024-05-22 09:08:45,239 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-15 00:00:00+00:00: scheduled__2023-08-15T00:00:00+00:00, state:running, queued_at: 2024-05-22 08:12:13.581329+00:00. externally triggered: False> failed
2024-05-22 09:08:45,240 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-15 00:00:00+00:00, run_id=scheduled__2023-08-15T00:00:00+00:00, run_start_date=2024-05-22 08:12:13.595711+00:00, run_end_date=2024-05-22 09:08:45.240263+00:00, run_duration=3391.644552, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-15 00:00:00+00:00, data_interval_end=2023-08-16 00:00:00+00:00, dag_hash=6230703ec3bce833ce744df0721e0f37
2024-05-22 09:08:45,243 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-16 00:00:00+00:00, run_after=2023-08-17 00:00:00+00:00
2024-05-22 09:08:45,264 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-20T00:00:00+00:00 [scheduled]>
2024-05-22 09:08:45,265 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 09:08:45,265 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 09:08:45,266 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 09:08:45,266 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-20T00:00:00+00:00 [scheduled]>
2024-05-22 09:08:45,270 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 09:08:45,271 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:08:45,272 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 09:08:45,272 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:08:45,273 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 09:08:45,274 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:08:45,276 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:10:01,889 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:10:06,165 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:15:10,834 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:15:10,835 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:15:10,835 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:15:10,842 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:10:08.093327+00:00, run_end_date=2024-05-22 09:15:10.124832+00:00, run_duration=302.031505, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=502, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 09:08:45.268171+00:00, queued_by_job_id=276, pid=100494
2024-05-22 09:15:10,842 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:08:47.343856+00:00, run_end_date=2024-05-22 09:10:00.826581+00:00, run_duration=73.482725, state=success, executor_state=success, try_number=1, max_tries=2, job_id=500, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 09:08:45.268171+00:00, queued_by_job_id=276, pid=100406
2024-05-22 09:15:10,843 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:10:03.974236+00:00, run_end_date=2024-05-22 09:10:05.462650+00:00, run_duration=1.488414, state=success, executor_state=success, try_number=1, max_tries=2, job_id=501, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 09:08:45.268171+00:00, queued_by_job_id=276, pid=100470
2024-05-22 09:15:10,887 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 09:15:10,910 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-24 00:00:00+00:00, run_after=2023-08-25 00:00:00+00:00
2024-05-22 09:15:11,032 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-16 00:00:00+00:00: scheduled__2023-08-16T00:00:00+00:00, state:running, queued_at: 2024-05-22 08:23:12.920415+00:00. externally triggered: False> failed
2024-05-22 09:15:11,033 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-16 00:00:00+00:00, run_id=scheduled__2023-08-16T00:00:00+00:00, run_start_date=2024-05-22 08:23:12.940306+00:00, run_end_date=2024-05-22 09:15:11.033126+00:00, run_duration=3118.09282, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-16 00:00:00+00:00, data_interval_end=2023-08-17 00:00:00+00:00, dag_hash=884badf5833e83c37eb2b5ddd85efd5a
2024-05-22 09:15:11,037 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-17 00:00:00+00:00, run_after=2023-08-18 00:00:00+00:00
2024-05-22 09:15:11,048 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-21T00:00:00+00:00 [scheduled]>
2024-05-22 09:15:11,048 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 09:15:11,049 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 09:15:11,049 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 09:15:11,050 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-21T00:00:00+00:00 [scheduled]>
2024-05-22 09:15:11,053 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 09:15:11,053 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:15:11,054 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 09:15:11,054 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:15:11,054 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 09:15:11,055 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:15:11,056 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:16:12,401 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:16:16,195 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:21:21,125 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:21:21,126 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:21:21,126 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:21:21,163 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:15:13.375052+00:00, run_end_date=2024-05-22 09:16:11.754035+00:00, run_duration=58.378983, state=success, executor_state=success, try_number=1, max_tries=2, job_id=503, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 09:15:11.051065+00:00, queued_by_job_id=276, pid=100697
2024-05-22 09:21:21,163 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:16:14.495178+00:00, run_end_date=2024-05-22 09:16:15.622789+00:00, run_duration=1.127611, state=success, executor_state=success, try_number=1, max_tries=2, job_id=504, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 09:15:11.051065+00:00, queued_by_job_id=276, pid=100750
2024-05-22 09:21:21,164 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:16:18.101852+00:00, run_end_date=2024-05-22 09:21:20.440648+00:00, run_duration=302.338796, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=505, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 09:15:11.051065+00:00, queued_by_job_id=276, pid=100774
2024-05-22 09:21:21,209 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 09:21:21,235 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-25 00:00:00+00:00, run_after=2023-08-26 00:00:00+00:00
2024-05-22 09:21:21,356 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-17 00:00:00+00:00: scheduled__2023-08-17T00:00:00+00:00, state:running, queued_at: 2024-05-22 08:31:16.075837+00:00. externally triggered: False> failed
2024-05-22 09:21:21,357 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-17 00:00:00+00:00, run_id=scheduled__2023-08-17T00:00:00+00:00, run_start_date=2024-05-22 08:31:16.098881+00:00, run_end_date=2024-05-22 09:21:21.357231+00:00, run_duration=3005.25835, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-17 00:00:00+00:00, data_interval_end=2023-08-18 00:00:00+00:00, dag_hash=afe8935f0ff9501233879720e88b0aab
2024-05-22 09:21:21,362 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-18 00:00:00+00:00, run_after=2023-08-19 00:00:00+00:00
2024-05-22 09:21:21,377 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-22T00:00:00+00:00 [scheduled]>
2024-05-22 09:21:21,377 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 09:21:21,378 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 09:21:21,378 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 09:21:21,379 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-22T00:00:00+00:00 [scheduled]>
2024-05-22 09:21:21,384 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 09:21:21,384 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:21:21,385 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 09:21:21,385 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:21:21,386 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 09:21:21,386 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:21:21,388 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:27:15,101 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:27:19,334 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:32:24,119 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:32:24,119 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:32:24,119 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:32:24,126 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:21:23.533322+00:00, run_end_date=2024-05-22 09:27:14.391377+00:00, run_duration=350.858055, state=success, executor_state=success, try_number=1, max_tries=2, job_id=506, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 09:21:21.380136+00:00, queued_by_job_id=276, pid=100976
2024-05-22 09:32:24,127 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:27:17.306629+00:00, run_end_date=2024-05-22 09:27:18.665769+00:00, run_duration=1.35914, state=success, executor_state=success, try_number=1, max_tries=2, job_id=507, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 09:21:21.380136+00:00, queued_by_job_id=276, pid=101214
2024-05-22 09:32:24,127 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:27:21.321642+00:00, run_end_date=2024-05-22 09:32:23.459678+00:00, run_duration=302.138036, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=508, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 09:21:21.380136+00:00, queued_by_job_id=276, pid=101238
2024-05-22 09:32:24,162 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 09:32:24,184 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-26 00:00:00+00:00, run_after=2023-08-27 00:00:00+00:00
2024-05-22 09:32:24,390 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-18 00:00:00+00:00: scheduled__2023-08-18T00:00:00+00:00, state:running, queued_at: 2024-05-22 08:38:30.230086+00:00. externally triggered: False> failed
2024-05-22 09:32:24,390 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-18 00:00:00+00:00, run_id=scheduled__2023-08-18T00:00:00+00:00, run_start_date=2024-05-22 08:38:30.243319+00:00, run_end_date=2024-05-22 09:32:24.390547+00:00, run_duration=3234.147228, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-18 00:00:00+00:00, data_interval_end=2023-08-19 00:00:00+00:00, dag_hash=0d166da97c686772bc8315f9a492f669
2024-05-22 09:32:24,394 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-19 00:00:00+00:00, run_after=2023-08-20 00:00:00+00:00
2024-05-22 09:32:24,405 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-23T00:00:00+00:00 [scheduled]>
2024-05-22 09:32:24,406 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 09:32:24,406 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 09:32:24,406 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 09:32:24,406 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-23T00:00:00+00:00 [scheduled]>
2024-05-22 09:32:24,409 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 09:32:24,409 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:32:24,410 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 09:32:24,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:32:24,410 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 09:32:24,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:32:24,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:37:32,654 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:37:36,326 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:42:40,899 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:42:40,899 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:42:40,899 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:42:40,908 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:37:38.129915+00:00, run_end_date=2024-05-22 09:42:40.168701+00:00, run_duration=302.038786, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=511, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 09:32:24.407617+00:00, queued_by_job_id=276, pid=101671
2024-05-22 09:42:40,909 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:32:26.567191+00:00, run_end_date=2024-05-22 09:37:31.567530+00:00, run_duration=305.000339, state=success, executor_state=success, try_number=1, max_tries=2, job_id=509, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 09:32:24.407617+00:00, queued_by_job_id=276, pid=101442
2024-05-22 09:42:40,909 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:37:34.604213+00:00, run_end_date=2024-05-22 09:37:35.716557+00:00, run_duration=1.112344, state=success, executor_state=success, try_number=1, max_tries=2, job_id=510, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 09:32:24.407617+00:00, queued_by_job_id=276, pid=101647
2024-05-22 09:42:40,945 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 09:42:40,966 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-27 00:00:00+00:00, run_after=2023-08-28 00:00:00+00:00
2024-05-22 09:42:41,081 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-19 00:00:00+00:00: scheduled__2023-08-19T00:00:00+00:00, state:running, queued_at: 2024-05-22 08:46:44.186970+00:00. externally triggered: False> failed
2024-05-22 09:42:41,081 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-19 00:00:00+00:00, run_id=scheduled__2023-08-19T00:00:00+00:00, run_start_date=2024-05-22 08:46:44.201921+00:00, run_end_date=2024-05-22 09:42:41.081910+00:00, run_duration=3356.879989, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-19 00:00:00+00:00, data_interval_end=2023-08-20 00:00:00+00:00, dag_hash=453c7691f433146dcb5963386f2637ca
2024-05-22 09:42:41,086 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-20 00:00:00+00:00, run_after=2023-08-21 00:00:00+00:00
2024-05-22 09:42:41,097 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-24T00:00:00+00:00 [scheduled]>
2024-05-22 09:42:41,098 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 09:42:41,098 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 09:42:41,098 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 09:42:41,098 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-24T00:00:00+00:00 [scheduled]>
2024-05-22 09:42:41,101 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 09:42:41,101 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:42:41,102 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 09:42:41,103 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:42:41,103 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 09:42:41,103 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:42:41,105 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:43:46,098 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:43:49,847 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:48:54,781 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:48:54,781 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:48:54,781 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:48:54,794 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:42:43.339183+00:00, run_end_date=2024-05-22 09:43:45.452210+00:00, run_duration=62.113027, state=success, executor_state=success, try_number=1, max_tries=2, job_id=512, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 09:42:41.099648+00:00, queued_by_job_id=276, pid=101870
2024-05-22 09:48:54,795 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:43:47.986947+00:00, run_end_date=2024-05-22 09:43:49.252108+00:00, run_duration=1.265161, state=success, executor_state=success, try_number=1, max_tries=2, job_id=513, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 09:42:41.099648+00:00, queued_by_job_id=276, pid=101925
2024-05-22 09:48:54,796 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:43:52.182693+00:00, run_end_date=2024-05-22 09:48:54.193800+00:00, run_duration=302.011107, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=514, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 09:42:41.099648+00:00, queued_by_job_id=276, pid=101950
2024-05-22 09:48:54,828 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 09:48:54,847 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-28 00:00:00+00:00, run_after=2023-08-29 00:00:00+00:00
2024-05-22 09:48:54,935 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-20 00:00:00+00:00: scheduled__2023-08-20T00:00:00+00:00, state:running, queued_at: 2024-05-22 08:56:43.711895+00:00. externally triggered: False> failed
2024-05-22 09:48:54,935 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-20 00:00:00+00:00, run_id=scheduled__2023-08-20T00:00:00+00:00, run_start_date=2024-05-22 08:56:43.729125+00:00, run_end_date=2024-05-22 09:48:54.935378+00:00, run_duration=3131.206253, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-20 00:00:00+00:00, data_interval_end=2023-08-21 00:00:00+00:00, dag_hash=74d614cf229274f43f0ce8dccb8ad938
2024-05-22 09:48:54,938 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-21 00:00:00+00:00, run_after=2023-08-22 00:00:00+00:00
2024-05-22 09:48:54,947 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-25T00:00:00+00:00 [scheduled]>
2024-05-22 09:48:54,948 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 09:48:54,948 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 09:48:54,948 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 09:48:54,948 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-25T00:00:00+00:00 [scheduled]>
2024-05-22 09:48:54,950 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 09:48:54,951 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:48:54,951 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 09:48:54,951 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:48:54,952 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 09:48:54,952 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:48:54,953 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:51:17,628 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:51:21,416 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:56:25,934 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:56:25,935 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:56:25,935 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 09:56:25,956 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:48:56.552671+00:00, run_end_date=2024-05-22 09:51:16.947450+00:00, run_duration=140.394779, state=success, executor_state=success, try_number=1, max_tries=2, job_id=515, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 09:48:54.949489+00:00, queued_by_job_id=276, pid=102146
2024-05-22 09:56:25,956 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:51:19.287206+00:00, run_end_date=2024-05-22 09:51:20.520275+00:00, run_duration=1.233069, state=success, executor_state=success, try_number=1, max_tries=2, job_id=516, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 09:48:54.949489+00:00, queued_by_job_id=276, pid=102250
2024-05-22 09:56:25,957 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:51:23.416420+00:00, run_end_date=2024-05-22 09:56:25.327947+00:00, run_duration=301.911527, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=517, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 09:48:54.949489+00:00, queued_by_job_id=276, pid=102274
2024-05-22 09:56:25,993 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 09:56:26,017 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-29 00:00:00+00:00, run_after=2023-08-30 00:00:00+00:00
2024-05-22 09:56:26,108 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-21 00:00:00+00:00: scheduled__2023-08-21T00:00:00+00:00, state:running, queued_at: 2024-05-22 09:02:44.305711+00:00. externally triggered: False> failed
2024-05-22 09:56:26,109 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-21 00:00:00+00:00, run_id=scheduled__2023-08-21T00:00:00+00:00, run_start_date=2024-05-22 09:02:44.319760+00:00, run_end_date=2024-05-22 09:56:26.109303+00:00, run_duration=3221.789543, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-21 00:00:00+00:00, data_interval_end=2023-08-22 00:00:00+00:00, dag_hash=ebe8c17db90692204d04d304372beb6b
2024-05-22 09:56:26,112 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-22 00:00:00+00:00, run_after=2023-08-23 00:00:00+00:00
2024-05-22 09:56:26,123 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-26T00:00:00+00:00 [scheduled]>
2024-05-22 09:56:26,123 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 09:56:26,123 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 09:56:26,123 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 09:56:26,124 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-26T00:00:00+00:00 [scheduled]>
2024-05-22 09:56:26,127 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 09:56:26,128 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:56:26,128 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 09:56:26,129 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:56:26,129 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 09:56:26,130 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 09:56:26,131 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:03:18,400 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:03:22,215 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:08:27,238 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:08:27,239 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:08:27,239 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:08:27,244 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:03:20.210488+00:00, run_end_date=2024-05-22 10:03:21.433110+00:00, run_duration=1.222622, state=success, executor_state=success, try_number=1, max_tries=2, job_id=519, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 09:56:26.125168+00:00, queued_by_job_id=276, pid=102732
2024-05-22 10:08:27,244 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:03:23.958202+00:00, run_end_date=2024-05-22 10:08:26.495007+00:00, run_duration=302.536805, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=520, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 09:56:26.125168+00:00, queued_by_job_id=276, pid=102756
2024-05-22 10:08:27,245 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 09:56:27.987208+00:00, run_end_date=2024-05-22 10:03:17.785542+00:00, run_duration=409.798334, state=success, executor_state=success, try_number=1, max_tries=2, job_id=518, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 09:56:26.125168+00:00, queued_by_job_id=276, pid=102473
2024-05-22 10:08:27,282 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 10:08:27,306 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-30 00:00:00+00:00, run_after=2023-08-31 00:00:00+00:00
2024-05-22 10:08:27,420 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-22 00:00:00+00:00: scheduled__2023-08-22T00:00:00+00:00, state:running, queued_at: 2024-05-22 09:08:45.131431+00:00. externally triggered: False> failed
2024-05-22 10:08:27,421 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-22 00:00:00+00:00, run_id=scheduled__2023-08-22T00:00:00+00:00, run_start_date=2024-05-22 09:08:45.150113+00:00, run_end_date=2024-05-22 10:08:27.421425+00:00, run_duration=3582.271312, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-22 00:00:00+00:00, data_interval_end=2023-08-23 00:00:00+00:00, dag_hash=fc53900c079a19add7325cf00241de71
2024-05-22 10:08:27,425 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-23 00:00:00+00:00, run_after=2023-08-24 00:00:00+00:00
2024-05-22 10:08:27,436 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-27T00:00:00+00:00 [scheduled]>
2024-05-22 10:08:27,437 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 10:08:27,437 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 10:08:27,437 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 10:08:27,438 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-27T00:00:00+00:00 [scheduled]>
2024-05-22 10:08:27,441 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 10:08:27,441 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:08:27,442 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 10:08:27,442 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:08:27,442 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 10:08:27,442 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:08:27,444 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:10:51,535 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:10:55,262 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:16:00,067 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:16:00,068 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:16:00,068 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:16:00,083 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:10:57.238302+00:00, run_end_date=2024-05-22 10:15:59.316402+00:00, run_duration=302.0781, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=523, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 10:08:27.439585+00:00, queued_by_job_id=276, pid=103086
2024-05-22 10:16:00,084 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:08:29.650843+00:00, run_end_date=2024-05-22 10:10:50.907897+00:00, run_duration=141.257054, state=success, executor_state=success, try_number=1, max_tries=2, job_id=521, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 10:08:27.439585+00:00, queued_by_job_id=276, pid=102957
2024-05-22 10:16:00,084 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:10:53.432114+00:00, run_end_date=2024-05-22 10:10:54.599104+00:00, run_duration=1.16699, state=success, executor_state=success, try_number=1, max_tries=2, job_id=522, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 10:08:27.439585+00:00, queued_by_job_id=276, pid=103062
2024-05-22 10:16:00,137 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 10:16:00,162 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-31 00:00:00+00:00, run_after=2023-09-01 00:00:00+00:00
2024-05-22 10:16:00,274 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-23 00:00:00+00:00: scheduled__2023-08-23T00:00:00+00:00, state:running, queued_at: 2024-05-22 09:15:10.902011+00:00. externally triggered: False> failed
2024-05-22 10:16:00,275 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-23 00:00:00+00:00, run_id=scheduled__2023-08-23T00:00:00+00:00, run_start_date=2024-05-22 09:15:10.918248+00:00, run_end_date=2024-05-22 10:16:00.275409+00:00, run_duration=3649.357161, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-23 00:00:00+00:00, data_interval_end=2023-08-24 00:00:00+00:00, dag_hash=eb2581b0a96f1d130dccc6420ef77ae4
2024-05-22 10:16:00,279 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-24 00:00:00+00:00, run_after=2023-08-25 00:00:00+00:00
2024-05-22 10:16:00,290 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-28T00:00:00+00:00 [scheduled]>
2024-05-22 10:16:00,291 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 10:16:00,291 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 10:16:00,291 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 10:16:00,291 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-28T00:00:00+00:00 [scheduled]>
2024-05-22 10:16:00,294 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 10:16:00,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:16:00,295 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 10:16:00,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:16:00,296 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 10:16:00,296 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:16:00,298 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:19:46,725 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:19:50,219 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:24:54,596 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:24:54,597 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:24:54,597 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:24:54,602 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:16:02.704483+00:00, run_end_date=2024-05-22 10:19:46.175252+00:00, run_duration=223.470769, state=success, executor_state=success, try_number=1, max_tries=2, job_id=524, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 10:16:00.292809+00:00, queued_by_job_id=276, pid=103283
2024-05-22 10:24:54,603 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:19:48.537789+00:00, run_end_date=2024-05-22 10:19:49.674052+00:00, run_duration=1.136263, state=success, executor_state=success, try_number=1, max_tries=2, job_id=525, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 10:16:00.292809+00:00, queued_by_job_id=276, pid=103443
2024-05-22 10:24:54,603 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:19:52.023387+00:00, run_end_date=2024-05-22 10:24:53.976949+00:00, run_duration=301.953562, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=526, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 10:16:00.292809+00:00, queued_by_job_id=276, pid=103468
2024-05-22 10:24:54,636 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 10:24:54,659 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-01 00:00:00+00:00, run_after=2023-09-02 00:00:00+00:00
2024-05-22 10:24:54,750 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-24 00:00:00+00:00: scheduled__2023-08-24T00:00:00+00:00, state:running, queued_at: 2024-05-22 09:21:21.226422+00:00. externally triggered: False> failed
2024-05-22 10:24:54,750 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-24 00:00:00+00:00, run_id=scheduled__2023-08-24T00:00:00+00:00, run_start_date=2024-05-22 09:21:21.244045+00:00, run_end_date=2024-05-22 10:24:54.750452+00:00, run_duration=3813.506407, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-24 00:00:00+00:00, data_interval_end=2023-08-25 00:00:00+00:00, dag_hash=ad4f1a9c8ccf882dfa9487289c14b24b
2024-05-22 10:24:54,753 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-25 00:00:00+00:00, run_after=2023-08-26 00:00:00+00:00
2024-05-22 10:24:54,765 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-29T00:00:00+00:00 [scheduled]>
2024-05-22 10:24:54,765 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 10:24:54,766 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 10:24:54,766 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 10:24:54,766 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-29T00:00:00+00:00 [scheduled]>
2024-05-22 10:24:54,768 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 10:24:54,769 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:24:54,769 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 10:24:54,769 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:24:54,770 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 10:24:54,770 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:24:54,772 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:26:49,209 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:26:53,476 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:31:57,995 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-08-31T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:31:57,995 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:31:57,996 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:31:58,020 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-08-31T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:24:56.994926+00:00, run_end_date=2024-05-22 10:26:48.611478+00:00, run_duration=111.616552, state=success, executor_state=success, try_number=1, max_tries=2, job_id=527, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 10:24:54.767465+00:00, queued_by_job_id=276, pid=104074
2024-05-22 10:31:58,021 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:26:51.374085+00:00, run_end_date=2024-05-22 10:26:52.787086+00:00, run_duration=1.413001, state=success, executor_state=success, try_number=1, max_tries=2, job_id=528, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 10:24:54.767465+00:00, queued_by_job_id=276, pid=104163
2024-05-22 10:31:58,021 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:26:55.283119+00:00, run_end_date=2024-05-22 10:31:57.314122+00:00, run_duration=302.031003, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=529, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 10:24:54.767465+00:00, queued_by_job_id=276, pid=104189
2024-05-22 10:31:58,059 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 10:31:58,082 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-02 00:00:00+00:00, run_after=2023-09-03 00:00:00+00:00
2024-05-22 10:31:58,184 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-25 00:00:00+00:00: scheduled__2023-08-25T00:00:00+00:00, state:running, queued_at: 2024-05-22 09:32:24.177847+00:00. externally triggered: False> failed
2024-05-22 10:31:58,185 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-25 00:00:00+00:00, run_id=scheduled__2023-08-25T00:00:00+00:00, run_start_date=2024-05-22 09:32:24.196536+00:00, run_end_date=2024-05-22 10:31:58.184999+00:00, run_duration=3573.988463, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-25 00:00:00+00:00, data_interval_end=2023-08-26 00:00:00+00:00, dag_hash=f398354b15ebe35dd239a0aacfe1a061
2024-05-22 10:31:58,189 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-26 00:00:00+00:00, run_after=2023-08-27 00:00:00+00:00
2024-05-22 10:31:58,200 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-30T00:00:00+00:00 [scheduled]>
2024-05-22 10:31:58,200 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 10:31:58,200 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 10:31:58,201 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 10:31:58,201 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-30T00:00:00+00:00 [scheduled]>
2024-05-22 10:31:58,203 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 10:31:58,204 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:31:58,204 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 10:31:58,204 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:31:58,205 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 10:31:58,205 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:31:58,206 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:34:06,379 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:34:10,421 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:39:14,981 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:39:14,982 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-08-31T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:39:14,982 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:39:14,987 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-08-31T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:34:08.385283+00:00, run_end_date=2024-05-22 10:34:09.733074+00:00, run_duration=1.347791, state=success, executor_state=success, try_number=1, max_tries=2, job_id=531, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 10:31:58.202227+00:00, queued_by_job_id=276, pid=104480
2024-05-22 10:39:14,987 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:34:12.422608+00:00, run_end_date=2024-05-22 10:39:14.334292+00:00, run_duration=301.911684, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=532, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 10:31:58.202227+00:00, queued_by_job_id=276, pid=104505
2024-05-22 10:39:14,988 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:32:00.047999+00:00, run_end_date=2024-05-22 10:34:05.779759+00:00, run_duration=125.73176, state=success, executor_state=success, try_number=1, max_tries=2, job_id=530, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 10:31:58.202227+00:00, queued_by_job_id=276, pid=104390
2024-05-22 10:39:15,027 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 10:39:15,047 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-03 00:00:00+00:00, run_after=2023-09-04 00:00:00+00:00
2024-05-22 10:39:15,137 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-26 00:00:00+00:00: scheduled__2023-08-26T00:00:00+00:00, state:running, queued_at: 2024-05-22 09:42:40.958859+00:00. externally triggered: False> failed
2024-05-22 10:39:15,138 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-26 00:00:00+00:00, run_id=scheduled__2023-08-26T00:00:00+00:00, run_start_date=2024-05-22 09:42:40.975144+00:00, run_end_date=2024-05-22 10:39:15.138137+00:00, run_duration=3394.162993, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-26 00:00:00+00:00, data_interval_end=2023-08-27 00:00:00+00:00, dag_hash=eabbc2f0ea337ca7389858eaaf2a7314
2024-05-22 10:39:15,141 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-27 00:00:00+00:00, run_after=2023-08-28 00:00:00+00:00
2024-05-22 10:39:15,150 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-31T00:00:00+00:00 [scheduled]>
2024-05-22 10:39:15,151 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 10:39:15,151 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 10:39:15,151 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 10:39:15,151 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-08-31T00:00:00+00:00 [scheduled]>
2024-05-22 10:39:15,154 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 10:39:15,154 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:39:15,154 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 10:39:15,154 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:39:15,155 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 10:39:15,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:39:15,156 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:42:26,601 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:42:30,674 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:47:35,115 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:47:35,115 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:47:35,115 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-08-31T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:47:35,121 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-08-31T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:42:32.610004+00:00, run_end_date=2024-05-22 10:47:34.510189+00:00, run_duration=301.900185, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=535, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 10:39:15.152599+00:00, queued_by_job_id=276, pid=104878
2024-05-22 10:47:35,121 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:39:16.814990+00:00, run_end_date=2024-05-22 10:42:25.884868+00:00, run_duration=189.069878, state=success, executor_state=success, try_number=1, max_tries=2, job_id=533, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 10:39:15.152599+00:00, queued_by_job_id=276, pid=104704
2024-05-22 10:47:35,122 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:42:28.682737+00:00, run_end_date=2024-05-22 10:42:30.027525+00:00, run_duration=1.344788, state=success, executor_state=success, try_number=1, max_tries=2, job_id=534, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 10:39:15.152599+00:00, queued_by_job_id=276, pid=104853
2024-05-22 10:47:35,161 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 10:47:35,183 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-04 00:00:00+00:00, run_after=2023-09-05 00:00:00+00:00
2024-05-22 10:47:35,275 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-27 00:00:00+00:00: scheduled__2023-08-27T00:00:00+00:00, state:running, queued_at: 2024-05-22 09:48:54.840651+00:00. externally triggered: False> failed
2024-05-22 10:47:35,276 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-27 00:00:00+00:00, run_id=scheduled__2023-08-27T00:00:00+00:00, run_start_date=2024-05-22 09:48:54.854434+00:00, run_end_date=2024-05-22 10:47:35.276188+00:00, run_duration=3520.421754, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-27 00:00:00+00:00, data_interval_end=2023-08-28 00:00:00+00:00, dag_hash=eb4eb73cf9af4fcd9a439bd3f318df21
2024-05-22 10:47:35,279 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-28 00:00:00+00:00, run_after=2023-08-29 00:00:00+00:00
2024-05-22 10:47:35,290 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-01T00:00:00+00:00 [scheduled]>
2024-05-22 10:47:35,290 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 10:47:35,290 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 10:47:35,291 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 10:47:35,291 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-01T00:00:00+00:00 [scheduled]>
2024-05-22 10:47:35,294 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 10:47:35,294 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:47:35,295 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 10:47:35,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:47:35,295 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 10:47:35,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:47:35,297 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:50:05,959 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:50:09,763 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:55:14,274 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:55:14,275 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:55:14,275 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 10:55:14,282 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:47:37.300537+00:00, run_end_date=2024-05-22 10:50:05.379715+00:00, run_duration=148.079178, state=success, executor_state=success, try_number=1, max_tries=2, job_id=536, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 10:47:35.292294+00:00, queued_by_job_id=276, pid=105079
2024-05-22 10:55:14,282 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:50:08.012734+00:00, run_end_date=2024-05-22 10:50:09.166670+00:00, run_duration=1.153936, state=success, executor_state=success, try_number=1, max_tries=2, job_id=537, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 10:47:35.292294+00:00, queued_by_job_id=276, pid=105186
2024-05-22 10:55:14,283 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:50:11.473956+00:00, run_end_date=2024-05-22 10:55:13.619582+00:00, run_duration=302.145626, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=538, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 10:47:35.292294+00:00, queued_by_job_id=276, pid=105211
2024-05-22 10:55:14,318 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 10:55:14,338 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-05 00:00:00+00:00, run_after=2023-09-06 00:00:00+00:00
2024-05-22 10:55:14,460 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-28 00:00:00+00:00: scheduled__2023-08-28T00:00:00+00:00, state:running, queued_at: 2024-05-22 09:56:26.010045+00:00. externally triggered: False> failed
2024-05-22 10:55:14,461 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-28 00:00:00+00:00, run_id=scheduled__2023-08-28T00:00:00+00:00, run_start_date=2024-05-22 09:56:26.024836+00:00, run_end_date=2024-05-22 10:55:14.461161+00:00, run_duration=3528.436325, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-28 00:00:00+00:00, data_interval_end=2023-08-29 00:00:00+00:00, dag_hash=f00eab9bf8c99d150a05b123fb6ea71a
2024-05-22 10:55:14,465 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-29 00:00:00+00:00, run_after=2023-08-30 00:00:00+00:00
2024-05-22 10:55:14,478 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-02T00:00:00+00:00 [scheduled]>
2024-05-22 10:55:14,478 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 10:55:14,478 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 10:55:14,479 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 10:55:14,480 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-02T00:00:00+00:00 [scheduled]>
2024-05-22 10:55:14,482 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 10:55:14,482 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:55:14,483 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 10:55:14,483 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:55:14,484 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 10:55:14,484 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:55:14,486 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:57:34,942 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 10:57:38,988 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:02:43,419 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:02:43,419 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:02:43,419 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:02:43,441 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:55:16.603574+00:00, run_end_date=2024-05-22 10:57:34.251384+00:00, run_duration=137.64781, state=success, executor_state=success, try_number=1, max_tries=2, job_id=539, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 10:55:14.480774+00:00, queued_by_job_id=276, pid=105409
2024-05-22 11:02:43,442 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:57:36.868218+00:00, run_end_date=2024-05-22 10:57:38.239760+00:00, run_duration=1.371542, state=success, executor_state=success, try_number=1, max_tries=2, job_id=540, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 10:55:14.480774+00:00, queued_by_job_id=276, pid=105505
2024-05-22 11:02:43,443 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 10:57:40.676709+00:00, run_end_date=2024-05-22 11:02:42.679485+00:00, run_duration=302.002776, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=541, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 10:55:14.480774+00:00, queued_by_job_id=276, pid=105530
2024-05-22 11:02:43,485 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 11:02:43,505 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-06 00:00:00+00:00, run_after=2023-09-07 00:00:00+00:00
2024-05-22 11:02:43,603 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-29 00:00:00+00:00: scheduled__2023-08-29T00:00:00+00:00, state:running, queued_at: 2024-05-22 10:08:27.298414+00:00. externally triggered: False> failed
2024-05-22 11:02:43,603 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-29 00:00:00+00:00, run_id=scheduled__2023-08-29T00:00:00+00:00, run_start_date=2024-05-22 10:08:27.314697+00:00, run_end_date=2024-05-22 11:02:43.603467+00:00, run_duration=3256.28877, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-29 00:00:00+00:00, data_interval_end=2023-08-30 00:00:00+00:00, dag_hash=f1d34d345402af2af5662439cf7af075
2024-05-22 11:02:43,606 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-30 00:00:00+00:00, run_after=2023-08-31 00:00:00+00:00
2024-05-22 11:02:43,620 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-03T00:00:00+00:00 [scheduled]>
2024-05-22 11:02:43,620 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 11:02:43,620 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 11:02:43,620 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 11:02:43,621 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-03T00:00:00+00:00 [scheduled]>
2024-05-22 11:02:43,629 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 11:02:43,629 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:02:43,631 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 11:02:43,632 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:02:43,635 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 11:02:43,635 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:02:43,638 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:06:34,321 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:06:38,006 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:11:42,988 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:11:42,989 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:11:42,989 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:11:42,996 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:02:45.787235+00:00, run_end_date=2024-05-22 11:06:33.760236+00:00, run_duration=227.973001, state=success, executor_state=success, try_number=1, max_tries=2, job_id=542, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 11:02:43.624506+00:00, queued_by_job_id=276, pid=105730
2024-05-22 11:11:42,996 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:06:36.079793+00:00, run_end_date=2024-05-22 11:06:37.333060+00:00, run_duration=1.253267, state=success, executor_state=success, try_number=1, max_tries=2, job_id=543, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 11:02:43.624506+00:00, queued_by_job_id=276, pid=105900
2024-05-22 11:11:42,996 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:06:39.972142+00:00, run_end_date=2024-05-22 11:11:42.038988+00:00, run_duration=302.066846, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=544, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 11:02:43.624506+00:00, queued_by_job_id=276, pid=105924
2024-05-22 11:11:43,034 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 11:11:43,055 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-07 00:00:00+00:00, run_after=2023-09-08 00:00:00+00:00
2024-05-22 11:11:43,163 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-30 00:00:00+00:00: scheduled__2023-08-30T00:00:00+00:00, state:running, queued_at: 2024-05-22 10:16:00.153887+00:00. externally triggered: False> failed
2024-05-22 11:11:43,164 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-30 00:00:00+00:00, run_id=scheduled__2023-08-30T00:00:00+00:00, run_start_date=2024-05-22 10:16:00.171399+00:00, run_end_date=2024-05-22 11:11:43.164151+00:00, run_duration=3342.992752, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-30 00:00:00+00:00, data_interval_end=2023-08-31 00:00:00+00:00, dag_hash=5da7e4b8b73d828d414a8e76eba37643
2024-05-22 11:11:43,168 INFO - Setting next_dagrun for extract_311_data_dag to 2023-08-31 00:00:00+00:00, run_after=2023-09-01 00:00:00+00:00
2024-05-22 11:11:43,179 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-04T00:00:00+00:00 [scheduled]>
2024-05-22 11:11:43,179 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 11:11:43,179 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 11:11:43,180 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 11:11:43,180 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-04T00:00:00+00:00 [scheduled]>
2024-05-22 11:11:43,183 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 11:11:43,183 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:11:43,184 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 11:11:43,184 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:11:43,184 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 11:11:43,185 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:11:43,186 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:13:29,732 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:13:33,467 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:18:38,335 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:18:38,335 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:18:38,336 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:18:38,341 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:13:31.448293+00:00, run_end_date=2024-05-22 11:13:32.813343+00:00, run_duration=1.36505, state=success, executor_state=success, try_number=1, max_tries=2, job_id=546, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 11:11:43.181408+00:00, queued_by_job_id=276, pid=106208
2024-05-22 11:18:38,342 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:11:45.171984+00:00, run_end_date=2024-05-22 11:13:29.073580+00:00, run_duration=103.901596, state=success, executor_state=success, try_number=1, max_tries=2, job_id=545, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 11:11:43.181408+00:00, queued_by_job_id=276, pid=106125
2024-05-22 11:18:38,342 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:13:35.308215+00:00, run_end_date=2024-05-22 11:18:37.527621+00:00, run_duration=302.219406, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=547, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 11:11:43.181408+00:00, queued_by_job_id=276, pid=106232
2024-05-22 11:18:38,382 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 11:18:38,404 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-08 00:00:00+00:00, run_after=2023-09-09 00:00:00+00:00
2024-05-22 11:18:38,537 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-08-31 00:00:00+00:00: scheduled__2023-08-31T00:00:00+00:00, state:running, queued_at: 2024-05-22 10:24:54.652207+00:00. externally triggered: False> failed
2024-05-22 11:18:38,538 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-08-31 00:00:00+00:00, run_id=scheduled__2023-08-31T00:00:00+00:00, run_start_date=2024-05-22 10:24:54.666107+00:00, run_end_date=2024-05-22 11:18:38.537910+00:00, run_duration=3223.871803, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-08-31 00:00:00+00:00, data_interval_end=2023-09-01 00:00:00+00:00, dag_hash=ae3d699801db35fc5880a2ea4c4a045c
2024-05-22 11:18:38,544 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-01 00:00:00+00:00, run_after=2023-09-02 00:00:00+00:00
2024-05-22 11:18:38,561 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-05T00:00:00+00:00 [scheduled]>
2024-05-22 11:18:38,561 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 11:18:38,561 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 11:18:38,561 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 11:18:38,563 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-05T00:00:00+00:00 [scheduled]>
2024-05-22 11:18:38,566 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 11:18:38,567 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:18:38,568 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 11:18:38,569 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:18:38,569 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 11:18:38,570 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:18:38,571 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:19:33,421 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:19:37,202 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:24:41,547 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:24:41,548 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:24:41,548 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:24:41,570 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:18:40.762383+00:00, run_end_date=2024-05-22 11:19:32.714942+00:00, run_duration=51.952559, state=success, executor_state=success, try_number=1, max_tries=2, job_id=548, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 11:18:38.564663+00:00, queued_by_job_id=276, pid=106432
2024-05-22 11:24:41,571 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:19:38.887939+00:00, run_end_date=2024-05-22 11:24:40.912124+00:00, run_duration=302.024185, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=550, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 11:18:38.564663+00:00, queued_by_job_id=276, pid=106506
2024-05-22 11:24:41,571 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:19:35.343843+00:00, run_end_date=2024-05-22 11:19:36.592186+00:00, run_duration=1.248343, state=success, executor_state=success, try_number=1, max_tries=2, job_id=549, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 11:18:38.564663+00:00, queued_by_job_id=276, pid=106482
2024-05-22 11:24:41,608 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 11:24:41,629 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-09 00:00:00+00:00, run_after=2023-09-10 00:00:00+00:00
2024-05-22 11:24:41,725 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-01 00:00:00+00:00: scheduled__2023-09-01T00:00:00+00:00, state:running, queued_at: 2024-05-22 10:31:58.074741+00:00. externally triggered: False> failed
2024-05-22 11:24:41,726 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-01 00:00:00+00:00, run_id=scheduled__2023-09-01T00:00:00+00:00, run_start_date=2024-05-22 10:31:58.090838+00:00, run_end_date=2024-05-22 11:24:41.725957+00:00, run_duration=3163.635119, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-01 00:00:00+00:00, data_interval_end=2023-09-02 00:00:00+00:00, dag_hash=418a5fb0d3a32e56c95c16121ea7acf8
2024-05-22 11:24:41,729 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-02 00:00:00+00:00, run_after=2023-09-03 00:00:00+00:00
2024-05-22 11:24:41,738 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-06T00:00:00+00:00 [scheduled]>
2024-05-22 11:24:41,739 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 11:24:41,739 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 11:24:41,739 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 11:24:41,740 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-06T00:00:00+00:00 [scheduled]>
2024-05-22 11:24:41,742 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 11:24:41,742 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:24:41,742 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 11:24:41,743 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:24:41,743 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 11:24:41,743 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:24:41,744 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:27:12,146 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:27:16,196 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:32:20,900 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:32:20,901 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:32:20,901 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:32:20,906 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:27:14.111393+00:00, run_end_date=2024-05-22 11:27:15.517075+00:00, run_duration=1.405682, state=success, executor_state=success, try_number=1, max_tries=2, job_id=552, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 11:24:41.740785+00:00, queued_by_job_id=276, pid=106813
2024-05-22 11:32:20,906 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:27:18.231703+00:00, run_end_date=2024-05-22 11:32:20.183489+00:00, run_duration=301.951786, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=553, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 11:24:41.740785+00:00, queued_by_job_id=276, pid=106837
2024-05-22 11:32:20,907 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:24:43.826754+00:00, run_end_date=2024-05-22 11:27:11.502103+00:00, run_duration=147.675349, state=success, executor_state=success, try_number=1, max_tries=2, job_id=551, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 11:24:41.740785+00:00, queued_by_job_id=276, pid=106704
2024-05-22 11:32:20,945 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 11:32:20,966 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-10 00:00:00+00:00, run_after=2023-09-11 00:00:00+00:00
2024-05-22 11:32:21,068 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-02 00:00:00+00:00: scheduled__2023-09-02T00:00:00+00:00, state:running, queued_at: 2024-05-22 10:39:15.040398+00:00. externally triggered: False> failed
2024-05-22 11:32:21,069 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-02 00:00:00+00:00, run_id=scheduled__2023-09-02T00:00:00+00:00, run_start_date=2024-05-22 10:39:15.054823+00:00, run_end_date=2024-05-22 11:32:21.069155+00:00, run_duration=3186.014332, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-02 00:00:00+00:00, data_interval_end=2023-09-03 00:00:00+00:00, dag_hash=b2ddb983faa1ce09f2725670d7209a77
2024-05-22 11:32:21,072 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-03 00:00:00+00:00, run_after=2023-09-04 00:00:00+00:00
2024-05-22 11:32:21,087 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-07T00:00:00+00:00 [scheduled]>
2024-05-22 11:32:21,088 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 11:32:21,088 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 11:32:21,088 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 11:32:21,088 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-07T00:00:00+00:00 [scheduled]>
2024-05-22 11:32:21,091 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 11:32:21,091 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:32:21,091 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 11:32:21,092 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:32:21,092 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 11:32:21,092 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:32:21,094 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:34:01,424 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:34:05,222 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:39:10,008 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:39:10,009 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:39:10,010 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:39:10,034 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:34:07.149313+00:00, run_end_date=2024-05-22 11:39:09.248168+00:00, run_duration=302.098855, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=556, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 11:32:21.089601+00:00, queued_by_job_id=276, pid=107135
2024-05-22 11:39:10,035 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:32:23.031905+00:00, run_end_date=2024-05-22 11:34:00.703217+00:00, run_duration=97.671312, state=success, executor_state=success, try_number=1, max_tries=2, job_id=554, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 11:32:21.089601+00:00, queued_by_job_id=276, pid=107036
2024-05-22 11:39:10,035 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:34:03.427127+00:00, run_end_date=2024-05-22 11:34:04.561692+00:00, run_duration=1.134565, state=success, executor_state=success, try_number=1, max_tries=2, job_id=555, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 11:32:21.089601+00:00, queued_by_job_id=276, pid=107111
2024-05-22 11:39:10,075 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 11:39:10,107 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-11 00:00:00+00:00, run_after=2023-09-12 00:00:00+00:00
2024-05-22 11:39:10,266 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-03 00:00:00+00:00: scheduled__2023-09-03T00:00:00+00:00, state:running, queued_at: 2024-05-22 10:47:35.176433+00:00. externally triggered: False> failed
2024-05-22 11:39:10,267 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-03 00:00:00+00:00, run_id=scheduled__2023-09-03T00:00:00+00:00, run_start_date=2024-05-22 10:47:35.190921+00:00, run_end_date=2024-05-22 11:39:10.267077+00:00, run_duration=3095.076156, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-03 00:00:00+00:00, data_interval_end=2023-09-04 00:00:00+00:00, dag_hash=e004ff30fd4d50ea32ed59b9623b5501
2024-05-22 11:39:10,270 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-04 00:00:00+00:00, run_after=2023-09-05 00:00:00+00:00
2024-05-22 11:39:10,282 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-08T00:00:00+00:00 [scheduled]>
2024-05-22 11:39:10,283 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 11:39:10,283 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 11:39:10,284 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 11:39:10,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-08T00:00:00+00:00 [scheduled]>
2024-05-22 11:39:10,288 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 11:39:10,288 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:39:10,289 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 11:39:10,289 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:39:10,290 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 11:39:10,290 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:39:10,292 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:41:10,994 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:41:14,950 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:46:19,426 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:46:19,426 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:46:19,427 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:46:19,432 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:39:12.621613+00:00, run_end_date=2024-05-22 11:41:10.372873+00:00, run_duration=117.75126, state=success, executor_state=success, try_number=1, max_tries=2, job_id=557, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 11:39:10.285883+00:00, queued_by_job_id=276, pid=107335
2024-05-22 11:46:19,432 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:41:13.042687+00:00, run_end_date=2024-05-22 11:41:14.350437+00:00, run_duration=1.30775, state=success, executor_state=success, try_number=1, max_tries=2, job_id=558, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 11:39:10.285883+00:00, queued_by_job_id=276, pid=107426
2024-05-22 11:46:19,432 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:41:16.767371+00:00, run_end_date=2024-05-22 11:46:18.784115+00:00, run_duration=302.016744, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=559, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 11:39:10.285883+00:00, queued_by_job_id=276, pid=107450
2024-05-22 11:46:19,466 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 11:46:19,485 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-12 00:00:00+00:00, run_after=2023-09-13 00:00:00+00:00
2024-05-22 11:46:19,573 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-04 00:00:00+00:00: scheduled__2023-09-04T00:00:00+00:00, state:running, queued_at: 2024-05-22 10:55:14.331051+00:00. externally triggered: False> failed
2024-05-22 11:46:19,573 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-04 00:00:00+00:00, run_id=scheduled__2023-09-04T00:00:00+00:00, run_start_date=2024-05-22 10:55:14.344956+00:00, run_end_date=2024-05-22 11:46:19.573428+00:00, run_duration=3065.228472, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-04 00:00:00+00:00, data_interval_end=2023-09-05 00:00:00+00:00, dag_hash=92dfa6813d372d5d529934f17d725325
2024-05-22 11:46:19,577 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-05 00:00:00+00:00, run_after=2023-09-06 00:00:00+00:00
2024-05-22 11:46:19,587 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-09T00:00:00+00:00 [scheduled]>
2024-05-22 11:46:19,588 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 11:46:19,588 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 11:46:19,588 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 11:46:19,589 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-09T00:00:00+00:00 [scheduled]>
2024-05-22 11:46:19,592 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 11:46:19,592 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:46:19,593 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 11:46:19,593 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:46:19,593 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 11:46:19,594 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:46:19,595 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:49:01,415 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:49:05,426 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:54:10,135 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:54:10,135 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:54:10,135 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 11:54:10,140 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:46:21.275255+00:00, run_end_date=2024-05-22 11:49:00.801956+00:00, run_duration=159.526701, state=success, executor_state=success, try_number=1, max_tries=2, job_id=560, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 11:46:19.590497+00:00, queued_by_job_id=276, pid=107648
2024-05-22 11:54:10,141 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:49:03.392331+00:00, run_end_date=2024-05-22 11:49:04.762267+00:00, run_duration=1.369936, state=success, executor_state=success, try_number=1, max_tries=2, job_id=561, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 11:46:19.590497+00:00, queued_by_job_id=276, pid=107761
2024-05-22 11:54:10,141 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:49:07.500557+00:00, run_end_date=2024-05-22 11:54:09.465604+00:00, run_duration=301.965047, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=562, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 11:46:19.590497+00:00, queued_by_job_id=276, pid=107785
2024-05-22 11:54:10,175 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 11:54:10,194 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-13 00:00:00+00:00, run_after=2023-09-14 00:00:00+00:00
2024-05-22 11:54:10,295 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-05 00:00:00+00:00: scheduled__2023-09-05T00:00:00+00:00, state:running, queued_at: 2024-05-22 11:02:43.498472+00:00. externally triggered: False> failed
2024-05-22 11:54:10,296 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-05 00:00:00+00:00, run_id=scheduled__2023-09-05T00:00:00+00:00, run_start_date=2024-05-22 11:02:43.513483+00:00, run_end_date=2024-05-22 11:54:10.296063+00:00, run_duration=3086.78258, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-05 00:00:00+00:00, data_interval_end=2023-09-06 00:00:00+00:00, dag_hash=d9bb340dc288fe82a7832c31faed478f
2024-05-22 11:54:10,299 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-06 00:00:00+00:00, run_after=2023-09-07 00:00:00+00:00
2024-05-22 11:54:10,312 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-10T00:00:00+00:00 [scheduled]>
2024-05-22 11:54:10,312 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 11:54:10,312 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 11:54:10,312 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 11:54:10,313 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-10T00:00:00+00:00 [scheduled]>
2024-05-22 11:54:10,315 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 11:54:10,315 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:54:10,316 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 11:54:10,316 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:54:10,316 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 11:54:10,316 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:54:10,317 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:55:26,028 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 11:55:29,891 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:00:34,617 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:00:34,618 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:00:34,618 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:00:34,623 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:54:12.189306+00:00, run_end_date=2024-05-22 11:55:25.353783+00:00, run_duration=73.164477, state=success, executor_state=success, try_number=1, max_tries=2, job_id=563, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 11:54:10.313697+00:00, queued_by_job_id=276, pid=107986
2024-05-22 12:00:34,624 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:55:27.987999+00:00, run_end_date=2024-05-22 11:55:29.261811+00:00, run_duration=1.273812, state=success, executor_state=success, try_number=1, max_tries=2, job_id=564, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 11:54:10.313697+00:00, queued_by_job_id=276, pid=108048
2024-05-22 12:00:34,624 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 11:55:31.767048+00:00, run_end_date=2024-05-22 12:00:33.845792+00:00, run_duration=302.078744, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=565, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 11:54:10.313697+00:00, queued_by_job_id=276, pid=108073
2024-05-22 12:00:34,657 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:00:34,676 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-14 00:00:00+00:00, run_after=2023-09-15 00:00:00+00:00
2024-05-22 12:00:34,835 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-06 00:00:00+00:00: scheduled__2023-09-06T00:00:00+00:00, state:running, queued_at: 2024-05-22 11:11:43.047574+00:00. externally triggered: False> failed
2024-05-22 12:00:34,835 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-06 00:00:00+00:00, run_id=scheduled__2023-09-06T00:00:00+00:00, run_start_date=2024-05-22 11:11:43.062658+00:00, run_end_date=2024-05-22 12:00:34.835443+00:00, run_duration=2931.772785, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-06 00:00:00+00:00, data_interval_end=2023-09-07 00:00:00+00:00, dag_hash=929945f3f85556d52f82077cd1140651
2024-05-22 12:00:34,840 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-07 00:00:00+00:00, run_after=2023-09-08 00:00:00+00:00
2024-05-22 12:00:34,852 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-11T00:00:00+00:00 [scheduled]>
2024-05-22 12:00:34,853 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:00:34,853 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:00:34,853 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:00:34,853 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-11T00:00:00+00:00 [scheduled]>
2024-05-22 12:00:34,856 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:00:34,856 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:00:34,856 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:00:34,856 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:00:34,857 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:00:34,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:00:34,858 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:02:04,186 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:02:07,782 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:07:12,589 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:07:12,589 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:07:12,589 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:07:12,596 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:00:36.774030+00:00, run_end_date=2024-05-22 12:02:03.443181+00:00, run_duration=86.669151, state=success, executor_state=success, try_number=1, max_tries=2, job_id=566, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:00:34.854461+00:00, queued_by_job_id=276, pid=108271
2024-05-22 12:07:12,597 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:02:06.090368+00:00, run_end_date=2024-05-22 12:02:07.196648+00:00, run_duration=1.10628, state=success, executor_state=success, try_number=1, max_tries=2, job_id=567, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:00:34.854461+00:00, queued_by_job_id=276, pid=108341
2024-05-22 12:07:12,597 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:02:09.557507+00:00, run_end_date=2024-05-22 12:07:11.798131+00:00, run_duration=302.240624, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=568, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:00:34.854461+00:00, queued_by_job_id=276, pid=108365
2024-05-22 12:07:12,644 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:07:12,679 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-15 00:00:00+00:00, run_after=2023-09-16 00:00:00+00:00
2024-05-22 12:07:12,914 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-07 00:00:00+00:00: scheduled__2023-09-07T00:00:00+00:00, state:running, queued_at: 2024-05-22 11:18:38.397045+00:00. externally triggered: False> failed
2024-05-22 12:07:12,915 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-07 00:00:00+00:00, run_id=scheduled__2023-09-07T00:00:00+00:00, run_start_date=2024-05-22 11:18:38.414334+00:00, run_end_date=2024-05-22 12:07:12.915211+00:00, run_duration=2914.500877, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-07 00:00:00+00:00, data_interval_end=2023-09-08 00:00:00+00:00, dag_hash=2d845ef0177d1fa683b125eb1093c0a2
2024-05-22 12:07:12,927 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-08 00:00:00+00:00, run_after=2023-09-09 00:00:00+00:00
2024-05-22 12:07:12,942 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-12T00:00:00+00:00 [scheduled]>
2024-05-22 12:07:12,942 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:07:12,942 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:07:12,942 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:07:12,943 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-12T00:00:00+00:00 [scheduled]>
2024-05-22 12:07:12,945 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:07:12,946 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:07:12,946 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:07:12,946 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:07:12,946 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:07:12,947 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:07:12,948 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:08:59,053 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:09:03,503 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:14:08,198 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:14:08,199 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:14:08,199 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:14:08,219 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:07:15.435607+00:00, run_end_date=2024-05-22 12:08:58.430255+00:00, run_duration=102.994648, state=success, executor_state=success, try_number=1, max_tries=2, job_id=569, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:07:12.943803+00:00, queued_by_job_id=276, pid=108568
2024-05-22 12:14:08,220 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:09:01.307273+00:00, run_end_date=2024-05-22 12:09:02.863838+00:00, run_duration=1.556565, state=success, executor_state=success, try_number=1, max_tries=2, job_id=570, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:07:12.943803+00:00, queued_by_job_id=276, pid=108645
2024-05-22 12:14:08,220 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:09:05.409695+00:00, run_end_date=2024-05-22 12:14:07.419319+00:00, run_duration=302.009624, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=571, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:07:12.943803+00:00, queued_by_job_id=276, pid=108669
2024-05-22 12:14:08,256 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:14:08,286 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-16 00:00:00+00:00, run_after=2023-09-17 00:00:00+00:00
2024-05-22 12:14:08,391 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-08 00:00:00+00:00: scheduled__2023-09-08T00:00:00+00:00, state:running, queued_at: 2024-05-22 11:24:41.621852+00:00. externally triggered: False> failed
2024-05-22 12:14:08,392 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-08 00:00:00+00:00, run_id=scheduled__2023-09-08T00:00:00+00:00, run_start_date=2024-05-22 11:24:41.635485+00:00, run_end_date=2024-05-22 12:14:08.392264+00:00, run_duration=2966.756779, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-08 00:00:00+00:00, data_interval_end=2023-09-09 00:00:00+00:00, dag_hash=329de3e2a0f757d6609ae0ccf03abd1d
2024-05-22 12:14:08,395 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-09 00:00:00+00:00, run_after=2023-09-10 00:00:00+00:00
2024-05-22 12:14:08,406 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-13T00:00:00+00:00 [scheduled]>
2024-05-22 12:14:08,407 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:14:08,407 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:14:08,407 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:14:08,407 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-13T00:00:00+00:00 [scheduled]>
2024-05-22 12:14:08,410 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:14:08,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:14:08,411 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:14:08,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:14:08,411 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:14:08,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:14:08,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:18:23,236 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:18:27,104 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:23:31,328 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:23:31,329 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:23:31,329 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:23:31,334 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:18:24.990263+00:00, run_end_date=2024-05-22 12:18:26.214601+00:00, run_duration=1.224338, state=success, executor_state=success, try_number=1, max_tries=2, job_id=573, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:14:08.408260+00:00, queued_by_job_id=276, pid=109038
2024-05-22 12:23:31,335 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:14:10.357528+00:00, run_end_date=2024-05-22 12:18:22.440629+00:00, run_duration=252.083101, state=success, executor_state=success, try_number=1, max_tries=2, job_id=572, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:14:08.408260+00:00, queued_by_job_id=276, pid=108868
2024-05-22 12:23:31,335 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:18:28.820775+00:00, run_end_date=2024-05-22 12:23:30.703757+00:00, run_duration=301.882982, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=574, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:14:08.408260+00:00, queued_by_job_id=276, pid=109066
2024-05-22 12:23:31,367 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:23:31,385 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-17 00:00:00+00:00, run_after=2023-09-18 00:00:00+00:00
2024-05-22 12:23:31,473 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-09 00:00:00+00:00: scheduled__2023-09-09T00:00:00+00:00, state:running, queued_at: 2024-05-22 11:32:20.959296+00:00. externally triggered: False> failed
2024-05-22 12:23:31,474 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-09 00:00:00+00:00, run_id=scheduled__2023-09-09T00:00:00+00:00, run_start_date=2024-05-22 11:32:20.974373+00:00, run_end_date=2024-05-22 12:23:31.474308+00:00, run_duration=3070.499935, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-09 00:00:00+00:00, data_interval_end=2023-09-10 00:00:00+00:00, dag_hash=3ac6dc76cee9daae7ecc6581f96b24f4
2024-05-22 12:23:31,477 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-10 00:00:00+00:00, run_after=2023-09-11 00:00:00+00:00
2024-05-22 12:23:31,488 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-14T00:00:00+00:00 [scheduled]>
2024-05-22 12:23:31,488 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:23:31,489 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:23:31,489 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:23:31,489 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-14T00:00:00+00:00 [scheduled]>
2024-05-22 12:23:31,492 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:23:31,493 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:23:31,493 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:23:31,493 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:23:31,493 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:23:31,494 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:23:31,495 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:24:41,002 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:24:44,935 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:29:49,486 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:29:49,486 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:29:49,486 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:29:49,491 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:24:46.869328+00:00, run_end_date=2024-05-22 12:29:48.728599+00:00, run_duration=301.859271, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=577, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:23:31.491293+00:00, queued_by_job_id=276, pid=109354
2024-05-22 12:29:49,492 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:23:33.821609+00:00, run_end_date=2024-05-22 12:24:40.397714+00:00, run_duration=66.576105, state=success, executor_state=success, try_number=1, max_tries=2, job_id=575, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:23:31.491293+00:00, queued_by_job_id=276, pid=109274
2024-05-22 12:29:49,492 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:24:42.718972+00:00, run_end_date=2024-05-22 12:24:44.269825+00:00, run_duration=1.550853, state=success, executor_state=success, try_number=1, max_tries=2, job_id=576, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:23:31.491293+00:00, queued_by_job_id=276, pid=109330
2024-05-22 12:29:49,525 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:29:49,547 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-18 00:00:00+00:00, run_after=2023-09-19 00:00:00+00:00
2024-05-22 12:29:49,636 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-10 00:00:00+00:00: scheduled__2023-09-10T00:00:00+00:00, state:running, queued_at: 2024-05-22 11:39:10.096008+00:00. externally triggered: False> failed
2024-05-22 12:29:49,637 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-10 00:00:00+00:00, run_id=scheduled__2023-09-10T00:00:00+00:00, run_start_date=2024-05-22 11:39:10.117766+00:00, run_end_date=2024-05-22 12:29:49.637013+00:00, run_duration=3039.519247, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-10 00:00:00+00:00, data_interval_end=2023-09-11 00:00:00+00:00, dag_hash=12f5c464e86fcdd02047b5abc7d73b4c
2024-05-22 12:29:49,640 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-11 00:00:00+00:00, run_after=2023-09-12 00:00:00+00:00
2024-05-22 12:29:49,660 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-15T00:00:00+00:00 [scheduled]>
2024-05-22 12:29:49,660 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:29:49,661 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:29:49,661 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:29:49,661 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-15T00:00:00+00:00 [scheduled]>
2024-05-22 12:29:49,663 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:29:49,663 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:29:49,664 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:29:49,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:29:49,664 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:29:49,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:29:49,666 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:32:53,349 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:32:56,766 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:38:01,883 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:38:01,884 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:38:01,884 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:38:01,890 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:29:51.557125+00:00, run_end_date=2024-05-22 12:32:52.560416+00:00, run_duration=181.003291, state=success, executor_state=success, try_number=1, max_tries=2, job_id=578, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:29:49.662074+00:00, queued_by_job_id=276, pid=109554
2024-05-22 12:38:01,891 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:32:54.981818+00:00, run_end_date=2024-05-22 12:32:56.118115+00:00, run_duration=1.136297, state=success, executor_state=success, try_number=1, max_tries=2, job_id=579, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:29:49.662074+00:00, queued_by_job_id=276, pid=109681
2024-05-22 12:38:01,891 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:32:59.044427+00:00, run_end_date=2024-05-22 12:38:01.136171+00:00, run_duration=302.091744, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=580, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:29:49.662074+00:00, queued_by_job_id=276, pid=109705
2024-05-22 12:38:01,930 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:38:01,952 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-19 00:00:00+00:00, run_after=2023-09-20 00:00:00+00:00
2024-05-22 12:38:02,064 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-11 00:00:00+00:00: scheduled__2023-09-11T00:00:00+00:00, state:running, queued_at: 2024-05-22 11:46:19.479178+00:00. externally triggered: False> failed
2024-05-22 12:38:02,064 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-11 00:00:00+00:00, run_id=scheduled__2023-09-11T00:00:00+00:00, run_start_date=2024-05-22 11:46:19.492767+00:00, run_end_date=2024-05-22 12:38:02.064479+00:00, run_duration=3102.571712, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-11 00:00:00+00:00, data_interval_end=2023-09-12 00:00:00+00:00, dag_hash=079079925bf9e903b9a45752ad1fe320
2024-05-22 12:38:02,068 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-12 00:00:00+00:00, run_after=2023-09-13 00:00:00+00:00
2024-05-22 12:38:02,079 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-16T00:00:00+00:00 [scheduled]>
2024-05-22 12:38:02,079 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:38:02,079 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:38:02,079 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:38:02,080 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-16T00:00:00+00:00 [scheduled]>
2024-05-22 12:38:02,082 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:38:02,082 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:38:02,083 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:38:02,083 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:38:02,083 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:38:02,083 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:38:02,085 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:39:17,264 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:39:21,627 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:44:26,400 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:44:26,400 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:44:26,401 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:44:26,420 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:39:23.715209+00:00, run_end_date=2024-05-22 12:44:25.769894+00:00, run_duration=302.054685, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=583, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:38:02.081074+00:00, queued_by_job_id=276, pid=109990
2024-05-22 12:44:26,420 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:38:04.166754+00:00, run_end_date=2024-05-22 12:39:16.586826+00:00, run_duration=72.420072, state=success, executor_state=success, try_number=1, max_tries=2, job_id=581, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:38:02.081074+00:00, queued_by_job_id=276, pid=109903
2024-05-22 12:44:26,421 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:39:19.750794+00:00, run_end_date=2024-05-22 12:39:20.979053+00:00, run_duration=1.228259, state=success, executor_state=success, try_number=1, max_tries=2, job_id=582, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:38:02.081074+00:00, queued_by_job_id=276, pid=109966
2024-05-22 12:44:26,454 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:44:26,474 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-20 00:00:00+00:00, run_after=2023-09-21 00:00:00+00:00
2024-05-22 12:44:26,560 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-12 00:00:00+00:00: scheduled__2023-09-12T00:00:00+00:00, state:running, queued_at: 2024-05-22 11:54:10.187873+00:00. externally triggered: False> failed
2024-05-22 12:44:26,561 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-12 00:00:00+00:00, run_id=scheduled__2023-09-12T00:00:00+00:00, run_start_date=2024-05-22 11:54:10.201489+00:00, run_end_date=2024-05-22 12:44:26.560966+00:00, run_duration=3016.359477, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-12 00:00:00+00:00, data_interval_end=2023-09-13 00:00:00+00:00, dag_hash=02cf826eed0b9abd36bd42ed95ace21c
2024-05-22 12:44:26,564 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-13 00:00:00+00:00, run_after=2023-09-14 00:00:00+00:00
2024-05-22 12:44:26,573 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-17T00:00:00+00:00 [scheduled]>
2024-05-22 12:44:26,574 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:44:26,574 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:44:26,574 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:44:26,574 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-17T00:00:00+00:00 [scheduled]>
2024-05-22 12:44:26,576 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:44:26,576 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:44:26,577 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:44:26,577 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:44:26,577 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:44:26,577 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:44:26,579 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:45:23,817 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:45:27,500 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:50:31,868 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:50:31,869 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:50:31,869 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:50:31,874 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:44:28.336230+00:00, run_end_date=2024-05-22 12:45:23.250221+00:00, run_duration=54.913991, state=success, executor_state=success, try_number=1, max_tries=2, job_id=584, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:44:26.575210+00:00, queued_by_job_id=276, pid=110190
2024-05-22 12:50:31,874 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:45:25.419261+00:00, run_end_date=2024-05-22 12:45:26.536221+00:00, run_duration=1.11696, state=success, executor_state=success, try_number=1, max_tries=2, job_id=585, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:44:26.575210+00:00, queued_by_job_id=276, pid=110239
2024-05-22 12:50:31,874 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:45:29.316160+00:00, run_end_date=2024-05-22 12:50:31.254137+00:00, run_duration=301.937977, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=586, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:44:26.575210+00:00, queued_by_job_id=276, pid=110267
2024-05-22 12:50:31,906 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:50:31,925 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-21 00:00:00+00:00, run_after=2023-09-22 00:00:00+00:00
2024-05-22 12:50:32,022 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-13 00:00:00+00:00: scheduled__2023-09-13T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:00:34.670148+00:00. externally triggered: False> failed
2024-05-22 12:50:32,023 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-13 00:00:00+00:00, run_id=scheduled__2023-09-13T00:00:00+00:00, run_start_date=2024-05-22 12:00:34.683638+00:00, run_end_date=2024-05-22 12:50:32.023158+00:00, run_duration=2997.33952, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-13 00:00:00+00:00, data_interval_end=2023-09-14 00:00:00+00:00, dag_hash=a0c5bbbce386aeda47734a31d2086184
2024-05-22 12:50:32,027 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-14 00:00:00+00:00, run_after=2023-09-15 00:00:00+00:00
2024-05-22 12:50:32,037 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-18T00:00:00+00:00 [scheduled]>
2024-05-22 12:50:32,038 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:50:32,038 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:50:32,038 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:50:32,038 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-18T00:00:00+00:00 [scheduled]>
2024-05-22 12:50:32,040 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:50:32,041 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:50:32,041 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:50:32,041 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:50:32,041 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:50:32,042 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:50:32,043 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:51:28,533 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:51:32,456 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:56:37,942 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:56:37,942 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:56:37,943 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 12:56:37,948 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:50:34.312408+00:00, run_end_date=2024-05-22 12:51:27.855367+00:00, run_duration=53.542959, state=success, executor_state=success, try_number=1, max_tries=2, job_id=587, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:50:32.039266+00:00, queued_by_job_id=276, pid=110479
2024-05-22 12:56:37,948 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:51:30.548834+00:00, run_end_date=2024-05-22 12:51:31.816818+00:00, run_duration=1.267984, state=success, executor_state=success, try_number=1, max_tries=2, job_id=588, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:50:32.039266+00:00, queued_by_job_id=276, pid=110529
2024-05-22 12:56:37,949 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:51:35.023876+00:00, run_end_date=2024-05-22 12:56:37.025061+00:00, run_duration=302.001185, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=589, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:50:32.039266+00:00, queued_by_job_id=276, pid=110558
2024-05-22 12:56:37,990 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 12:56:38,019 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-22 00:00:00+00:00, run_after=2023-09-23 00:00:00+00:00
2024-05-22 12:56:38,208 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-14 00:00:00+00:00: scheduled__2023-09-14T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:07:12.667114+00:00. externally triggered: False> failed
2024-05-22 12:56:38,208 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-14 00:00:00+00:00, run_id=scheduled__2023-09-14T00:00:00+00:00, run_start_date=2024-05-22 12:07:12.693953+00:00, run_end_date=2024-05-22 12:56:38.208584+00:00, run_duration=2965.514631, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-14 00:00:00+00:00, data_interval_end=2023-09-15 00:00:00+00:00, dag_hash=cc23396c13931e7d4de29541aa394e09
2024-05-22 12:56:38,212 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-15 00:00:00+00:00, run_after=2023-09-16 00:00:00+00:00
2024-05-22 12:56:38,224 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-19T00:00:00+00:00 [scheduled]>
2024-05-22 12:56:38,224 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 12:56:38,224 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 12:56:38,224 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 12:56:38,225 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-19T00:00:00+00:00 [scheduled]>
2024-05-22 12:56:38,227 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 12:56:38,228 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:56:38,228 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 12:56:38,228 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:56:38,228 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 12:56:38,228 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:56:38,230 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:57:22,120 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 12:57:26,660 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:02:31,811 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:02:31,811 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:02:31,811 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:02:31,817 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:56:40.155462+00:00, run_end_date=2024-05-22 12:57:21.537935+00:00, run_duration=41.382473, state=success, executor_state=success, try_number=1, max_tries=2, job_id=590, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 12:56:38.225838+00:00, queued_by_job_id=276, pid=110752
2024-05-22 13:02:31,818 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:57:24.241051+00:00, run_end_date=2024-05-22 12:57:25.798229+00:00, run_duration=1.557178, state=success, executor_state=success, try_number=1, max_tries=2, job_id=591, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 12:56:38.225838+00:00, queued_by_job_id=276, pid=110797
2024-05-22 13:02:31,818 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 12:57:28.981889+00:00, run_end_date=2024-05-22 13:02:31.066878+00:00, run_duration=302.084989, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=592, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 12:56:38.225838+00:00, queued_by_job_id=276, pid=110821
2024-05-22 13:02:31,861 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:02:31,884 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-23 00:00:00+00:00, run_after=2023-09-24 00:00:00+00:00
2024-05-22 13:02:31,992 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-15 00:00:00+00:00: scheduled__2023-09-15T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:14:08.276918+00:00. externally triggered: False> failed
2024-05-22 13:02:31,992 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-15 00:00:00+00:00, run_id=scheduled__2023-09-15T00:00:00+00:00, run_start_date=2024-05-22 12:14:08.296365+00:00, run_end_date=2024-05-22 13:02:31.992499+00:00, run_duration=2903.696134, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-15 00:00:00+00:00, data_interval_end=2023-09-16 00:00:00+00:00, dag_hash=f19230a645997f9492453e60fd7ed96b
2024-05-22 13:02:31,996 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-16 00:00:00+00:00, run_after=2023-09-17 00:00:00+00:00
2024-05-22 13:02:32,009 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-20T00:00:00+00:00 [scheduled]>
2024-05-22 13:02:32,010 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:02:32,010 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:02:32,010 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:02:32,010 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-20T00:00:00+00:00 [scheduled]>
2024-05-22 13:02:32,013 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:02:32,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:02:32,014 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:02:32,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:02:32,014 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:02:32,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:02:32,016 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:03:56,547 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:04:00,372 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:09:04,981 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:09:04,981 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:09:04,981 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:09:04,987 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:03:58.439665+00:00, run_end_date=2024-05-22 13:03:59.627470+00:00, run_duration=1.187805, state=success, executor_state=success, try_number=1, max_tries=2, job_id=594, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:02:32.011158+00:00, queued_by_job_id=276, pid=111089
2024-05-22 13:09:04,987 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:02:34.348587+00:00, run_end_date=2024-05-22 13:03:55.891569+00:00, run_duration=81.542982, state=success, executor_state=success, try_number=1, max_tries=2, job_id=593, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:02:32.011158+00:00, queued_by_job_id=276, pid=111021
2024-05-22 13:09:04,987 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:04:02.182122+00:00, run_end_date=2024-05-22 13:09:04.314157+00:00, run_duration=302.132035, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=595, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:02:32.011158+00:00, queued_by_job_id=276, pid=111113
2024-05-22 13:09:05,022 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:09:05,042 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-24 00:00:00+00:00, run_after=2023-09-25 00:00:00+00:00
2024-05-22 13:09:05,134 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-16 00:00:00+00:00: scheduled__2023-09-16T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:23:31.379414+00:00. externally triggered: False> failed
2024-05-22 13:09:05,135 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-16 00:00:00+00:00, run_id=scheduled__2023-09-16T00:00:00+00:00, run_start_date=2024-05-22 12:23:31.392383+00:00, run_end_date=2024-05-22 13:09:05.135275+00:00, run_duration=2733.742892, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-16 00:00:00+00:00, data_interval_end=2023-09-17 00:00:00+00:00, dag_hash=33606ca2c16e4b4381cda0dcc2ab53ac
2024-05-22 13:09:05,138 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-17 00:00:00+00:00, run_after=2023-09-18 00:00:00+00:00
2024-05-22 13:09:05,148 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-21T00:00:00+00:00 [scheduled]>
2024-05-22 13:09:05,148 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:09:05,149 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:09:05,149 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:09:05,149 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-21T00:00:00+00:00 [scheduled]>
2024-05-22 13:09:05,151 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:09:05,151 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:09:05,152 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:09:05,152 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:09:05,152 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:09:05,152 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:09:05,153 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:13:08,746 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:13:12,496 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:18:17,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:18:17,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:18:17,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:18:17,564 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:13:14.763051+00:00, run_end_date=2024-05-22 13:18:16.938279+00:00, run_duration=302.175228, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=598, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:09:05.150044+00:00, queued_by_job_id=276, pid=111495
2024-05-22 13:18:17,565 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:13:10.513537+00:00, run_end_date=2024-05-22 13:13:11.789390+00:00, run_duration=1.275853, state=success, executor_state=success, try_number=1, max_tries=2, job_id=597, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:09:05.150044+00:00, queued_by_job_id=276, pid=111470
2024-05-22 13:18:17,565 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:09:07.254992+00:00, run_end_date=2024-05-22 13:13:08.114914+00:00, run_duration=240.859922, state=success, executor_state=success, try_number=1, max_tries=2, job_id=596, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:09:05.150044+00:00, queued_by_job_id=276, pid=111310
2024-05-22 13:18:17,600 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:18:17,622 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-25 00:00:00+00:00, run_after=2023-09-26 00:00:00+00:00
2024-05-22 13:18:17,715 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-17 00:00:00+00:00: scheduled__2023-09-17T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:29:49.541129+00:00. externally triggered: False> failed
2024-05-22 13:18:17,715 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-17 00:00:00+00:00, run_id=scheduled__2023-09-17T00:00:00+00:00, run_start_date=2024-05-22 12:29:49.554155+00:00, run_end_date=2024-05-22 13:18:17.715893+00:00, run_duration=2908.161738, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-17 00:00:00+00:00, data_interval_end=2023-09-18 00:00:00+00:00, dag_hash=b06bfde1100655dbe35e2009efb07444
2024-05-22 13:18:17,719 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-18 00:00:00+00:00, run_after=2023-09-19 00:00:00+00:00
2024-05-22 13:18:17,731 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-22T00:00:00+00:00 [scheduled]>
2024-05-22 13:18:17,731 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:18:17,732 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:18:17,732 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:18:17,732 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-22T00:00:00+00:00 [scheduled]>
2024-05-22 13:18:17,735 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:18:17,735 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:18:17,736 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:18:17,736 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:18:17,736 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:18:17,736 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:18:17,738 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:19:38,912 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:19:43,075 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:24:47,638 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:24:47,638 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:24:47,638 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:24:47,643 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:19:45.119513+00:00, run_end_date=2024-05-22 13:24:47.069386+00:00, run_duration=301.949873, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=601, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:18:17.733317+00:00, queued_by_job_id=276, pid=111787
2024-05-22 13:24:47,644 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:19:41.167458+00:00, run_end_date=2024-05-22 13:19:42.417584+00:00, run_duration=1.250126, state=success, executor_state=success, try_number=1, max_tries=2, job_id=600, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:18:17.733317+00:00, queued_by_job_id=276, pid=111763
2024-05-22 13:24:47,644 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:18:19.605406+00:00, run_end_date=2024-05-22 13:19:38.189324+00:00, run_duration=78.583918, state=success, executor_state=success, try_number=1, max_tries=2, job_id=599, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:18:17.733317+00:00, queued_by_job_id=276, pid=111698
2024-05-22 13:24:47,694 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:24:47,716 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-26 00:00:00+00:00, run_after=2023-09-27 00:00:00+00:00
2024-05-22 13:24:47,805 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-18 00:00:00+00:00: scheduled__2023-09-18T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:38:01.944908+00:00. externally triggered: False> failed
2024-05-22 13:24:47,806 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-18 00:00:00+00:00, run_id=scheduled__2023-09-18T00:00:00+00:00, run_start_date=2024-05-22 12:38:01.961471+00:00, run_end_date=2024-05-22 13:24:47.806081+00:00, run_duration=2805.84461, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-18 00:00:00+00:00, data_interval_end=2023-09-19 00:00:00+00:00, dag_hash=727c911ce68fbf73992da0902f703d53
2024-05-22 13:24:47,809 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-19 00:00:00+00:00, run_after=2023-09-20 00:00:00+00:00
2024-05-22 13:24:47,819 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-23T00:00:00+00:00 [scheduled]>
2024-05-22 13:24:47,819 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:24:47,820 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:24:47,820 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:24:47,820 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-23T00:00:00+00:00 [scheduled]>
2024-05-22 13:24:47,822 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:24:47,822 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:24:47,822 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:24:47,823 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:24:47,823 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:24:47,823 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:24:47,824 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:25:59,900 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:26:04,085 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:31:08,841 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:31:08,841 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:31:08,841 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:31:08,846 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:26:06.011555+00:00, run_end_date=2024-05-22 13:31:08.137375+00:00, run_duration=302.12582, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=604, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:24:47.820980+00:00, queued_by_job_id=276, pid=112069
2024-05-22 13:31:08,847 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:24:49.471065+00:00, run_end_date=2024-05-22 13:25:59.208167+00:00, run_duration=69.737102, state=success, executor_state=success, try_number=1, max_tries=2, job_id=602, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:24:47.820980+00:00, queued_by_job_id=276, pid=111985
2024-05-22 13:31:08,847 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:26:01.976941+00:00, run_end_date=2024-05-22 13:26:03.362555+00:00, run_duration=1.385614, state=success, executor_state=success, try_number=1, max_tries=2, job_id=603, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:24:47.820980+00:00, queued_by_job_id=276, pid=112045
2024-05-22 13:31:08,881 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:31:08,903 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-27 00:00:00+00:00, run_after=2023-09-28 00:00:00+00:00
2024-05-22 13:31:09,002 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-19 00:00:00+00:00: scheduled__2023-09-19T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:44:26.467589+00:00. externally triggered: False> failed
2024-05-22 13:31:09,002 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-19 00:00:00+00:00, run_id=scheduled__2023-09-19T00:00:00+00:00, run_start_date=2024-05-22 12:44:26.480690+00:00, run_end_date=2024-05-22 13:31:09.002944+00:00, run_duration=2802.522254, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-19 00:00:00+00:00, data_interval_end=2023-09-20 00:00:00+00:00, dag_hash=e0f191207bd3da36c38ee801c36884b8
2024-05-22 13:31:09,006 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-20 00:00:00+00:00, run_after=2023-09-21 00:00:00+00:00
2024-05-22 13:31:09,017 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-24T00:00:00+00:00 [scheduled]>
2024-05-22 13:31:09,018 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:31:09,018 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:31:09,018 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:31:09,018 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-24T00:00:00+00:00 [scheduled]>
2024-05-22 13:31:09,021 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:31:09,021 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:31:09,022 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:31:09,022 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:31:09,022 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:31:09,022 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:31:09,023 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:33:01,296 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:33:05,566 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:38:10,304 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:38:10,304 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:38:10,304 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:38:10,310 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:31:10.900579+00:00, run_end_date=2024-05-22 13:33:00.671859+00:00, run_duration=109.77128, state=success, executor_state=success, try_number=1, max_tries=2, job_id=605, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:31:09.019516+00:00, queued_by_job_id=276, pid=112268
2024-05-22 13:38:10,310 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:33:03.436218+00:00, run_end_date=2024-05-22 13:33:04.897358+00:00, run_duration=1.46114, state=success, executor_state=success, try_number=1, max_tries=2, job_id=606, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:31:09.019516+00:00, queued_by_job_id=276, pid=112352
2024-05-22 13:38:10,310 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:33:07.555142+00:00, run_end_date=2024-05-22 13:38:09.635366+00:00, run_duration=302.080224, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=607, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:31:09.019516+00:00, queued_by_job_id=276, pid=112376
2024-05-22 13:38:10,343 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:38:10,361 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-28 00:00:00+00:00, run_after=2023-09-29 00:00:00+00:00
2024-05-22 13:38:10,447 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-20 00:00:00+00:00: scheduled__2023-09-20T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:50:31.919009+00:00. externally triggered: False> failed
2024-05-22 13:38:10,448 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-20 00:00:00+00:00, run_id=scheduled__2023-09-20T00:00:00+00:00, run_start_date=2024-05-22 12:50:31.931653+00:00, run_end_date=2024-05-22 13:38:10.447968+00:00, run_duration=2858.516315, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-20 00:00:00+00:00, data_interval_end=2023-09-21 00:00:00+00:00, dag_hash=708bdba5ee18994dd1ce71dc0e15122a
2024-05-22 13:38:10,451 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-21 00:00:00+00:00, run_after=2023-09-22 00:00:00+00:00
2024-05-22 13:38:10,460 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-25T00:00:00+00:00 [scheduled]>
2024-05-22 13:38:10,461 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:38:10,461 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:38:10,461 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:38:10,461 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-25T00:00:00+00:00 [scheduled]>
2024-05-22 13:38:10,463 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:38:10,463 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:38:10,464 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:38:10,464 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:38:10,464 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:38:10,464 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:38:10,465 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:40:55,956 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:40:59,781 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:46:04,921 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:46:04,922 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:46:04,922 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:46:04,927 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:38:12.235345+00:00, run_end_date=2024-05-22 13:40:55.298528+00:00, run_duration=163.063183, state=success, executor_state=success, try_number=1, max_tries=2, job_id=608, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:38:10.462141+00:00, queued_by_job_id=276, pid=112574
2024-05-22 13:46:04,928 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:40:57.922288+00:00, run_end_date=2024-05-22 13:40:59.159594+00:00, run_duration=1.237306, state=success, executor_state=success, try_number=1, max_tries=2, job_id=609, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:38:10.462141+00:00, queued_by_job_id=276, pid=112688
2024-05-22 13:46:04,928 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:41:02.109188+00:00, run_end_date=2024-05-22 13:46:04.301311+00:00, run_duration=302.192123, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=610, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:38:10.462141+00:00, queued_by_job_id=276, pid=112712
2024-05-22 13:46:04,964 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:46:04,983 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-29 00:00:00+00:00, run_after=2023-09-30 00:00:00+00:00
2024-05-22 13:46:05,076 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-21 00:00:00+00:00: scheduled__2023-09-21T00:00:00+00:00, state:running, queued_at: 2024-05-22 12:56:38.011714+00:00. externally triggered: False> failed
2024-05-22 13:46:05,077 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-21 00:00:00+00:00, run_id=scheduled__2023-09-21T00:00:00+00:00, run_start_date=2024-05-22 12:56:38.028662+00:00, run_end_date=2024-05-22 13:46:05.077297+00:00, run_duration=2967.048635, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-21 00:00:00+00:00, data_interval_end=2023-09-22 00:00:00+00:00, dag_hash=793334edf7b60c1283ec0d188fbaaebc
2024-05-22 13:46:05,080 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-22 00:00:00+00:00, run_after=2023-09-23 00:00:00+00:00
2024-05-22 13:46:05,090 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-26T00:00:00+00:00 [scheduled]>
2024-05-22 13:46:05,091 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:46:05,091 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:46:05,091 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:46:05,091 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-26T00:00:00+00:00 [scheduled]>
2024-05-22 13:46:05,095 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:46:05,095 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:46:05,095 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:46:05,096 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:46:05,096 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:46:05,096 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:46:05,097 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:47:36,826 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:47:40,598 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:52:45,931 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:52:45,931 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:52:45,931 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:52:45,950 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:46:07.012770+00:00, run_end_date=2024-05-22 13:47:36.198851+00:00, run_duration=89.186081, state=success, executor_state=success, try_number=1, max_tries=2, job_id=611, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:46:05.093478+00:00, queued_by_job_id=276, pid=112910
2024-05-22 13:52:45,951 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:47:38.701587+00:00, run_end_date=2024-05-22 13:47:39.964063+00:00, run_duration=1.262476, state=success, executor_state=success, try_number=1, max_tries=2, job_id=612, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:46:05.093478+00:00, queued_by_job_id=276, pid=112982
2024-05-22 13:52:45,951 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:47:42.752285+00:00, run_end_date=2024-05-22 13:52:45.270082+00:00, run_duration=302.517797, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=613, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:46:05.093478+00:00, queued_by_job_id=276, pid=113006
2024-05-22 13:52:45,986 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:52:46,008 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-30 00:00:00+00:00, run_after=2023-10-01 00:00:00+00:00
2024-05-22 13:52:46,107 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-22 00:00:00+00:00: scheduled__2023-09-22T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:02:31.875771+00:00. externally triggered: False> failed
2024-05-22 13:52:46,107 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-22 00:00:00+00:00, run_id=scheduled__2023-09-22T00:00:00+00:00, run_start_date=2024-05-22 13:02:31.891557+00:00, run_end_date=2024-05-22 13:52:46.107422+00:00, run_duration=3014.215865, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-22 00:00:00+00:00, data_interval_end=2023-09-23 00:00:00+00:00, dag_hash=7f08504d40275d7b637c69a0a1e2f2f9
2024-05-22 13:52:46,110 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-23 00:00:00+00:00, run_after=2023-09-24 00:00:00+00:00
2024-05-22 13:52:46,121 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-27T00:00:00+00:00 [scheduled]>
2024-05-22 13:52:46,121 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:52:46,121 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:52:46,121 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:52:46,121 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-27T00:00:00+00:00 [scheduled]>
2024-05-22 13:52:46,125 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:52:46,125 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:52:46,126 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:52:46,126 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:52:46,126 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:52:46,126 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:52:46,128 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:54:00,468 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:54:04,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:59:08,749 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:59:08,749 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:59:08,749 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 13:59:08,761 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:52:48.037646+00:00, run_end_date=2024-05-22 13:53:59.747939+00:00, run_duration=71.710293, state=success, executor_state=success, try_number=1, max_tries=2, job_id=614, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:52:46.122600+00:00, queued_by_job_id=276, pid=113204
2024-05-22 13:59:08,761 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:54:02.323608+00:00, run_end_date=2024-05-22 13:54:03.720564+00:00, run_duration=1.396956, state=success, executor_state=success, try_number=1, max_tries=2, job_id=615, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:52:46.122600+00:00, queued_by_job_id=276, pid=113269
2024-05-22 13:59:08,761 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:54:06.118886+00:00, run_end_date=2024-05-22 13:59:08.156822+00:00, run_duration=302.037936, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=616, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:52:46.122600+00:00, queued_by_job_id=276, pid=113293
2024-05-22 13:59:08,826 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 13:59:08,844 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-01 00:00:00+00:00, run_after=2023-10-02 00:00:00+00:00
2024-05-22 13:59:08,931 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-23 00:00:00+00:00: scheduled__2023-09-23T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:09:05.035613+00:00. externally triggered: False> failed
2024-05-22 13:59:08,931 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-23 00:00:00+00:00, run_id=scheduled__2023-09-23T00:00:00+00:00, run_start_date=2024-05-22 13:09:05.050948+00:00, run_end_date=2024-05-22 13:59:08.931875+00:00, run_duration=3003.880927, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-23 00:00:00+00:00, data_interval_end=2023-09-24 00:00:00+00:00, dag_hash=42cc5ab6d6fa56d46c42a98542071148
2024-05-22 13:59:08,935 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-24 00:00:00+00:00, run_after=2023-09-25 00:00:00+00:00
2024-05-22 13:59:08,944 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-28T00:00:00+00:00 [scheduled]>
2024-05-22 13:59:08,945 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 13:59:08,945 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 13:59:08,945 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 13:59:08,945 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-09-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-28T00:00:00+00:00 [scheduled]>
2024-05-22 13:59:08,948 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 13:59:08,948 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:59:08,948 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 13:59:08,948 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:59:08,949 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 13:59:08,949 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 13:59:08,950 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:00:37,080 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:00:41,098 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:05:45,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-09-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:05:45,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:05:45,545 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:05:45,551 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-09-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 13:59:10.724193+00:00, run_end_date=2024-05-22 14:00:36.469918+00:00, run_duration=85.745725, state=success, executor_state=success, try_number=1, max_tries=2, job_id=617, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 13:59:08.946291+00:00, queued_by_job_id=276, pid=113505
2024-05-22 14:05:45,552 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:00:39.023165+00:00, run_end_date=2024-05-22 14:00:40.424394+00:00, run_duration=1.401229, state=success, executor_state=success, try_number=1, max_tries=2, job_id=618, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 13:59:08.946291+00:00, queued_by_job_id=276, pid=113582
2024-05-22 14:05:45,552 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:00:42.871989+00:00, run_end_date=2024-05-22 14:05:44.764224+00:00, run_duration=301.892235, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=619, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 13:59:08.946291+00:00, queued_by_job_id=276, pid=113606
2024-05-22 14:05:45,584 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:05:45,603 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-02 00:00:00+00:00, run_after=2023-10-03 00:00:00+00:00
2024-05-22 14:05:45,693 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-24 00:00:00+00:00: scheduled__2023-09-24T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:18:17.614557+00:00. externally triggered: False> failed
2024-05-22 14:05:45,693 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-24 00:00:00+00:00, run_id=scheduled__2023-09-24T00:00:00+00:00, run_start_date=2024-05-22 13:18:17.630389+00:00, run_end_date=2024-05-22 14:05:45.693572+00:00, run_duration=2848.063183, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-24 00:00:00+00:00, data_interval_end=2023-09-25 00:00:00+00:00, dag_hash=3bdb9ac73dccf72b76bd228bf9e5fe12
2024-05-22 14:05:45,697 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-25 00:00:00+00:00, run_after=2023-09-26 00:00:00+00:00
2024-05-22 14:05:45,706 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-29T00:00:00+00:00 [scheduled]>
2024-05-22 14:05:45,707 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:05:45,707 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:05:45,707 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:05:45,707 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-09-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-29T00:00:00+00:00 [scheduled]>
2024-05-22 14:05:45,709 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:05:45,709 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:05:45,710 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:05:45,710 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:05:45,710 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:05:45,710 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:05:45,711 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:07:11,086 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:07:14,778 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:12:18,972 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:12:18,972 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-09-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:12:18,972 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:12:18,977 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-09-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:07:12.800968+00:00, run_end_date=2024-05-22 14:07:14.140324+00:00, run_duration=1.339356, state=success, executor_state=success, try_number=1, max_tries=2, job_id=621, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:05:45.708203+00:00, queued_by_job_id=276, pid=113873
2024-05-22 14:12:18,978 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:07:16.534518+00:00, run_end_date=2024-05-22 14:12:18.361738+00:00, run_duration=301.82722, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=622, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:05:45.708203+00:00, queued_by_job_id=276, pid=113898
2024-05-22 14:12:18,978 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:05:47.630237+00:00, run_end_date=2024-05-22 14:07:10.522484+00:00, run_duration=82.892247, state=success, executor_state=success, try_number=1, max_tries=2, job_id=620, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:05:45.708203+00:00, queued_by_job_id=276, pid=113806
2024-05-22 14:12:19,011 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:12:19,032 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-03 00:00:00+00:00, run_after=2023-10-04 00:00:00+00:00
2024-05-22 14:12:19,119 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-25 00:00:00+00:00: scheduled__2023-09-25T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:24:47.709525+00:00. externally triggered: False> failed
2024-05-22 14:12:19,119 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-25 00:00:00+00:00, run_id=scheduled__2023-09-25T00:00:00+00:00, run_start_date=2024-05-22 13:24:47.722994+00:00, run_end_date=2024-05-22 14:12:19.119943+00:00, run_duration=2851.396949, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-25 00:00:00+00:00, data_interval_end=2023-09-26 00:00:00+00:00, dag_hash=db34a9cf94c71fa43c1a10f0b146ee21
2024-05-22 14:12:19,123 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-26 00:00:00+00:00, run_after=2023-09-27 00:00:00+00:00
2024-05-22 14:12:19,132 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-30T00:00:00+00:00 [scheduled]>
2024-05-22 14:12:19,133 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:12:19,133 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:12:19,133 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:12:19,133 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-09-30T00:00:00+00:00 [scheduled]>
2024-05-22 14:12:19,135 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:12:19,135 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:12:19,136 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:12:19,136 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:12:19,136 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:12:19,136 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:12:19,138 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:13:10,549 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:13:15,042 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:18:19,123 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:18:19,123 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:18:19,124 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-09-30T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:18:19,130 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-09-30T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:13:16.668483+00:00, run_end_date=2024-05-22 14:18:18.579854+00:00, run_duration=301.911371, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=625, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:12:19.134216+00:00, queued_by_job_id=276, pid=114170
2024-05-22 14:18:19,130 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:12:21.056004+00:00, run_end_date=2024-05-22 14:13:09.951066+00:00, run_duration=48.895062, state=success, executor_state=success, try_number=1, max_tries=2, job_id=623, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:12:19.134216+00:00, queued_by_job_id=276, pid=114097
2024-05-22 14:18:19,130 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:13:12.486831+00:00, run_end_date=2024-05-22 14:13:14.242591+00:00, run_duration=1.75576, state=success, executor_state=success, try_number=1, max_tries=2, job_id=624, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:12:19.134216+00:00, queued_by_job_id=276, pid=114140
2024-05-22 14:18:19,173 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:18:19,193 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-04 00:00:00+00:00, run_after=2023-10-05 00:00:00+00:00
2024-05-22 14:18:19,286 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-26 00:00:00+00:00: scheduled__2023-09-26T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:31:08.897010+00:00. externally triggered: False> failed
2024-05-22 14:18:19,287 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-26 00:00:00+00:00, run_id=scheduled__2023-09-26T00:00:00+00:00, run_start_date=2024-05-22 13:31:08.910986+00:00, run_end_date=2024-05-22 14:18:19.287070+00:00, run_duration=2830.376084, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-26 00:00:00+00:00, data_interval_end=2023-09-27 00:00:00+00:00, dag_hash=b47cb76ca1ab60316146ffb4eb520dd6
2024-05-22 14:18:19,290 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-27 00:00:00+00:00, run_after=2023-09-28 00:00:00+00:00
2024-05-22 14:18:19,299 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-01T00:00:00+00:00 [scheduled]>
2024-05-22 14:18:19,300 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:18:19,300 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:18:19,300 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:18:19,300 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-01T00:00:00+00:00 [scheduled]>
2024-05-22 14:18:19,302 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:18:19,303 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:18:19,303 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:18:19,303 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:18:19,303 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:18:19,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:18:19,305 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:20:54,154 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:20:57,834 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:26:02,448 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:26:02,450 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:26:02,451 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-01T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:26:02,473 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-01T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:20:59.764684+00:00, run_end_date=2024-05-22 14:26:01.777545+00:00, run_duration=302.012861, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=628, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:18:19.301407+00:00, queued_by_job_id=276, pid=114505
2024-05-22 14:26:02,473 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:18:21.014996+00:00, run_end_date=2024-05-22 14:20:53.360997+00:00, run_duration=152.346001, state=success, executor_state=success, try_number=1, max_tries=2, job_id=626, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:18:19.301407+00:00, queued_by_job_id=276, pid=114371
2024-05-22 14:26:02,474 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:20:55.922850+00:00, run_end_date=2024-05-22 14:20:57.174987+00:00, run_duration=1.252137, state=success, executor_state=success, try_number=1, max_tries=2, job_id=627, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:18:19.301407+00:00, queued_by_job_id=276, pid=114481
2024-05-22 14:26:02,512 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:26:02,537 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-05 00:00:00+00:00, run_after=2023-10-06 00:00:00+00:00
2024-05-22 14:26:02,644 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-27 00:00:00+00:00: scheduled__2023-09-27T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:38:10.355946+00:00. externally triggered: False> failed
2024-05-22 14:26:02,645 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-27 00:00:00+00:00, run_id=scheduled__2023-09-27T00:00:00+00:00, run_start_date=2024-05-22 13:38:10.369273+00:00, run_end_date=2024-05-22 14:26:02.645077+00:00, run_duration=2872.275804, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 00:00:00+00:00, data_interval_end=2023-09-28 00:00:00+00:00, dag_hash=5013834a4381abe1ea0b40f8abaafedc
2024-05-22 14:26:02,648 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-28 00:00:00+00:00, run_after=2023-09-29 00:00:00+00:00
2024-05-22 14:26:02,660 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-02T00:00:00+00:00 [scheduled]>
2024-05-22 14:26:02,660 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:26:02,660 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:26:02,661 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:26:02,661 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-02T00:00:00+00:00 [scheduled]>
2024-05-22 14:26:02,663 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:26:02,663 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:26:02,664 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:26:02,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:26:02,664 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:26:02,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:26:02,666 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:26:55,002 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:26:58,849 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:32:03,501 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:32:03,501 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:32:03,501 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-02T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:32:03,508 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:26:04.662412+00:00, run_end_date=2024-05-22 14:26:54.356643+00:00, run_duration=49.694231, state=success, executor_state=success, try_number=1, max_tries=2, job_id=629, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:26:02.661881+00:00, queued_by_job_id=276, pid=114704
2024-05-22 14:32:03,509 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:26:57.017369+00:00, run_end_date=2024-05-22 14:26:58.221906+00:00, run_duration=1.204537, state=success, executor_state=success, try_number=1, max_tries=2, job_id=630, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:26:02.661881+00:00, queued_by_job_id=276, pid=114752
2024-05-22 14:32:03,509 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-02T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:27:00.578415+00:00, run_end_date=2024-05-22 14:32:02.693457+00:00, run_duration=302.115042, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=631, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:26:02.661881+00:00, queued_by_job_id=276, pid=114776
2024-05-22 14:32:03,548 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:32:03,585 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-06 00:00:00+00:00, run_after=2023-10-07 00:00:00+00:00
2024-05-22 14:32:03,805 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-28 00:00:00+00:00: scheduled__2023-09-28T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:46:04.977194+00:00. externally triggered: False> failed
2024-05-22 14:32:03,806 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-28 00:00:00+00:00, run_id=scheduled__2023-09-28T00:00:00+00:00, run_start_date=2024-05-22 13:46:04.990949+00:00, run_end_date=2024-05-22 14:32:03.806025+00:00, run_duration=2758.815076, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-28 00:00:00+00:00, data_interval_end=2023-09-29 00:00:00+00:00, dag_hash=de273602226fa001d9f3797e9fbd91c9
2024-05-22 14:32:03,810 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-29 00:00:00+00:00, run_after=2023-09-30 00:00:00+00:00
2024-05-22 14:32:03,824 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-03T00:00:00+00:00 [scheduled]>
2024-05-22 14:32:03,825 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:32:03,826 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:32:03,826 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:32:03,826 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-03T00:00:00+00:00 [scheduled]>
2024-05-22 14:32:03,829 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:32:03,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:32:03,829 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:32:03,830 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:32:03,830 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:32:03,830 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:32:03,832 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:32:56,507 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:33:00,085 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:38:05,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:38:05,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:38:05,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-03T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:38:05,310 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:32:05.859241+00:00, run_end_date=2024-05-22 14:32:55.910953+00:00, run_duration=50.051712, state=success, executor_state=success, try_number=1, max_tries=2, job_id=632, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:32:03.827615+00:00, queued_by_job_id=276, pid=114975
2024-05-22 14:38:05,310 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:32:58.242628+00:00, run_end_date=2024-05-22 14:32:59.464533+00:00, run_duration=1.221905, state=success, executor_state=success, try_number=1, max_tries=2, job_id=633, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:32:03.827615+00:00, queued_by_job_id=276, pid=115019
2024-05-22 14:38:05,311 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-03T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:33:02.174201+00:00, run_end_date=2024-05-22 14:38:04.383090+00:00, run_duration=302.208889, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=634, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:32:03.827615+00:00, queued_by_job_id=276, pid=115047
2024-05-22 14:38:05,343 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:38:05,361 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-07 00:00:00+00:00, run_after=2023-10-08 00:00:00+00:00
2024-05-22 14:38:05,454 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-29 00:00:00+00:00: scheduled__2023-09-29T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:52:45.999910+00:00. externally triggered: False> failed
2024-05-22 14:38:05,455 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-29 00:00:00+00:00, run_id=scheduled__2023-09-29T00:00:00+00:00, run_start_date=2024-05-22 13:52:46.017064+00:00, run_end_date=2024-05-22 14:38:05.455352+00:00, run_duration=2719.438288, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-29 00:00:00+00:00, data_interval_end=2023-09-30 00:00:00+00:00, dag_hash=ac1aa2c0778b52e398f176e6e14cbcd7
2024-05-22 14:38:05,459 INFO - Setting next_dagrun for extract_311_data_dag to 2023-09-30 00:00:00+00:00, run_after=2023-10-01 00:00:00+00:00
2024-05-22 14:38:05,483 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-04T00:00:00+00:00 [scheduled]>
2024-05-22 14:38:05,484 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:38:05,485 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:38:05,485 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:38:05,485 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-04T00:00:00+00:00 [scheduled]>
2024-05-22 14:38:05,493 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:38:05,494 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:38:05,494 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:38:05,494 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:38:05,496 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:38:05,496 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:38:05,498 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:39:50,602 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:39:54,862 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:44:59,724 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:44:59,725 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:44:59,725 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-04T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:44:59,730 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:38:07.630651+00:00, run_end_date=2024-05-22 14:39:49.928554+00:00, run_duration=102.297903, state=success, executor_state=success, try_number=1, max_tries=2, job_id=635, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:38:05.490400+00:00, queued_by_job_id=276, pid=115246
2024-05-22 14:44:59,730 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:39:52.741439+00:00, run_end_date=2024-05-22 14:39:54.157269+00:00, run_duration=1.41583, state=success, executor_state=success, try_number=1, max_tries=2, job_id=636, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:38:05.490400+00:00, queued_by_job_id=276, pid=115322
2024-05-22 14:44:59,731 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-04T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:39:56.872039+00:00, run_end_date=2024-05-22 14:44:59.069044+00:00, run_duration=302.197005, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=637, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:38:05.490400+00:00, queued_by_job_id=276, pid=115347
2024-05-22 14:44:59,764 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:44:59,783 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-08 00:00:00+00:00, run_after=2023-10-09 00:00:00+00:00
2024-05-22 14:44:59,881 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-09-30 00:00:00+00:00: scheduled__2023-09-30T00:00:00+00:00, state:running, queued_at: 2024-05-22 13:59:08.838343+00:00. externally triggered: False> failed
2024-05-22 14:44:59,881 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-09-30 00:00:00+00:00, run_id=scheduled__2023-09-30T00:00:00+00:00, run_start_date=2024-05-22 13:59:08.851916+00:00, run_end_date=2024-05-22 14:44:59.881560+00:00, run_duration=2751.029644, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-30 00:00:00+00:00, data_interval_end=2023-10-01 00:00:00+00:00, dag_hash=1b8110d30be17615382ea5b8c015b219
2024-05-22 14:44:59,884 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-01 00:00:00+00:00, run_after=2023-10-02 00:00:00+00:00
2024-05-22 14:44:59,895 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-05T00:00:00+00:00 [scheduled]>
2024-05-22 14:44:59,895 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:44:59,895 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:44:59,896 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:44:59,896 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-05T00:00:00+00:00 [scheduled]>
2024-05-22 14:44:59,898 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:44:59,898 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:44:59,899 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:44:59,899 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:44:59,899 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:44:59,899 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:44:59,901 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:46:16,782 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:46:20,824 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:51:25,725 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:51:25,726 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:51:25,726 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-05T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:51:25,731 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:45:01.895835+00:00, run_end_date=2024-05-22 14:46:16.092245+00:00, run_duration=74.19641, state=success, executor_state=success, try_number=1, max_tries=2, job_id=638, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:44:59.897097+00:00, queued_by_job_id=276, pid=115549
2024-05-22 14:51:25,731 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:46:18.803805+00:00, run_end_date=2024-05-22 14:46:20.129799+00:00, run_duration=1.325994, state=success, executor_state=success, try_number=1, max_tries=2, job_id=639, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:44:59.897097+00:00, queued_by_job_id=276, pid=115612
2024-05-22 14:51:25,731 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-05T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:46:22.860706+00:00, run_end_date=2024-05-22 14:51:25.106888+00:00, run_duration=302.246182, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=640, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:44:59.897097+00:00, queued_by_job_id=276, pid=115636
2024-05-22 14:51:25,763 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:51:25,781 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-09 00:00:00+00:00, run_after=2023-10-10 00:00:00+00:00
2024-05-22 14:51:25,865 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-01 00:00:00+00:00: scheduled__2023-10-01T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:05:45.597232+00:00. externally triggered: False> failed
2024-05-22 14:51:25,866 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-01 00:00:00+00:00, run_id=scheduled__2023-10-01T00:00:00+00:00, run_start_date=2024-05-22 14:05:45.610302+00:00, run_end_date=2024-05-22 14:51:25.866045+00:00, run_duration=2740.255743, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-01 00:00:00+00:00, data_interval_end=2023-10-02 00:00:00+00:00, dag_hash=2f2ecacaa3fe65ca0fd85da27fcdc732
2024-05-22 14:51:25,869 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-02 00:00:00+00:00, run_after=2023-10-03 00:00:00+00:00
2024-05-22 14:51:25,879 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-06T00:00:00+00:00 [scheduled]>
2024-05-22 14:51:25,879 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:51:25,879 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:51:25,879 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:51:25,880 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-06T00:00:00+00:00 [scheduled]>
2024-05-22 14:51:25,882 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:51:25,882 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:51:25,882 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:51:25,882 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:51:25,883 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:51:25,883 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:51:25,884 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:52:34,427 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:52:37,835 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:57:42,000 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:57:42,000 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:57:42,001 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-06T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 14:57:42,021 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:52:36.158217+00:00, run_end_date=2024-05-22 14:52:37.268755+00:00, run_duration=1.110538, state=success, executor_state=success, try_number=1, max_tries=2, job_id=642, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:51:25.880655+00:00, queued_by_job_id=276, pid=115890
2024-05-22 14:57:42,022 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:51:27.466566+00:00, run_end_date=2024-05-22 14:52:33.708465+00:00, run_duration=66.241899, state=success, executor_state=success, try_number=1, max_tries=2, job_id=641, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:51:25.880655+00:00, queued_by_job_id=276, pid=115833
2024-05-22 14:57:42,022 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-06T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:52:39.522379+00:00, run_end_date=2024-05-22 14:57:41.401794+00:00, run_duration=301.879415, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=643, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:51:25.880655+00:00, queued_by_job_id=276, pid=115914
2024-05-22 14:57:42,056 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 14:57:42,076 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-10 00:00:00+00:00, run_after=2023-10-11 00:00:00+00:00
2024-05-22 14:57:42,173 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-02 00:00:00+00:00: scheduled__2023-10-02T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:12:19.025694+00:00. externally triggered: False> failed
2024-05-22 14:57:42,173 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-02 00:00:00+00:00, run_id=scheduled__2023-10-02T00:00:00+00:00, run_start_date=2024-05-22 14:12:19.039509+00:00, run_end_date=2024-05-22 14:57:42.173368+00:00, run_duration=2723.133859, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-02 00:00:00+00:00, data_interval_end=2023-10-03 00:00:00+00:00, dag_hash=268d9e7943f25188f8e016dfeae8f53b
2024-05-22 14:57:42,176 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-03 00:00:00+00:00, run_after=2023-10-04 00:00:00+00:00
2024-05-22 14:57:42,190 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-07T00:00:00+00:00 [scheduled]>
2024-05-22 14:57:42,190 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 14:57:42,190 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 14:57:42,190 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 14:57:42,191 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-07T00:00:00+00:00 [scheduled]>
2024-05-22 14:57:42,193 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 14:57:42,193 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:57:42,193 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 14:57:42,194 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:57:42,194 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 14:57:42,194 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:57:42,195 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:59:02,550 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 14:59:06,565 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:04:11,156 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:04:11,156 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:04:11,157 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-07T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:04:11,181 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-07T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:59:08.396495+00:00, run_end_date=2024-05-22 15:04:10.491747+00:00, run_duration=302.095252, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=646, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 14:57:42.191757+00:00, queued_by_job_id=276, pid=116218
2024-05-22 15:04:11,185 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:59:04.851063+00:00, run_end_date=2024-05-22 14:59:05.926821+00:00, run_duration=1.075758, state=success, executor_state=success, try_number=1, max_tries=2, job_id=645, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 14:57:42.191757+00:00, queued_by_job_id=276, pid=116194
2024-05-22 15:04:11,186 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 14:57:44.271090+00:00, run_end_date=2024-05-22 14:59:01.862470+00:00, run_duration=77.59138, state=success, executor_state=success, try_number=1, max_tries=2, job_id=644, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 14:57:42.191757+00:00, queued_by_job_id=276, pid=116128
2024-05-22 15:04:11,226 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:04:11,247 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-11 00:00:00+00:00, run_after=2023-10-12 00:00:00+00:00
2024-05-22 15:04:11,340 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-03 00:00:00+00:00: scheduled__2023-10-03T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:18:19.186149+00:00. externally triggered: False> failed
2024-05-22 15:04:11,340 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-03 00:00:00+00:00, run_id=scheduled__2023-10-03T00:00:00+00:00, run_start_date=2024-05-22 14:18:19.206139+00:00, run_end_date=2024-05-22 15:04:11.340520+00:00, run_duration=2752.134381, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-03 00:00:00+00:00, data_interval_end=2023-10-04 00:00:00+00:00, dag_hash=2544f1dce0f608aec441bf6faaa54bbb
2024-05-22 15:04:11,343 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-04 00:00:00+00:00, run_after=2023-10-05 00:00:00+00:00
2024-05-22 15:04:11,354 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-08T00:00:00+00:00 [scheduled]>
2024-05-22 15:04:11,355 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:04:11,355 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:04:11,355 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:04:11,355 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-08T00:00:00+00:00 [scheduled]>
2024-05-22 15:04:11,358 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:04:11,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:04:11,358 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:04:11,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:04:11,359 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:04:11,359 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:04:11,360 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:05:07,544 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:05:11,111 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:10:15,773 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:10:15,773 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:10:15,774 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-08T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:10:15,779 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-08T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:05:12.948138+00:00, run_end_date=2024-05-22 15:10:15.073917+00:00, run_duration=302.125779, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=649, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:04:11.356406+00:00, queued_by_job_id=276, pid=116498
2024-05-22 15:10:15,779 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:04:13.260329+00:00, run_end_date=2024-05-22 15:05:06.878560+00:00, run_duration=53.618231, state=success, executor_state=success, try_number=1, max_tries=2, job_id=647, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:04:11.356406+00:00, queued_by_job_id=276, pid=116421
2024-05-22 15:10:15,780 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:05:09.325585+00:00, run_end_date=2024-05-22 15:05:10.510988+00:00, run_duration=1.185403, state=success, executor_state=success, try_number=1, max_tries=2, job_id=648, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:04:11.356406+00:00, queued_by_job_id=276, pid=116474
2024-05-22 15:10:15,817 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:10:15,840 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-12 00:00:00+00:00, run_after=2023-10-13 00:00:00+00:00
2024-05-22 15:10:15,997 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-04 00:00:00+00:00: scheduled__2023-10-04T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:26:02.528239+00:00. externally triggered: False> failed
2024-05-22 15:10:15,998 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-04 00:00:00+00:00, run_id=scheduled__2023-10-04T00:00:00+00:00, run_start_date=2024-05-22 14:26:02.546355+00:00, run_end_date=2024-05-22 15:10:15.998222+00:00, run_duration=2653.451867, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-04 00:00:00+00:00, data_interval_end=2023-10-05 00:00:00+00:00, dag_hash=077f6fcd18b2b7ea4c0356a34d479ac3
2024-05-22 15:10:16,002 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-05 00:00:00+00:00, run_after=2023-10-06 00:00:00+00:00
2024-05-22 15:10:16,016 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-09T00:00:00+00:00 [scheduled]>
2024-05-22 15:10:16,017 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:10:16,017 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:10:16,017 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:10:16,017 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-09T00:00:00+00:00 [scheduled]>
2024-05-22 15:10:16,020 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:10:16,020 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:10:16,021 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:10:16,021 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:10:16,021 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:10:16,022 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:10:16,023 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:11:44,281 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:11:47,872 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:16:52,753 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:16:52,753 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:16:52,753 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-09T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:16:52,760 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:11:46.117326+00:00, run_end_date=2024-05-22 15:11:47.226418+00:00, run_duration=1.109092, state=success, executor_state=success, try_number=1, max_tries=2, job_id=651, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:10:16.018606+00:00, queued_by_job_id=276, pid=116766
2024-05-22 15:16:52,760 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-09T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:11:49.843429+00:00, run_end_date=2024-05-22 15:16:51.974448+00:00, run_duration=302.131019, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=652, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:10:16.018606+00:00, queued_by_job_id=276, pid=116790
2024-05-22 15:16:52,760 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:10:17.929085+00:00, run_end_date=2024-05-22 15:11:43.484702+00:00, run_duration=85.555617, state=success, executor_state=success, try_number=1, max_tries=2, job_id=650, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:10:16.018606+00:00, queued_by_job_id=276, pid=116699
2024-05-22 15:16:52,805 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:16:52,830 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-13 00:00:00+00:00, run_after=2023-10-14 00:00:00+00:00
2024-05-22 15:16:52,943 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-05 00:00:00+00:00: scheduled__2023-10-05T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:32:03.571896+00:00. externally triggered: False> failed
2024-05-22 15:16:52,943 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-05 00:00:00+00:00, run_id=scheduled__2023-10-05T00:00:00+00:00, run_start_date=2024-05-22 14:32:03.611699+00:00, run_end_date=2024-05-22 15:16:52.943839+00:00, run_duration=2689.33214, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-05 00:00:00+00:00, data_interval_end=2023-10-06 00:00:00+00:00, dag_hash=1a0ebebc8261ac5be1f39d170dd1bcec
2024-05-22 15:16:52,948 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-06 00:00:00+00:00, run_after=2023-10-07 00:00:00+00:00
2024-05-22 15:16:52,961 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-10T00:00:00+00:00 [scheduled]>
2024-05-22 15:16:52,961 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:16:52,961 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:16:52,962 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:16:52,962 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-10T00:00:00+00:00 [scheduled]>
2024-05-22 15:16:52,964 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:16:52,965 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:16:52,965 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:16:52,965 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:16:52,966 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:16:52,966 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:16:52,967 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:17:39,783 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:17:43,781 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:22:48,929 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:22:48,929 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:22:48,929 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-10T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:22:48,935 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:17:41.815859+00:00, run_end_date=2024-05-22 15:17:43.101210+00:00, run_duration=1.285351, state=success, executor_state=success, try_number=1, max_tries=2, job_id=654, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:16:52.962870+00:00, queued_by_job_id=276, pid=117037
2024-05-22 15:22:48,935 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:16:55.206506+00:00, run_end_date=2024-05-22 15:17:39.136283+00:00, run_duration=43.929777, state=success, executor_state=success, try_number=1, max_tries=2, job_id=653, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:16:52.962870+00:00, queued_by_job_id=276, pid=116989
2024-05-22 15:22:48,936 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-10T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:17:46.151177+00:00, run_end_date=2024-05-22 15:22:48.212660+00:00, run_duration=302.061483, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=655, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:16:52.962870+00:00, queued_by_job_id=276, pid=117061
2024-05-22 15:22:48,971 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:22:48,995 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-14 00:00:00+00:00, run_after=2023-10-15 00:00:00+00:00
2024-05-22 15:22:49,094 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-06 00:00:00+00:00: scheduled__2023-10-06T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:38:05.355032+00:00. externally triggered: False> failed
2024-05-22 15:22:49,095 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-06 00:00:00+00:00, run_id=scheduled__2023-10-06T00:00:00+00:00, run_start_date=2024-05-22 14:38:05.368575+00:00, run_end_date=2024-05-22 15:22:49.095112+00:00, run_duration=2683.726537, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-06 00:00:00+00:00, data_interval_end=2023-10-07 00:00:00+00:00, dag_hash=c63b40171d32cb80a5b2bdc08d3559d9
2024-05-22 15:22:49,098 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-07 00:00:00+00:00, run_after=2023-10-08 00:00:00+00:00
2024-05-22 15:22:49,109 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-11T00:00:00+00:00 [scheduled]>
2024-05-22 15:22:49,109 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:22:49,109 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:22:49,110 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:22:49,110 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-11T00:00:00+00:00 [scheduled]>
2024-05-22 15:22:49,112 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:22:49,112 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:22:49,113 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:22:49,113 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:22:49,113 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:22:49,113 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:22:49,115 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:23:43,445 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:23:47,677 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:28:52,095 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:28:52,096 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:28:52,096 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-11T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:28:52,118 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:22:50.945733+00:00, run_end_date=2024-05-22 15:23:42.862413+00:00, run_duration=51.91668, state=success, executor_state=success, try_number=1, max_tries=2, job_id=656, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:22:49.110917+00:00, queued_by_job_id=276, pid=117259
2024-05-22 15:28:52,119 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:23:45.828466+00:00, run_end_date=2024-05-22 15:23:47.062052+00:00, run_duration=1.233586, state=success, executor_state=success, try_number=1, max_tries=2, job_id=657, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:22:49.110917+00:00, queued_by_job_id=276, pid=117310
2024-05-22 15:28:52,119 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-11T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:23:49.617494+00:00, run_end_date=2024-05-22 15:28:51.406009+00:00, run_duration=301.788515, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=658, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:22:49.110917+00:00, queued_by_job_id=276, pid=117334
2024-05-22 15:28:52,157 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:28:52,182 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-15 00:00:00+00:00, run_after=2023-10-16 00:00:00+00:00
2024-05-22 15:28:52,305 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-07 00:00:00+00:00: scheduled__2023-10-07T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:44:59.777588+00:00. externally triggered: False> failed
2024-05-22 15:28:52,306 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-07 00:00:00+00:00, run_id=scheduled__2023-10-07T00:00:00+00:00, run_start_date=2024-05-22 14:44:59.791481+00:00, run_end_date=2024-05-22 15:28:52.306304+00:00, run_duration=2632.514823, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-07 00:00:00+00:00, data_interval_end=2023-10-08 00:00:00+00:00, dag_hash=62af1c81d81c7cd5fb4a5e62b4fb97f2
2024-05-22 15:28:52,311 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-08 00:00:00+00:00, run_after=2023-10-09 00:00:00+00:00
2024-05-22 15:28:52,324 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-12T00:00:00+00:00 [scheduled]>
2024-05-22 15:28:52,325 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:28:52,325 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:28:52,325 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:28:52,325 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-12T00:00:00+00:00 [scheduled]>
2024-05-22 15:28:52,328 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:28:52,328 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:28:52,328 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:28:52,329 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:28:52,329 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:28:52,329 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:28:52,331 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:30:07,957 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:30:11,870 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:35:16,286 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:35:16,286 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:35:16,287 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-12T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:35:16,291 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:28:54.525794+00:00, run_end_date=2024-05-22 15:30:07.334786+00:00, run_duration=72.808992, state=success, executor_state=success, try_number=1, max_tries=2, job_id=659, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:28:52.326557+00:00, queued_by_job_id=276, pid=117532
2024-05-22 15:35:16,292 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:30:09.790270+00:00, run_end_date=2024-05-22 15:30:11.169217+00:00, run_duration=1.378947, state=success, executor_state=success, try_number=1, max_tries=2, job_id=660, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:28:52.326557+00:00, queued_by_job_id=276, pid=117595
2024-05-22 15:35:16,292 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-12T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:30:13.786309+00:00, run_end_date=2024-05-22 15:35:15.694814+00:00, run_duration=301.908505, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=661, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:28:52.326557+00:00, queued_by_job_id=276, pid=117619
2024-05-22 15:35:16,324 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:35:16,342 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-16 00:00:00+00:00, run_after=2023-10-17 00:00:00+00:00
2024-05-22 15:35:16,432 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-08 00:00:00+00:00: scheduled__2023-10-08T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:51:25.774819+00:00. externally triggered: False> failed
2024-05-22 15:35:16,432 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-08 00:00:00+00:00, run_id=scheduled__2023-10-08T00:00:00+00:00, run_start_date=2024-05-22 14:51:25.788406+00:00, run_end_date=2024-05-22 15:35:16.432613+00:00, run_duration=2630.644207, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-08 00:00:00+00:00, data_interval_end=2023-10-09 00:00:00+00:00, dag_hash=937b83c7685b228397a020cdfca9016f
2024-05-22 15:35:16,435 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-09 00:00:00+00:00, run_after=2023-10-10 00:00:00+00:00
2024-05-22 15:35:16,444 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-13T00:00:00+00:00 [scheduled]>
2024-05-22 15:35:16,445 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:35:16,445 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:35:16,445 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:35:16,445 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-13T00:00:00+00:00 [scheduled]>
2024-05-22 15:35:16,447 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:35:16,448 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:35:16,448 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:35:16,448 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:35:16,448 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:35:16,448 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:35:16,450 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:36:44,554 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:36:48,275 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:41:53,018 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:41:53,018 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:41:53,018 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-13T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:41:53,025 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:35:18.108414+00:00, run_end_date=2024-05-22 15:36:43.830000+00:00, run_duration=85.721586, state=success, executor_state=success, try_number=1, max_tries=2, job_id=662, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:35:16.446294+00:00, queued_by_job_id=276, pid=117819
2024-05-22 15:41:53,025 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:36:46.364925+00:00, run_end_date=2024-05-22 15:36:47.586702+00:00, run_duration=1.221777, state=success, executor_state=success, try_number=1, max_tries=2, job_id=663, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:35:16.446294+00:00, queued_by_job_id=276, pid=117886
2024-05-22 15:41:53,026 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-13T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:36:50.270420+00:00, run_end_date=2024-05-22 15:41:52.329938+00:00, run_duration=302.059518, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=664, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:35:16.446294+00:00, queued_by_job_id=276, pid=117910
2024-05-22 15:41:53,066 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:41:53,084 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-17 00:00:00+00:00, run_after=2023-10-18 00:00:00+00:00
2024-05-22 15:41:53,191 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-09 00:00:00+00:00: scheduled__2023-10-09T00:00:00+00:00, state:running, queued_at: 2024-05-22 14:57:42.069820+00:00. externally triggered: False> failed
2024-05-22 15:41:53,191 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-09 00:00:00+00:00, run_id=scheduled__2023-10-09T00:00:00+00:00, run_start_date=2024-05-22 14:57:42.084373+00:00, run_end_date=2024-05-22 15:41:53.191628+00:00, run_duration=2651.107255, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-09 00:00:00+00:00, data_interval_end=2023-10-10 00:00:00+00:00, dag_hash=3e58c6c074b3e453b6f6f5a4d2a1ab49
2024-05-22 15:41:53,194 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-10 00:00:00+00:00, run_after=2023-10-11 00:00:00+00:00
2024-05-22 15:41:53,204 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-14T00:00:00+00:00 [scheduled]>
2024-05-22 15:41:53,205 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:41:53,205 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:41:53,205 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:41:53,205 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-14T00:00:00+00:00 [scheduled]>
2024-05-22 15:41:53,207 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:41:53,208 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:41:53,208 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:41:53,208 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:41:53,208 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:41:53,208 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:41:53,210 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:42:41,171 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:42:45,611 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:47:50,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:47:50,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:47:50,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-14T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:47:50,313 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:42:43.370473+00:00, run_end_date=2024-05-22 15:42:44.880591+00:00, run_duration=1.510118, state=success, executor_state=success, try_number=1, max_tries=2, job_id=666, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:41:53.206366+00:00, queued_by_job_id=276, pid=118170
2024-05-22 15:47:50,313 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:41:55.141352+00:00, run_end_date=2024-05-22 15:42:40.476013+00:00, run_duration=45.334661, state=success, executor_state=success, try_number=1, max_tries=2, job_id=665, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:41:53.206366+00:00, queued_by_job_id=276, pid=118123
2024-05-22 15:47:50,313 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-14T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:42:47.697637+00:00, run_end_date=2024-05-22 15:47:49.646074+00:00, run_duration=301.948437, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=667, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:41:53.206366+00:00, queued_by_job_id=276, pid=118194
2024-05-22 15:47:50,347 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:47:50,366 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-18 00:00:00+00:00, run_after=2023-10-19 00:00:00+00:00
2024-05-22 15:47:50,453 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-10 00:00:00+00:00: scheduled__2023-10-10T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:04:11.240022+00:00. externally triggered: False> failed
2024-05-22 15:47:50,453 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-10 00:00:00+00:00, run_id=scheduled__2023-10-10T00:00:00+00:00, run_start_date=2024-05-22 15:04:11.256080+00:00, run_end_date=2024-05-22 15:47:50.453568+00:00, run_duration=2619.197488, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-10 00:00:00+00:00, data_interval_end=2023-10-11 00:00:00+00:00, dag_hash=e7b470fda80d8df54d481a8929a047b9
2024-05-22 15:47:50,456 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-11 00:00:00+00:00, run_after=2023-10-12 00:00:00+00:00
2024-05-22 15:47:50,466 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-15T00:00:00+00:00 [scheduled]>
2024-05-22 15:47:50,466 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:47:50,466 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:47:50,467 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:47:50,467 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-15T00:00:00+00:00 [scheduled]>
2024-05-22 15:47:50,469 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:47:50,469 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:47:50,470 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:47:50,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:47:50,470 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:47:50,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:47:50,472 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:52:53,075 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:52:56,684 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:58:01,322 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:58:01,323 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:58:01,323 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-15T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 15:58:01,328 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-15T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:52:58.514631+00:00, run_end_date=2024-05-22 15:58:00.691734+00:00, run_duration=302.177103, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=670, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:47:50.467899+00:00, queued_by_job_id=276, pid=118618
2024-05-22 15:58:01,328 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:52:55.028612+00:00, run_end_date=2024-05-22 15:52:56.103883+00:00, run_duration=1.075271, state=success, executor_state=success, try_number=1, max_tries=2, job_id=669, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:47:50.467899+00:00, queued_by_job_id=276, pid=118593
2024-05-22 15:58:01,328 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:47:52.108416+00:00, run_end_date=2024-05-22 15:52:52.455467+00:00, run_duration=300.347051, state=success, executor_state=success, try_number=1, max_tries=2, job_id=668, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:47:50.467899+00:00, queued_by_job_id=276, pid=118397
2024-05-22 15:58:01,373 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 15:58:01,393 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-19 00:00:00+00:00, run_after=2023-10-20 00:00:00+00:00
2024-05-22 15:58:01,487 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-11 00:00:00+00:00: scheduled__2023-10-11T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:10:15.834094+00:00. externally triggered: False> failed
2024-05-22 15:58:01,488 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-11 00:00:00+00:00, run_id=scheduled__2023-10-11T00:00:00+00:00, run_start_date=2024-05-22 15:10:15.850135+00:00, run_end_date=2024-05-22 15:58:01.488281+00:00, run_duration=2865.638146, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-11 00:00:00+00:00, data_interval_end=2023-10-12 00:00:00+00:00, dag_hash=cf2ff15287c2601acd52de48c36f7930
2024-05-22 15:58:01,491 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-12 00:00:00+00:00, run_after=2023-10-13 00:00:00+00:00
2024-05-22 15:58:01,502 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-16T00:00:00+00:00 [scheduled]>
2024-05-22 15:58:01,502 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 15:58:01,503 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 15:58:01,503 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 15:58:01,503 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-16T00:00:00+00:00 [scheduled]>
2024-05-22 15:58:01,505 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 15:58:01,505 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:58:01,506 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 15:58:01,506 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:58:01,506 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 15:58:01,506 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:58:01,508 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:58:57,841 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 15:59:01,638 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:04:06,765 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:04:06,765 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:04:06,765 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-16T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:04:06,786 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-16T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:59:03.754485+00:00, run_end_date=2024-05-22 16:04:05.981410+00:00, run_duration=302.226925, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=673, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 15:58:01.503979+00:00, queued_by_job_id=276, pid=118890
2024-05-22 16:04:06,787 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:58:03.695851+00:00, run_end_date=2024-05-22 15:58:57.295344+00:00, run_duration=53.599493, state=success, executor_state=success, try_number=1, max_tries=2, job_id=671, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 15:58:01.503979+00:00, queued_by_job_id=276, pid=118815
2024-05-22 16:04:06,787 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 15:58:59.639925+00:00, run_end_date=2024-05-22 15:59:00.882845+00:00, run_duration=1.24292, state=success, executor_state=success, try_number=1, max_tries=2, job_id=672, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 15:58:01.503979+00:00, queued_by_job_id=276, pid=118866
2024-05-22 16:04:06,823 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:04:06,845 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-20 00:00:00+00:00, run_after=2023-10-21 00:00:00+00:00
2024-05-22 16:04:06,947 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-12 00:00:00+00:00: scheduled__2023-10-12T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:16:52.822554+00:00. externally triggered: False> failed
2024-05-22 16:04:06,947 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-12 00:00:00+00:00, run_id=scheduled__2023-10-12T00:00:00+00:00, run_start_date=2024-05-22 15:16:52.839267+00:00, run_end_date=2024-05-22 16:04:06.947841+00:00, run_duration=2834.108574, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-12 00:00:00+00:00, data_interval_end=2023-10-13 00:00:00+00:00, dag_hash=89a191cdc02d71d2d07450fe47c1fa60
2024-05-22 16:04:06,952 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-13 00:00:00+00:00, run_after=2023-10-14 00:00:00+00:00
2024-05-22 16:04:06,965 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-17T00:00:00+00:00 [scheduled]>
2024-05-22 16:04:06,966 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:04:06,966 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:04:06,966 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:04:06,966 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-17T00:00:00+00:00 [scheduled]>
2024-05-22 16:04:06,969 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:04:06,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:04:06,970 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:04:06,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:04:06,970 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:04:06,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:04:06,972 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:05:29,950 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:05:33,516 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:10:38,306 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:10:38,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:10:38,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-17T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:10:38,312 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:04:08.836365+00:00, run_end_date=2024-05-22 16:05:29.348093+00:00, run_duration=80.511728, state=success, executor_state=success, try_number=1, max_tries=2, job_id=674, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:04:06.967415+00:00, queued_by_job_id=276, pid=119092
2024-05-22 16:10:38,312 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:05:31.685934+00:00, run_end_date=2024-05-22 16:05:32.838318+00:00, run_duration=1.152384, state=success, executor_state=success, try_number=1, max_tries=2, job_id=675, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:04:06.967415+00:00, queued_by_job_id=276, pid=119161
2024-05-22 16:10:38,312 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-17T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:05:35.769986+00:00, run_end_date=2024-05-22 16:10:37.718288+00:00, run_duration=301.948302, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=676, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:04:06.967415+00:00, queued_by_job_id=276, pid=119186
2024-05-22 16:10:38,350 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:10:38,369 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-21 00:00:00+00:00, run_after=2023-10-22 00:00:00+00:00
2024-05-22 16:10:38,465 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-13 00:00:00+00:00: scheduled__2023-10-13T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:22:48.988071+00:00. externally triggered: False> failed
2024-05-22 16:10:38,465 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-13 00:00:00+00:00, run_id=scheduled__2023-10-13T00:00:00+00:00, run_start_date=2024-05-22 15:22:49.003464+00:00, run_end_date=2024-05-22 16:10:38.465625+00:00, run_duration=2869.462161, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-13 00:00:00+00:00, data_interval_end=2023-10-14 00:00:00+00:00, dag_hash=b93c13c1d13fb0b2790dbdd36a79502a
2024-05-22 16:10:38,470 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-14 00:00:00+00:00, run_after=2023-10-15 00:00:00+00:00
2024-05-22 16:10:38,485 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-18T00:00:00+00:00 [scheduled]>
2024-05-22 16:10:38,485 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:10:38,485 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:10:38,486 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:10:38,486 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-18T00:00:00+00:00 [scheduled]>
2024-05-22 16:10:38,488 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:10:38,489 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:10:38,489 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:10:38,489 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:10:38,489 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:10:38,490 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:10:38,491 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:12:07,600 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:12:11,812 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:17:16,580 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:17:16,580 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:17:16,581 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-18T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:17:16,586 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:10:40.341490+00:00, run_end_date=2024-05-22 16:12:07.010371+00:00, run_duration=86.668881, state=success, executor_state=success, try_number=1, max_tries=2, job_id=677, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:10:38.486920+00:00, queued_by_job_id=276, pid=119382
2024-05-22 16:17:16,586 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:12:09.790864+00:00, run_end_date=2024-05-22 16:12:11.168116+00:00, run_duration=1.377252, state=success, executor_state=success, try_number=1, max_tries=2, job_id=678, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:10:38.486920+00:00, queued_by_job_id=276, pid=119466
2024-05-22 16:17:16,586 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-18T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:12:13.810659+00:00, run_end_date=2024-05-22 16:17:15.877904+00:00, run_duration=302.067245, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=679, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:10:38.486920+00:00, queued_by_job_id=276, pid=119490
2024-05-22 16:17:16,631 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:17:16,666 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-22 00:00:00+00:00, run_after=2023-10-23 00:00:00+00:00
2024-05-22 16:17:16,770 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-14 00:00:00+00:00: scheduled__2023-10-14T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:28:52.172830+00:00. externally triggered: False> failed
2024-05-22 16:17:16,770 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-14 00:00:00+00:00, run_id=scheduled__2023-10-14T00:00:00+00:00, run_start_date=2024-05-22 15:28:52.191551+00:00, run_end_date=2024-05-22 16:17:16.770513+00:00, run_duration=2904.578962, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-14 00:00:00+00:00, data_interval_end=2023-10-15 00:00:00+00:00, dag_hash=5e85e6e9fe42253ce2040000637b24fb
2024-05-22 16:17:16,774 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-15 00:00:00+00:00, run_after=2023-10-16 00:00:00+00:00
2024-05-22 16:17:16,785 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-19T00:00:00+00:00 [scheduled]>
2024-05-22 16:17:16,785 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:17:16,785 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:17:16,785 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:17:16,785 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-19T00:00:00+00:00 [scheduled]>
2024-05-22 16:17:16,788 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:17:16,788 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:17:16,788 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:17:16,789 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:17:16,789 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:17:16,789 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:17:16,790 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:18:06,547 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:18:10,133 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:23:14,592 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:23:14,593 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:23:14,593 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-19T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:23:14,598 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:18:08.362337+00:00, run_end_date=2024-05-22 16:18:09.568883+00:00, run_duration=1.206546, state=success, executor_state=success, try_number=1, max_tries=2, job_id=681, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:17:16.786575+00:00, queued_by_job_id=276, pid=119743
2024-05-22 16:23:14,599 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-19T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:18:12.036952+00:00, run_end_date=2024-05-22 16:23:13.956771+00:00, run_duration=301.919819, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=682, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:17:16.786575+00:00, queued_by_job_id=276, pid=119767
2024-05-22 16:23:14,599 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:17:18.748008+00:00, run_end_date=2024-05-22 16:18:05.920769+00:00, run_duration=47.172761, state=success, executor_state=success, try_number=1, max_tries=2, job_id=680, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:17:16.786575+00:00, queued_by_job_id=276, pid=119696
2024-05-22 16:23:14,632 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:23:14,659 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-23 00:00:00+00:00, run_after=2023-10-24 00:00:00+00:00
2024-05-22 16:23:14,779 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-15 00:00:00+00:00: scheduled__2023-10-15T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:35:16.336461+00:00. externally triggered: False> failed
2024-05-22 16:23:14,779 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-15 00:00:00+00:00, run_id=scheduled__2023-10-15T00:00:00+00:00, run_start_date=2024-05-22 15:35:16.348753+00:00, run_end_date=2024-05-22 16:23:14.779494+00:00, run_duration=2878.430741, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-15 00:00:00+00:00, data_interval_end=2023-10-16 00:00:00+00:00, dag_hash=0d723426c21e1b81c57ded593ee05622
2024-05-22 16:23:14,782 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-16 00:00:00+00:00, run_after=2023-10-17 00:00:00+00:00
2024-05-22 16:23:14,792 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-20T00:00:00+00:00 [scheduled]>
2024-05-22 16:23:14,792 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:23:14,793 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:23:14,793 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:23:14,793 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-20T00:00:00+00:00 [scheduled]>
2024-05-22 16:23:14,795 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:23:14,795 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:23:14,796 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:23:14,796 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:23:14,796 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:23:14,796 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:23:14,798 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:24:04,454 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:24:08,339 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:29:12,486 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:29:12,487 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:29:12,487 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-20T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:29:12,498 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:23:16.985031+00:00, run_end_date=2024-05-22 16:24:03.825410+00:00, run_duration=46.840379, state=success, executor_state=success, try_number=1, max_tries=2, job_id=683, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:23:14.794116+00:00, queued_by_job_id=276, pid=119966
2024-05-22 16:29:12,499 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-20T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:24:09.926187+00:00, run_end_date=2024-05-22 16:29:11.807157+00:00, run_duration=301.88097, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=685, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:23:14.794116+00:00, queued_by_job_id=276, pid=120037
2024-05-22 16:29:12,499 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:24:06.452116+00:00, run_end_date=2024-05-22 16:24:07.686585+00:00, run_duration=1.234469, state=success, executor_state=success, try_number=1, max_tries=2, job_id=684, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:23:14.794116+00:00, queued_by_job_id=276, pid=120013
2024-05-22 16:29:12,532 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:29:12,550 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-24 00:00:00+00:00, run_after=2023-10-25 00:00:00+00:00
2024-05-22 16:29:12,639 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-16 00:00:00+00:00: scheduled__2023-10-16T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:41:53.078654+00:00. externally triggered: False> failed
2024-05-22 16:29:12,639 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-16 00:00:00+00:00, run_id=scheduled__2023-10-16T00:00:00+00:00, run_start_date=2024-05-22 15:41:53.092361+00:00, run_end_date=2024-05-22 16:29:12.639662+00:00, run_duration=2839.547301, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-16 00:00:00+00:00, data_interval_end=2023-10-17 00:00:00+00:00, dag_hash=2fa294100de168a75e5ef3b2af306ce3
2024-05-22 16:29:12,650 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-17 00:00:00+00:00, run_after=2023-10-18 00:00:00+00:00
2024-05-22 16:29:12,661 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-21T00:00:00+00:00 [scheduled]>
2024-05-22 16:29:12,661 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:29:12,661 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:29:12,661 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:29:12,662 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-21T00:00:00+00:00 [scheduled]>
2024-05-22 16:29:12,664 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:29:12,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:29:12,664 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:29:12,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:29:12,665 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:29:12,665 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:29:12,666 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:31:23,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:31:27,257 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:36:31,808 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:36:31,808 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:36:31,808 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:36:31,828 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:29:14.574031+00:00, run_end_date=2024-05-22 16:31:22.708409+00:00, run_duration=128.134378, state=success, executor_state=success, try_number=1, max_tries=2, job_id=686, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:29:12.662660+00:00, queued_by_job_id=276, pid=120235
2024-05-22 16:36:31,829 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:31:25.298674+00:00, run_end_date=2024-05-22 16:31:26.489793+00:00, run_duration=1.191119, state=success, executor_state=success, try_number=1, max_tries=2, job_id=687, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:29:12.662660+00:00, queued_by_job_id=276, pid=120331
2024-05-22 16:36:31,829 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-21T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:31:29.213196+00:00, run_end_date=2024-05-22 16:36:31.184004+00:00, run_duration=301.970808, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=688, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:29:12.662660+00:00, queued_by_job_id=276, pid=120356
2024-05-22 16:36:31,865 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:36:31,886 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-25 00:00:00+00:00, run_after=2023-10-26 00:00:00+00:00
2024-05-22 16:36:31,977 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-17 00:00:00+00:00: scheduled__2023-10-17T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:47:50.359635+00:00. externally triggered: False> failed
2024-05-22 16:36:31,977 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-17 00:00:00+00:00, run_id=scheduled__2023-10-17T00:00:00+00:00, run_start_date=2024-05-22 15:47:50.373421+00:00, run_end_date=2024-05-22 16:36:31.977838+00:00, run_duration=2921.604417, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-17 00:00:00+00:00, data_interval_end=2023-10-18 00:00:00+00:00, dag_hash=052cdbc0473f80ef0cc89f68d5c7dde6
2024-05-22 16:36:31,981 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-18 00:00:00+00:00, run_after=2023-10-19 00:00:00+00:00
2024-05-22 16:36:31,991 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-22T00:00:00+00:00 [scheduled]>
2024-05-22 16:36:31,992 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:36:31,992 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:36:31,992 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:36:31,992 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-22T00:00:00+00:00 [scheduled]>
2024-05-22 16:36:31,995 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:36:31,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:36:31,995 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:36:31,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:36:31,995 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:36:31,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:36:31,997 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:37:41,321 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:37:45,120 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:42:49,884 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:42:49,884 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:42:49,885 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-22T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:42:49,890 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:36:33.693900+00:00, run_end_date=2024-05-22 16:37:40.641779+00:00, run_duration=66.947879, state=success, executor_state=success, try_number=1, max_tries=2, job_id=689, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:36:31.993523+00:00, queued_by_job_id=276, pid=120555
2024-05-22 16:42:49,890 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:37:43.312746+00:00, run_end_date=2024-05-22 16:37:44.440401+00:00, run_duration=1.127655, state=success, executor_state=success, try_number=1, max_tries=2, job_id=690, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:36:31.993523+00:00, queued_by_job_id=276, pid=120612
2024-05-22 16:42:49,891 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-22T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:37:47.178318+00:00, run_end_date=2024-05-22 16:42:49.174919+00:00, run_duration=301.996601, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=691, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:36:31.993523+00:00, queued_by_job_id=276, pid=120640
2024-05-22 16:42:49,925 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:42:49,961 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-26 00:00:00+00:00, run_after=2023-10-27 00:00:00+00:00
2024-05-22 16:42:50,102 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-18 00:00:00+00:00: scheduled__2023-10-18T00:00:00+00:00, state:running, queued_at: 2024-05-22 15:58:01.385781+00:00. externally triggered: False> failed
2024-05-22 16:42:50,103 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-18 00:00:00+00:00, run_id=scheduled__2023-10-18T00:00:00+00:00, run_start_date=2024-05-22 15:58:01.400877+00:00, run_end_date=2024-05-22 16:42:50.103074+00:00, run_duration=2688.702197, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-18 00:00:00+00:00, data_interval_end=2023-10-19 00:00:00+00:00, dag_hash=5dd616ccc0c7851b81bf3c6d24e563e5
2024-05-22 16:42:50,106 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-19 00:00:00+00:00, run_after=2023-10-20 00:00:00+00:00
2024-05-22 16:42:50,116 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-23T00:00:00+00:00 [scheduled]>
2024-05-22 16:42:50,117 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:42:50,117 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:42:50,117 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:42:50,117 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-23T00:00:00+00:00 [scheduled]>
2024-05-22 16:42:50,119 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:42:50,120 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:42:50,120 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:42:50,120 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:42:50,120 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:42:50,120 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:42:50,122 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:43:48,523 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:43:52,498 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:48:57,139 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:48:57,140 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:48:57,140 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-23T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:48:57,145 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:42:52.316588+00:00, run_end_date=2024-05-22 16:43:47.943323+00:00, run_duration=55.626735, state=success, executor_state=success, try_number=1, max_tries=2, job_id=692, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:42:50.118440+00:00, queued_by_job_id=276, pid=120838
2024-05-22 16:48:57,145 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:43:50.215574+00:00, run_end_date=2024-05-22 16:43:51.848394+00:00, run_duration=1.63282, state=success, executor_state=success, try_number=1, max_tries=2, job_id=693, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:42:50.118440+00:00, queued_by_job_id=276, pid=120885
2024-05-22 16:48:57,146 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-23T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:43:54.480352+00:00, run_end_date=2024-05-22 16:48:56.438323+00:00, run_duration=301.957971, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=694, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:42:50.118440+00:00, queued_by_job_id=276, pid=120913
2024-05-22 16:48:57,182 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:48:57,203 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-27 00:00:00+00:00, run_after=2023-10-28 00:00:00+00:00
2024-05-22 16:48:57,305 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-19 00:00:00+00:00: scheduled__2023-10-19T00:00:00+00:00, state:running, queued_at: 2024-05-22 16:04:06.837775+00:00. externally triggered: False> failed
2024-05-22 16:48:57,306 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-19 00:00:00+00:00, run_id=scheduled__2023-10-19T00:00:00+00:00, run_start_date=2024-05-22 16:04:06.853255+00:00, run_end_date=2024-05-22 16:48:57.306235+00:00, run_duration=2690.45298, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-19 00:00:00+00:00, data_interval_end=2023-10-20 00:00:00+00:00, dag_hash=5363908c5ccacc8829451f56531a1e3d
2024-05-22 16:48:57,309 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-20 00:00:00+00:00, run_after=2023-10-21 00:00:00+00:00
2024-05-22 16:48:57,322 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-24T00:00:00+00:00 [scheduled]>
2024-05-22 16:48:57,323 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:48:57,323 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:48:57,323 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:48:57,323 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-24T00:00:00+00:00 [scheduled]>
2024-05-22 16:48:57,326 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:48:57,326 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:48:57,327 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:48:57,327 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:48:57,327 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:48:57,327 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:48:57,329 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:50:25,249 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:50:29,398 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:55:33,656 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:55:33,656 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:55:33,656 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-24T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 16:55:33,662 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:50:27.315395+00:00, run_end_date=2024-05-22 16:50:28.718176+00:00, run_duration=1.402781, state=success, executor_state=success, try_number=1, max_tries=2, job_id=696, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:48:57.324803+00:00, queued_by_job_id=276, pid=121182
2024-05-22 16:55:33,663 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:48:59.066639+00:00, run_end_date=2024-05-22 16:50:24.566308+00:00, run_duration=85.499669, state=success, executor_state=success, try_number=1, max_tries=2, job_id=695, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:48:57.324803+00:00, queued_by_job_id=276, pid=121111
2024-05-22 16:55:33,663 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-24T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:50:31.090562+00:00, run_end_date=2024-05-22 16:55:32.959571+00:00, run_duration=301.869009, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=697, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:48:57.324803+00:00, queued_by_job_id=276, pid=121206
2024-05-22 16:55:33,697 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 16:55:33,717 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-28 00:00:00+00:00, run_after=2023-10-29 00:00:00+00:00
2024-05-22 16:55:33,812 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-20 00:00:00+00:00: scheduled__2023-10-20T00:00:00+00:00, state:running, queued_at: 2024-05-22 16:10:38.363018+00:00. externally triggered: False> failed
2024-05-22 16:55:33,812 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-20 00:00:00+00:00, run_id=scheduled__2023-10-20T00:00:00+00:00, run_start_date=2024-05-22 16:10:38.376434+00:00, run_end_date=2024-05-22 16:55:33.812354+00:00, run_duration=2695.43592, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-20 00:00:00+00:00, data_interval_end=2023-10-21 00:00:00+00:00, dag_hash=0f7a2a8d0d8bf204966f4506e9339e54
2024-05-22 16:55:33,815 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-21 00:00:00+00:00, run_after=2023-10-22 00:00:00+00:00
2024-05-22 16:55:33,826 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-25T00:00:00+00:00 [scheduled]>
2024-05-22 16:55:33,826 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 16:55:33,827 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 16:55:33,827 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 16:55:33,827 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-25T00:00:00+00:00 [scheduled]>
2024-05-22 16:55:33,829 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 16:55:33,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:55:33,830 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 16:55:33,830 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:55:33,830 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 16:55:33,831 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:55:33,832 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:57:10,992 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 16:57:14,611 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:02:19,090 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:02:19,090 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:02:19,091 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-25T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:02:19,096 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:57:12.776548+00:00, run_end_date=2024-05-22 16:57:13.988441+00:00, run_duration=1.211893, state=success, executor_state=success, try_number=1, max_tries=2, job_id=699, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 16:55:33.828066+00:00, queued_by_job_id=276, pid=121477
2024-05-22 17:02:19,096 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-25T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:57:16.521588+00:00, run_end_date=2024-05-22 17:02:18.426885+00:00, run_duration=301.905297, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=700, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 16:55:33.828066+00:00, queued_by_job_id=276, pid=121502
2024-05-22 17:02:19,097 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 16:55:35.947828+00:00, run_end_date=2024-05-22 16:57:10.404155+00:00, run_duration=94.456327, state=success, executor_state=success, try_number=1, max_tries=2, job_id=698, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 16:55:33.828066+00:00, queued_by_job_id=276, pid=121405
2024-05-22 17:02:19,130 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 17:02:19,151 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-29 00:00:00+00:00, run_after=2023-10-30 00:00:00+00:00
2024-05-22 17:02:19,449 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-21 00:00:00+00:00: scheduled__2023-10-21T00:00:00+00:00, state:running, queued_at: 2024-05-22 16:17:16.648191+00:00. externally triggered: False> failed
2024-05-22 17:02:19,450 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-21 00:00:00+00:00, run_id=scheduled__2023-10-21T00:00:00+00:00, run_start_date=2024-05-22 16:17:16.682590+00:00, run_end_date=2024-05-22 17:02:19.450509+00:00, run_duration=2702.767919, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-21 00:00:00+00:00, data_interval_end=2023-10-22 00:00:00+00:00, dag_hash=1ab34a3d097f3214aaeafa8d5c15277a
2024-05-22 17:02:19,455 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-22 00:00:00+00:00, run_after=2023-10-23 00:00:00+00:00
2024-05-22 17:02:19,470 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
2024-05-22 17:02:19,470 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 17:02:19,470 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 17:02:19,470 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 17:02:19,471 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
2024-05-22 17:02:19,473 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 17:02:19,473 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:02:19,474 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 17:02:19,474 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:02:19,474 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 17:02:19,475 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:02:19,476 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:03:52,280 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:03:56,669 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:09:01,481 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:09:01,481 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:09:01,481 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:09:01,501 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 17:03:58.600891+00:00, run_end_date=2024-05-22 17:09:00.849390+00:00, run_duration=302.248499, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=703, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 17:02:19.471793+00:00, queued_by_job_id=276, pid=121798
2024-05-22 17:09:01,502 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 17:02:21.500314+00:00, run_end_date=2024-05-22 17:03:51.565952+00:00, run_duration=90.065638, state=success, executor_state=success, try_number=1, max_tries=2, job_id=701, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 17:02:19.471793+00:00, queued_by_job_id=276, pid=121702
2024-05-22 17:09:01,502 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 17:03:54.697182+00:00, run_end_date=2024-05-22 17:03:56.056525+00:00, run_duration=1.359343, state=success, executor_state=success, try_number=1, max_tries=2, job_id=702, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 17:02:19.471793+00:00, queued_by_job_id=276, pid=121773
2024-05-22 17:09:01,540 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 17:09:01,561 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-30 00:00:00+00:00, run_after=2023-10-31 00:00:00+00:00
2024-05-22 17:09:01,670 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-22 00:00:00+00:00: scheduled__2023-10-22T00:00:00+00:00, state:running, queued_at: 2024-05-22 16:23:14.645003+00:00. externally triggered: False> failed
2024-05-22 17:09:01,671 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-22 00:00:00+00:00, run_id=scheduled__2023-10-22T00:00:00+00:00, run_start_date=2024-05-22 16:23:14.678378+00:00, run_end_date=2024-05-22 17:09:01.671283+00:00, run_duration=2746.992905, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-22 00:00:00+00:00, data_interval_end=2023-10-23 00:00:00+00:00, dag_hash=f6d895ccd7076c4b2ba94d646e1b9bda
2024-05-22 17:09:01,675 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-23 00:00:00+00:00, run_after=2023-10-24 00:00:00+00:00
2024-05-22 17:09:01,695 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-27T00:00:00+00:00 [scheduled]>
2024-05-22 17:09:01,696 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 17:09:01,697 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 17:09:01,697 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 17:09:01,697 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-27T00:00:00+00:00 [scheduled]>
2024-05-22 17:09:01,704 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 17:09:01,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:09:01,704 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 17:09:01,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:09:01,705 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 17:09:01,705 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:09:01,713 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:09:58,837 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:10:02,913 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:15:07,380 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-29T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:15:07,380 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-28T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:15:07,380 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-27T00:00:00+00:00', try_number=1, map_index=-1)
2024-05-22 17:15:07,386 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=extract_311_data, run_id=scheduled__2023-10-29T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 17:09:03.742555+00:00, run_end_date=2024-05-22 17:09:58.205231+00:00, run_duration=54.462676, state=success, executor_state=success, try_number=1, max_tries=2, job_id=704, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-05-22 17:09:01.699374+00:00, queued_by_job_id=276, pid=121997
2024-05-22 17:15:07,386 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=load_to_s3, run_id=scheduled__2023-10-28T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 17:10:00.758185+00:00, run_end_date=2024-05-22 17:10:02.221764+00:00, run_duration=1.463579, state=success, executor_state=success, try_number=1, max_tries=2, job_id=705, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2024-05-22 17:09:01.699374+00:00, queued_by_job_id=276, pid=122051
2024-05-22 17:15:07,387 INFO - TaskInstance Finished: dag_id=extract_311_data_dag, task_id=is_file_in_s3_available, run_id=scheduled__2023-10-27T00:00:00+00:00, map_index=-1, run_start_date=2024-05-22 17:10:04.819283+00:00, run_end_date=2024-05-22 17:15:06.757119+00:00, run_duration=301.937836, state=failed, executor_state=success, try_number=1, max_tries=2, job_id=706, pool=default_pool, queue=default, priority_weight=6, operator=S3KeySensor, queued_dttm=2024-05-22 17:09:01.699374+00:00, queued_by_job_id=276, pid=122075
2024-05-22 17:15:07,422 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-05-22 17:15:07,441 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-31 00:00:00+00:00, run_after=2023-11-01 00:00:00+00:00
2024-05-22 17:15:07,565 ERROR - Marking run <DagRun extract_311_data_dag @ 2023-10-23 00:00:00+00:00: scheduled__2023-10-23T00:00:00+00:00, state:running, queued_at: 2024-05-22 16:29:12.545124+00:00. externally triggered: False> failed
2024-05-22 17:15:07,565 INFO - DagRun Finished: dag_id=extract_311_data_dag, execution_date=2023-10-23 00:00:00+00:00, run_id=scheduled__2023-10-23T00:00:00+00:00, run_start_date=2024-05-22 16:29:12.557912+00:00, run_end_date=2024-05-22 17:15:07.565524+00:00, run_duration=2755.007612, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-23 00:00:00+00:00, data_interval_end=2023-10-24 00:00:00+00:00, dag_hash=aab7727126d78c14739687d5e97643de
2024-05-22 17:15:07,568 INFO - Setting next_dagrun for extract_311_data_dag to 2023-10-24 00:00:00+00:00, run_after=2023-10-25 00:00:00+00:00
2024-05-22 17:15:07,579 INFO - 3 tasks up for execution:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-28T00:00:00+00:00 [scheduled]>
2024-05-22 17:15:07,579 INFO - DAG extract_311_data_dag has 0/16 running and queued tasks
2024-05-22 17:15:07,579 INFO - DAG extract_311_data_dag has 1/16 running and queued tasks
2024-05-22 17:15:07,579 INFO - DAG extract_311_data_dag has 2/16 running and queued tasks
2024-05-22 17:15:07,580 INFO - Setting the following tasks to queued state:
	<TaskInstance: extract_311_data_dag.extract_311_data scheduled__2023-10-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.load_to_s3 scheduled__2023-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: extract_311_data_dag.is_file_in_s3_available scheduled__2023-10-28T00:00:00+00:00 [scheduled]>
2024-05-22 17:15:07,582 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='extract_311_data', run_id='scheduled__2023-10-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-05-22 17:15:07,582 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:15:07,582 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='load_to_s3', run_id='scheduled__2023-10-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-05-22 17:15:07,583 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:15:07,583 INFO - Sending TaskInstanceKey(dag_id='extract_311_data_dag', task_id='is_file_in_s3_available', run_id='scheduled__2023-10-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-05-22 17:15:07,583 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:15:07,585 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'extract_311_data', 'scheduled__2023-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:16:46,987 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'load_to_s3', 'scheduled__2023-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:16:50,920 INFO - Executing command: ['airflow', 'tasks', 'run', 'extract_311_data_dag', 'is_file_in_s3_available', 'scheduled__2023-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/311-analytics-dag.py']
2024-05-22 17:20:59,954 INFO - Exiting gracefully upon receiving signal 15
